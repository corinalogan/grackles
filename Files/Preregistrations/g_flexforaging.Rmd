---
title: Behavioral flexibility is related to foraging behavior in a rapidly expanding species
author: 
- '[Logan CJ](http://CorinaLogan.com)^1^*'
- '[Lukas D](http://dieterlukas.mystrikingly.com)^1^*'
- 'Blackwell A^2^'
- 'Bergeron L^3^'
- 'Edrisi M^2^'
- 'Folsom M^1^'
- 'Geng X^4^'
- 'Hardy K^4^'
- 'He X^4^'
- 'LeGrande-Rolls C^1^'
- 'Marfori Z^1^'
- 'Rowney C^1^'
- 'Sevchik A^5^'
- '[McCune KB](https://www.kelseymccune.com)^3^'
date: '`r Sys.Date()`'
always_allow_html: yes
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
    code_folding: hide 
  bookdown::pdf_document2:
    keep_tex: true
  number_sections: TRUE
  fig_caption: TRUE
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
bibliography: MyLibrary.bib
biblio-style: authoryear
csl: Peer-Community-Journal-PCI.csl
caption-side: bottom
urlcolor: blue
header-includes:
  - \usepackage[left]{lineno}
  - \linenumbers
  - \usepackage{fancyhdr}
  - \usepackage{pdflscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
preamble: >
  \usepackage{amsmath} #NOTE: to make this yaml work, run install.packages("rticles")
base_format: rticles::amsmath
#SUBMITTING TO PCJ: use the google doc template (not the .tex file bc would have to attach all dependent files) and trim the bib to only those articles cited (see r code chunk "setup"). Follow the template and instructions
##If not sure that the formatting is perfect, then a odt or word file is easier to handle for PCJ. With xpopbehaviorhabitatq1 (google doc to .odt and they worked only from the odt bc they had to make so many changes), most changes PCJ had to do were subsections and sub-subsections formatting, spaces after normal text, removing empty lines, format of legend of figures and legends of tables, format of tables, and avoiding big empty spaces along the article by playing with the dimensions of figures and tables. The rest was ok. 
##PCJ says "The google doc is ok to use if there is not much corrections to do on our side after we receive it. In other words, if we received a very well formatted google doc, it's perfect. If we have to work extensively on it, it's a waste of time compared to a latex, word or odt because there is no automatic formatting in google doc."
##.bib file: For proper formatting of species names in the refs, wrap with {\emph{(Columbia livia)}} so it will be properly capitalized and in italics (https://stackoverflow.com/questions/62176912/references-in-rmarkdown-use-title-capitalization-as-is-in-the-bib-file)
---

Open... ![](logoOpenAccess.png){width=5%} access ![](logoOpenCode.png){width=5%} [code](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforaging.Rmd) ![](logoOpenPeerReview.png){width=5%} peer review ![](logoOpenData.png){width=5%} [data]()

&nbsp;

**Affiliations:** 1) Max Planck Institute for Evolutionary Anthropology, Leipzig, Germany, 2) Washington State University, Pullman, Washington, USA, 3) University of California Santa Barbara, USA, 4) University of Rochester, New York, USA, 5) Arizona State University, Tempe, Arizona, USA. *Corresponding author: corina_logan@eva.mpg.de

```{r setup, include=FALSE}
library(knitr)
library(formatR)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=70),tidy=TRUE) 
#Make code chunks wrap text so it doesn't go off the page when knitting to PDF

knitr::opts_chunk$set(echo=T, include=T, results='asis', warning=F, message=F) 
#sets global options to display code along with the results https://exeter-data-analytics.github.io/LitProg/r-markdown.html
#set echo=F for knitting to PDF (hide code), and echo=T for knitting to HTML (show code)
```

```{r cleanbib, include=FALSE, eval=F}
### make a bibtex file that has only the references cited in this rmd 
#load the Rmd file
Rmd <- readChar("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging.Rmd",nchars=1e7)

#find all in text citations that start with @, but are preceded by a space
pattern <- "\\ @(.*?)\\ "
m <- regmatches(Rmd,gregexpr(pattern,Rmd))[[1]]
m

res<- gsub("\\ ","",m) #delete spaces
res<- gsub("\\]","",res) #delete ]
res<- gsub("\\;","",res) #delete ;
res<- gsub("\\,","",res) #delete ,
res<- gsub("\\.","",res) # delete .

#find all in text citations that start with @, but are preceded by a "["
pattern2 <- "\\[@(.*?)\\ "
m2 <- regmatches(Rmd,gregexpr(pattern2,Rmd))[[1]]
m2

res2<- gsub("\\[","",m2)
res2<- gsub("\\]","",res2)
res2<- gsub("\\]","",res2)
res2<- gsub("\\;","",res2)
res2<- gsub("\\,","",res2)
res2<- gsub("\\.","",res2)
res2<- gsub("\\ ","",res2)

#combine both patterns
allbibtexkeys<-c(res,res2)

#write to a new file and then clean it up manually
write(allbibtexkeys,file="g_flexforaging_bibtexkeys.txt")

#load the cleaned txt file
allbibtexkeys<-read.csv("gxpopbehaviorhabitatq1_bibtexkeys.txt")

#use bib2df to convert the bibliography file into a dataframe
install.packages("bib2df")
library(bib2df)

#load the bib from GitHub
df <- bib2df("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/MyLibrary.bib")

#remove the @ to match the entry in the bib file
allbibtexkeys2<- gsub("\\@","",allbibtexkeys[,1])

#filter the full bib to only keep the entries that are cited here
df_filtered<-df[df$BIBTEXKEY %in% allbibtexkeys2,]

#use bib2df to convert the data frame into the bibliography file that only contains the citations in this Rmd
df2bib(df_filtered, file = "g_flexforaging_refs.bib", append = FALSE)
```


&nbsp;

**This is the post-study manuscript of the preregistration that was pre-study peer reviewed and received an In Principle Recommendation on 6 Aug 2019 by:**

Julia Astegiano and Esther Sebastián Gonzalez (2019) Understanding geographic range expansions in human-dominated landscapes: does behavioral flexibility modulate flexibility in foraging and social behavior? *Peer Community in Ecology*, 100026. [10.24072/pci.ecology.100026](https://doi.org/10.24072/pci.ecology.100026). Reviewers: Pizza Ka Yee Chow and Esther Sebastián González

**Preregistration:** [html](http://corinalogan.com/Preregistrations/g_flexforaging.html), [pdf](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforagingPassedPreStudyPeerReviewOn6Aug2019.pdf), [rmd](https://github.com/corinalogan/grackles/blob/d17a75c24df4b90aa607eda452f4fcc496ae9409/Files/Preregistrations/g_flexforaging.Rmd)

**Post-study manuscript** (submitted to PCI Ecology for post-study peer review on ?): preprint [pdf]() at EcoEvoRxiv, [rmd](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforaging.Rmd)


# Abstract {-}

This is one of the first studies planned for our long-term research on the role of behavioral flexibility in rapid geographic range expansions. **Project background:** Behavioral flexibility, the ability to change behavior when circumstances change based on learning from previous experience (@mikhalevich_is_2017), is thought to play an important role in a species' ability to successfully adapt to new environments and expand its geographic range (e.g., @lefebvre1997feeding, @griffin2014innovation, @chow2016practice, @sol2000behavioural, @sol2002behavioural, @sol2005big). However, behavioral flexibility is rarely directly tested at the individual level, thus limiting our ability to determine how it relates to other traits (e.g., behavior, invasion success, diet generalism, foraging techniques, foraging innovations, mortality, brain size), which limits the power of predictions about a species' ability to adapt behavior to new environments. We use great-tailed grackles (a bird species) as a model to investigate this question because they have rapidly expanded their range into North America over the past 140 years (i.e., they increased their nesting range by over 5500% between 1880 and 2000 [@wehtje2003range], [@peer2011invasion]) (Fig. 1). Foraging behavior is considered central to the rapid geographic range expansion of this species and it is thought that they have been so successful by following human urban and agricultural corridors (@wehtje2003range, @peer2011invasion). Therefore, as humans continue to modify landscapes, this increases the amount of suitable grackle habitat. We expect this species to be behaviorally flexible because they are fast at reversal learning (@logan2016behavioral), they often encounter human-made "puzzle boxes" in the wild as they attempt to open packaging to access food when digging through garbage cans and eating at outdoor cafes, and they may track resources across time and space. Results will allow us to determine whether, as predicted by hypotheses and cross-species correlational data, in this expanding species, individual-level variation in flexibility is linked with diet breadth, foraging proficiency, social interactions, habitat use, and movement into new geographic areas. **This investigation**: In this piece of the long-term project, we will assess whether individual performance in experiments that assess behavioral flexibility relates to individual variation in ecological and social behavior in the natural environment. In particular, we aim to determine whether the more behaviorally flexible (measured by reversal learning and solution switching on a multi-access box in a separate [preregistration](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md)) grackles have more flexible foraging behavior (eat a larger number of different foods, use a wider variety of foraging techniques), are more flexible in their habitat use (are found in more diverse habitat types, disperse farther from their natal area), and are more flexible in their social relationships (have more or stronger social bonds particularly with less related individuals). We will be able to compare the grackle's ability to adapt behavior according to social context with data from other species, as well as determine whether it is linked with measures of flexibility in asocial contexts.  

\newpage

# Introduction {-}

## HYPOTHESES

### H1: [Behavioral flexibility](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md) [see @mikhalevich_is_2017 for a detailed definition] is related to foraging behavior (measured with focal follows using this [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing)) in wild individuals (after their release from the aviaries). We measure flexibility in aviaries using two paradigms: reversal learning [where grackles must learn to prefer one of two options that contain food and then reverse this preference] and switching between options on a multi-access box (where grackles must learn to switch to a new option, out of four available options, when an option becomes non-functional). We expect this species to be behaviorally flexible because they are fast at reversal learning [@logan2016behavioral], they often encounter human-made "puzzle boxes" in the wild as they attempt to open packaging to access food when digging through garbage cans and eating at outdoor cafes, and they may track resources across time and space. Foraging behavior is considered central to the rapid geographic range expansion of this species and it is thought that they have been so successful by following human urban and agricultural corridors [@wehtje2003range; @peer2011invasion]. Therefore, as humans continue to modify landscapes, this increases the amount of suitable grackle habitat.

**Prediction 1:** Individuals that are faster to reverse preferences on a reversal learning task and who also have lower latencies to switch to solving new loci after previously solved loci become unavailable (multi-access box) will eat a larger number of different foods and use a wider variety of foraging techniques in the wild, validating the cross-species correlational finding that technique breadth [@overington2009technical] and diet breadth [@ducatez2015ecological] is associated with flexibility.

**P1 alternative 1:** If there is no correlation, this suggests that flexibility as we measured it represents a trait that is not related to the number of foods eaten and foraging techniques used. Flexibility may not necessarily be associated with diet and foraging technique breadth because flexibility could be constrained in a foraging context due to social competition (e.g., subordinates are outcompeted while foraging and thus try new foods and techniques) or ecological limitations (e.g., constrained by what is available). Additional research would be required to determine the factors that might constrain foraging behavior.

**P1 alternative 2:** If there is a negative correlation between flexibility and the number of different foods eaten, this might indicate that the more flexible individuals target particular food items. If this prediction is supported, we will conduct an additional analysis to examine what food types the more flexible grackles eat and whether these food types are potentially more valuable (measured as having more calories).

**P1 alternative 3:** If there is a negative correlation between flexibility and the number of foraging techniques, this could indicate that the more flexible individuals use particular (potentially more effective) techniques.

**P2:** Individuals whose [flexibility](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md) has been increased experimentally will consume a larger number of foods and use more foraging techniques (measured with focal follows) than individuals whose flexibility has not been manipulated. This would further validate that flexibility is related to diet breadth and foraging techniques. 

**P2 alternative 1:** If the flexibility manipulation does not work in that those individuals in the experimental condition do not decrease their reversal learning speeds more than control individuals, then we will rely on the general individual variation in flexibility and how it relates to foraging in the wild (as in P1).

**P3:** The proportion of a grackle's diet that is human foods and the proportion of their foraging techniques involving human foods is higher for the more flexible individuals, who will consistently occur in locations closer to known outdoor human food locations like picnic areas and outdoor cafe seating (measured as the repeatability of the individual's distance from cafes across multiple separate focal follows) OR who will occupy a home range that contains more outdoor human food locations. For the diet, this is potentially due to A) having stayed in their parent's home range (i.e., they eat human food because it happens to be more prevalent in their home range than in other home ranges; local specialization) or B) because these individuals move around to seek out such opportunities (potentially seeking out habitat edges within their population). For the foraging techniques, this is potentially due to human foods and their packaging changing at a faster rate than natural foods and prey items and their accessibility. Foods  eaten and foraging techniques used will be recorded during focal follows. Because this species is highly associated with human-modified landscapes, it is likely that consuming human foods is part of the reason for this association, and that flexible individuals are better at solving these human-made "puzzle boxes" to access food.

**P3 alternative 1:** There is no correlation between an individual's flexibility and the proportion of human foods in their diet, potentially because A) their daily range sizes encompass many different food resources, including human foods (though they are likely not specialized on human foods), and B) some less flexible individuals might specialize on human foods.

**P3 alternative 2:** There is a negative correlation between an individual's flexibility and the proportion of human foods in their diet, potentially because some of the less flexible individuals might specialize on human foods, thus increasing their consumption above that of the more flexible individuals.

### H2: [Behavioral flexibility](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md) [see @mikhalevich_is_2017 for a detailed definition] is related to social behavior (measured year-round with focal follows using this [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing)) in wild individuals. Flexibility is measured in aviaries using two paradigms: reversal learning and switching between options on a multi-access box. To give an example of the types of social relationships this sexually dimorphic species engages in, they forage and roost socially [@selander1961analysis] and they have a non-faithful-male frank polygynous mating system [@johnson2000male]. In terms of male social relationships, @johnson2000male found during the breeding season in a population in Texas that one or more territorial males defend a territory with several nests from females, that non-territory holding resident males will queue to gain access to a territory, and that transient males move from colony to colony. There could be varying needs for males to manage their relationships with each other in breeding and non-breeding seasons, and flexibility could potentially play a role in such management.

**P4** Flexible individuals are more likely to have a greater number of bonds OR stronger bonds with others, in particular with individuals who are less related, potentially because they are better able to adjust their behavior to that of an affiliate. Social bonds are measured using the focal follow method to sample affiliative and aggressive behaviors.

**P4 alternative 1:** Individual flexibility is not related to the number or strength of social bonds, potentially because all individuals are able to form bonds with like individuals, including the less flexible individuals.

**P4 alternative 2:** Flexible individuals may have fewer affiliates or be less likely to regularly affiliate with the same individuals, potentially because they frequently change their behavior and are difficult to associate with. We are not able to test this alternative in this study, but could propose experimental designs for future research if this alternative is supported by the data.


# Methods {-}

Please see our preregistration that received in principle acceptance at PCI Ecology [PDF](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforagingPassedPreStudyPeerReviewOn6Aug2019.pdf) for the preregistered methods. We include here a summary of the methods and describe the deviations from the preregistration. 

## Planned sample and data collection stopping rule

Great-tailed grackles (n > 200) were caught in the wild at three field sites across their geographic range: the center of their original range (at a site to be determined in Central America), the middle of the northward expanding edge (Tempe, Arizona USA), and on the northern expanding edge (Sacramento, California USA). Individuals were identified using colored leg bands in unique combinations, their data collected (blood, feathers, and biometrics), and then they were released back to the wild. Some individuals (64-100, minimum 60) were brought temporarily into aviaries for behavioral testing, and then released back to the wild where the data for this study were collected. We will stop collecting data in April 2023 when the current funding ends, or after data have been collected at all three field sites, whichever date comes first.

 - **Deviation from the plan:** We originally planned to collect data from three field sites: the middle of the northward expanding edge (Tempe, Arizona), on the northern expanding edge (this ended up being in Sacramento, California), and at a site in the center of their original range (Central America). We ended up not being able to run the Central American site because the research station we were planning on using as the base for the site was exposed for having decades of sexual abuse toward women. We did not feel comfortable being at that station or bringing our business there, and it was too late to find another site because they take years to set up. Therefore, we have data only from two field sites and not three. This also means our sample size was not >200 grackles as originally planned. Our sample size ended up being 66 grackles with focal follow data in Arizona and 32 grackles in California, for a total of 98. We had also planned on bringing at least 60 of these grackles into the aviaries for behavioral choice tests. Of the grackles we brought into the aviaries, 49 (20 in Arizona and 19 in California) ended up completing their reversal learning experiment. We stopped collecting data in December 2022 when the California field site's data collection was complete.

## Open materials

 - [Ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing) for Prim8

 - [Individuals](https://docs.google.com/spreadsheets/d/1Lr0pwsmdnpVM8X2Fyoj9EIGa3zOY1WCZlntW7e0Ui_Y/edit?usp=sharing) for Prim8

 - [Protocol](https://docs.google.com/document/d/1SMUy43qRd52BBTZM5Oe2hpSExBLRAC6iUVyGvrAlgqs/edit?usp=sharing) for cleaning the focal follow data

## Open data

The data, scripts, and code are available at the Knowledge Network for Biocomplexity's data repository [@logan2023flexforagingdata].


## Dependent variables

***P1-P2***

1) Number of different foods eaten in the first X minutes (X=the sum of the total observation time per individual, using the individual who had the lowest sum to equalize observation time across individuals)

2) Number of foraging techniques used (based on Table 1 in @overington2009technical) in the first X minutes (X=the sum of the total observation time per individual, using the individual who had the lowest sum to equalize observation time across individuals)

One model will be run per dependent variable.

***P1 alternative 2 additional analysis: flexible = more valuable food types***

Food type (listed under the What modifier in the Eat behavior in the [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing))

***P3: flexible = more human foods***

1) Proportion of diet per individual that is human food

2) Distance to outdoor human food areas during focal follows

3) Number of outdoor human food areas within the home range

***P4: flexible = a greater number of bonds or stronger bonds***

1) Strength of the maximum bond (calculated as the half-weight index based on association behavior during focal follows. See Analysis Plan > P4 for a complete description). 

2) Individual strength (the sum of all bonds an individual has; @wey2008social)

3) Individual degree (maximum number of other individuals that the focal subject associated with; @wey2008social).

4) Male shares territory with another male: yes, no

5) Relatedness for the strongest bond (measured following the protocol in @thrasher2018double to estimate pairwise relatedness between all individuals based on the extent of sharing of genetic variants as determined by ddRADseq)

## Independent variables

***P1-P4***

1) Flexibility 1: **Number of trials to reverse** a preference in the last reversal (in the reversal learning experiment) an individual experienced (individuals in the flexibility control group only experience 1 reversal so this data will come from their first and only reversal; individuals in the flexibility manipulation group experience serial reversals until they pass a certain criterion, therefore we will only use data from their most recent reversal). An individual is considered to have a preference if it chose the rewarded option at least 17 out of the most recent 20 trials, with a minimum of 8 or 9 correct choices out of 10 on the two most recent sets of 10 trials). See behavioral flexibility [preregistration](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md).

2) Flexibility 3: If the number of trials to reverse a preference does not positively correlate with the number of trials to attempt or solve (meet criterion) new loci on the multi-access box (an additional measure of behavioral flexibility), then the **number of trials to solve** and the **number of trials to attempt** a new option on the multi-access box will be additional dependent variables. See behavioral flexibility [preregistration](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md).

3) Flexibility 4: This measure is currently being developed and is intended be a more accurate representation of all of the choices an individual made, as well as accounting for the degree of uncertainty exhibited by individuals as preferences change. It will be based on a Bayesian estimate of the reduction in error across trials estimated from the number of correct choices from the beginning of each reversal. If this measure more effectively represents flexibility (determined using a modeled dataset and not the actual data), we may decide to solely rely on this measure and not use flexibility measures 1 through 3. If this ends up being the case, we will modify the code in the analysis plan below to reflect this change.

4) Flexibility manipulation: control, manipulated

5) Dominance rank: measured as the number of wins minus the number of losses, divided by the sum of wins + losses. This calculation will give each individual a dominance rank number, and we will order individuals by rank from lowest to highest to create a dominance hierarchy.

6) Condition: aviary-tested, not-aviary-tested

7) ID (random effect because multiple measures per individual)

8) Population: center (Central America), middle (Arizona), edge (northern US) (random effect because each population might have a different slope)

***P1 alternative 2 additional analysis: flexible = more valuable food types***

Flexibility 1 (as above)



## ANALYSIS PLAN

We did not exclude any data. When missing data occurred, the existing data for that individual was included in the analyses for the tests they completed. Analyses were conducted in R [current version `r getRversion()`; @rcoreteam], using several R packages: @kableextra, @stargazer, @hadfield2010mcmcglmm, @mumin, @rethinking2020, @rstan, @formatr, @rstudioapi, @rcpp, @ggplot2, knitr [@xie2018knitr; @xie2017dynamic; @xie2013knitr], @dplyr, @cmdstanr, posterior [@burkner2020posterior], cowplot [@wilkecowplot], bayesplot [@gabry2019visualization], irr [@gamer2012package], psych [@revelle2014psych; @psych], @reactable, DHARMa [@hartig2019dharma], lme4 [@lme4; @bates2012lme4]. When there was more than one experimenter within a test, experimenter was added as a random effect to account for potential differences between experimenters in conducting the tests. When there are no differences between models including or excluding experimenter as a random effect, then we use the model without this random effect for simplicity. We analyzed data for ffales and males separately because each sex has a distinct natural history.

 - **Deviation from the plan:** We removed experimenter (random variable) from all analyses because the interobserver reliability scores were so high, indicating there was no difference between experimenters, therefore we could keep our models simpler by leaving this variable out.

### Calculating the independent variable Flexibility 4 (phis and lambdas)

We used the phis and lambdas from each bird's initial discrimination plus first reversal (for the CA birds and AZ control birds) or the last two reversals (for the AZ manipulated birds). We calculated the phis and lambdas using the model and code from @lukas2022flexmanip, and entered these into the data sheets used for the analyses in the results section.

```{r phislambdas, eval=FALSE}
### Code below copied from Lukas et al. 2022. Using OBSERVED (not simulated) data from GTGR in Woodland/Sacramento and Tempe

# These are the phis and lambas for the AZ birds using their LAST 2 switches
eachbirdslearningparameters<-read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexmanip_ArizonaBirds_EstimatedPhiLambdaReversalLearning.csv"), header=T, sep=",", stringsAsFactors=F)


# The code below gets the phis and lambdas for the first 2 switches, so only use it to calculate the CA data
# We want to estimate lambda and phi differently. For the initial values, we combine the data from the first association learning with the first reversal.
dflex <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/gxpopbehavhabitat_data_reversegtgr.csv"), header=T, sep=",", stringsAsFactors=F) 

library(rstan)
library(rethinking)
library(cmdstanr)
library(posterior)

# If you have cmdstan installed, use the following:
# set_ulam_cmdstan(TRUE)

# PREPARE reversal learning data
#exclude birds that did not finish the reversal experiment
dflex <- dflex[!dflex$ID=="Chocolate" & !dflex$ID=="Xango" & !dflex$ID=="Wachil" & !dflex$ID=="Talingo" & !dflex$ID=="Quiscalus" & !dflex$ID=="Churro" & !dflex$ID=="Sopapilla" & !dflex$ID=="Tres Leches" & !dflex$ID=="Merengue" & !dflex$ID=="Carlota" & !dflex$ID=="Changa" & !dflex$ID=="Urraca" & !dflex$ID=="Bacmut bacni" & !dflex$ID=="Zanate",] 

#include only those trials where the bird made a choice (0 or 1)
dflex <- subset(dflex, dflex$CorrectChoice != -1) #reverse number. 0=initial discrimination
dflex$Reversal <- as.integer(dflex$Reversal)

dflex$Correct <- as.integer(dflex$CorrectChoice)
dflex$Trial <- as.integer(dflex$Trial)
#exclude NAs from the CorrectChoice column
dflex <- subset(dflex, is.na(dflex$Correct) == FALSE)

# Want data ONLY from initial learning and first reversal to determine phi and lambda at the beginning. This is for all birds, including those that did not experience the reversal manipulation experiment
reduceddata <- matrix(ncol=ncol(dflex),nrow=0)
reduceddata <- data.frame(reduceddata)
for (i in 1:length(unique(dflex$ID))) {
  thisbird <- unique(dflex$ID)[i]
  thisbirddata <- dflex[dflex$ID==thisbird,]
  thisbirdslastreversal <- thisbirddata[thisbirddata$Reversal %in% c(0,1),]
  reduceddata <- rbind(reduceddata,thisbirdslastreversal)
}
dflex_beginning <- reduceddata

# We want to remove the birds who did not complete at least the first reversal
birdscompletedreversal<-unique(dflex_beginning[dflex_beginning$Reversal==1,]$ID)

dflex_beginning<-dflex_beginning[dflex_beginning$ID %in% birdscompletedreversal,]

length(unique(dflex_beginning$ID)) #39 birds

#Construct Choice variable to match with how the STAN model is set up.
dflex_beginning$Choice <- NA
for (i in 1: nrow(dflex_beginning)) {
  if (dflex_beginning$Reversal[i] %in% seq(0, max(unique(dflex_beginning$Reversal)), by = 2)){
    
    if (dflex_beginning$Correct[i] == 1){
      dflex_beginning$Choice[i] <- 1
    } else {
      dflex_beginning$Choice[i] <- 2
    } 
  } else {
    if (dflex_beginning$Correct[i] == 1){
      dflex_beginning$Choice[i] <- 2
    } else {
      dflex_beginning$Choice[i] <- 1
    } 
  }
}
dflex_beginning <- dflex_beginning[with(dflex_beginning, order(dflex_beginning$ID)), ]

#enter the column name for the individual's name here (ID) and then we will change it to small "id" to match the stan code below
colnames(dflex_beginning)[colnames(dflex_beginning)=="ID"]<-"id"

# Sort birds alphabetically; we do this so we can later on rematch the names to the numerical ids.
dflex_beginning <- dflex_beginning[with(dflex_beginning, order(dflex_beginning$id)), ]

# Store the bird names
birdnames<-unique(dflex_beginning$id)

# Convert bird names into numeric ids
dflex_beginning$id <- as.numeric(as.factor(dflex_beginning$id))

# Select only the columns that are of relevance. In particular, remove any additional columns that contain missing values.
dflex_beginning<-dflex_beginning[,c("id","Reversal","Trial","CorrectChoice","Correct","Choice")]

# Prepare the data in the setup for the STAN model, as a list
datinitialandfirstreversal <- as.list(dflex_beginning)
datinitialandfirstreversal$N <- nrow(dflex_beginning)
datinitialandfirstreversal$N_id <- length(unique(dflex_beginning$id))

datinitialandfirstreversal$Reversal<-as.numeric(as.factor(datinitialandfirstreversal$Reversal))
datinitialandfirstreversal$CorrectChoice<-as.numeric(as.factor(datinitialandfirstreversal$CorrectChoice))


# The STAN model is set up to have the initial attraction for each option set to 0.1, and that individuals only learn the reward of the option they chose in a given trial.
reinforcement_model_nonzeroattraction_alternativepriors <- "

data{
   int N;
   int N_id;
   int id[N];
   int Trial[N];
   int Choice[N];
   int Correct[N];
}

parameters{
  real logit_phi;
  real log_L;

  // Varying effects clustered on individual
  matrix[N_id,2] v_ID;
}

model{
matrix[N_id,2] A; // attraction matrix

logit_phi ~  normal(0,1);
log_L ~  normal(0,1);

// varying effects
to_vector(v_ID) ~ normal(0,1);

// initialize attraction scores

for ( i in 1:N_id ) {
A[i,1] = 0.1; A[i,2] = 0.1;
}

// loop over Choices

for ( i in 1:N ) {
vector[2] pay;
vector[2] p;
real L;
real phi;

// first, what is log-prob of observed choice

L =  exp(log_L + v_ID[id[i],1]);
p = softmax(L*A[id[i],1:2]' );
Choice[i] ~ categorical( p );

// second, update attractions conditional on observed choice

phi =  inv_logit(logit_phi + v_ID[id[i],2]);
pay[1:2] = rep_vector(0,2);
pay[ Choice[i] ] = Correct[i];
A[ id[i] , Choice[i] ] = ( (1-phi)*(A[ id[i] , Choice[i] ]) + phi*pay[Choice[i]]);

}//i
}
"

# RUN MODEL OPTION 1: The first way to run the model is directly through rstan. This does not work on some computers because of the way the interfacing runs. If it doesn't work on your computer, use Option 2 below, which uses cmdstan
m_initialandreversal <- stan( model_code =  reinforcement_model_nonzeroattraction_alternativepriors, data=datinitialandfirstreversal ,iter = 5000, cores = 4, chains=4, control = list(adapt_delta=0.9, max_treedepth = 12))

sinitialandreversal <- extract.samples(m_initialandreversal)
initialandreversal_lambda <- sapply(1 : datinitialandfirstreversal$N_id, function(x) exp( mean(sinitialandreversal$log_L) + mean(sinitialandreversal$v_ID[ ,x, 1])))
initialandreversal_phi <- sapply(1 : datinitialandfirstreversal$N_id, function(x) inv_logit( mean(sinitialandreversal$logit_phi) + mean(sinitialandreversal$v_ID[ ,x, 2])))

plot(initialandreversal_phi~initialandreversal_lambda)

# Combine the extracted values in a dataframe, and link them back to the id of the individuals
birds_phi_lambda<-matrix(ncol=3,nrow=length(birdnames))
birds_phi_lambda<-as.data.frame(birds_phi_lambda)
colnames(birds_phi_lambda)<-c("id","phi","lambda")
birds_phi_lambda$id<-birdnames
birds_phi_lambda$phi<-initialandreversal_phi
birds_phi_lambda$lambda<-initialandreversal_lambda
#here is the table with the phis and lambdas!
birds_phi_lambda 
#DONE with Option 1


# RUN MODEL OPTION 2: This alternative setup uses cmdstanr to run the model. It first needs to create an executable on your computer for the model for which you need to specify the path to where it can find the relevant compilers.
currentlocation<-getwd()
cmdstanlocation <- cmdstan_path()
setwd(cmdstanlocation)

# access the output file created by the model running the reinforcement model / reinforcement_model_nonzeroattraction_alternativepriors
write(reinforcement_model_nonzeroattraction_alternativepriors,file="myowntrial.stan")
file <- file.path(cmdstan_path(), "myowntrial.stan")
mod <- cmdstan_model(file)
options(mc.cores=4)

# RUN the model
fit_initialandfirstreversal <- mod$sample(
  data = datinitialandfirstreversal,
  chains = 4,
  parallel_chains = 4,
  refresh = 500
)

# Show the 90% compatibility intervals for the association between latency to switch loci on the plastic multi-access box and lambda and phi, and the interaction between lambda and phi from the reinforcement learning model
drawsarray<-fit_initialandfirstreversal$draws()
drawsdataframe<-as_draws_df(drawsarray)
drawsdataframe<-data.frame(drawsdataframe)
initialandreversal_lambda <- sapply(1 : datinitialandfirstreversal$N_id, function(x) exp( mean(drawsdataframe$log_L) + mean(drawsdataframe[,x+3]))) 
initialandreversal_phi <- sapply(1 : datinitialandfirstreversal$N_id, function(x) inv_logit( mean(drawsdataframe$logit_phi) + mean(drawsdataframe[,x+3+length(unique(datinitialandfirstreversal$id))])))

# Remove the stan command line file we created for this particular model from your computer
fn<-"myowntrial"
file.remove(fn)

# Reset your working directory to what it was before we ran the model
setwd(currentlocation)

# Combine the extracted values in a dataframe, and link them back to the id of the individuals
birds_phi_lambda<-matrix(ncol=3,nrow=length(birdnames))
birds_phi_lambda<-as.data.frame(birds_phi_lambda)
colnames(birds_phi_lambda)<-c("id","phi","lambda")
birds_phi_lambda$id<-birdnames
birds_phi_lambda$phi<-initialandreversal_phi
birds_phi_lambda$lambda<-initialandreversal_lambda
#here is the table with the phis and lambdas!
birds_phi_lambda 
#DONE with Option 2
```

### Data checking

The data will be checked for overdispersion, underdispersion, zero-inflation, and heteroscedasticity with the DHARMa R package [@hartig2019dharma] following methods by [Hartig](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html). Note: DHARMa doesn't support MCMCglmm, therefore we will use the closest supported model: glmer from the R package lme4 [@lme4].

### Ability to detect actual effects

To begin to understand what kinds of effect sizes we will be able to detect given our sample size limitations and our interest in decreasing noise by attempting to measure it, which increases the number of explanatory variables, we will revise the Analysis Plan after reading @statrethinkingbook. We currently don’t have any estimates for any of our measured variables because these tests have never been done in grackles and we have not encountered previous research that has manipulated flexibility in this way. We will use Bayesian analyses to estimate our likely confidence in the results given simulated data. We will revise this preregistration to include these new analyses before conducting the planned analyses on our actual data. Based on the simulations, we might adapt the number of focal follows per individual or decide to collect much more data just with the aviary-tested birds to increase the amount of information per individual.

## Deviations from the prepregistration

**In the middle of data collection**

 - Because all models only include aviary-tested birds for our analyses, Condition (IV6), which indicates whether a bird is aviary-tested or not-aviary-tested, does not need to be included as an independent variable as we originally indicated. (13 July 2022)
 - The Flexibility 4 independent variable calculates the phi and lambda of aviary-tested birds, and as such, it is redundant to include IV4: Flexibility manipulation as an independent variable in the analysis. (13 July 2022)
 - Initially, the dependent variables for P1 and P2 calculated the number of different foods eaten and the number of foraging techniques used in the first X minutes of a focal follow. To equalize observation time across individuals, X minutes was the total observation time using the individual with the lowest sum across all individuals. As we started to clean the data and prepare it for analysis, we noticed three individuals had no focal follows (sum focal time = 0) and the next lowest sum focal time was 497 seconds. The average sum focal time across all 38 individuals was 3024 seconds, leaving an excess of data that would be excluded given the originally prescribed calculation of the dependent variables. Therefore, we changed this to a proportion and divided the number of different foods eaten and the number of foraging techniques used by an individual with the sum observation time across that individual’s focal follows. The analysis for the P1 and P2 dependent variables accommodated this change by adjusting from a poisson to a binomial distribution. (3 August 2022)

## P1:


## P2: Flexibility manipulation and food types/foraging techniques

This dataset includes only the Arizona grackles who were in the flexibility manipulation (serial reversal learning of color preferences) or the control group (only one reversal). We approach this prediction with two different models because each presumes a different process that could lead to individuals showing more food types or foraging techniques during our focal observation time windows. 

The first model is a **binomial** that evaluates, of the known food types and foraging techniques, how many does an individual use. The model assumes every individual is able to eat all of the food types and use all of the foraging techniques, and it evaluates the probability of using a given food type or foraging technique at a given time. If there are any differences between the two groups (manipulated or control), they will appear at intermediate amounts of observation time. This is because, when an individual has not been observed for many seconds, it is improbable that it will have eaten/used more than one food type/foraging technique, and, if observed for long enough, one is likely to have seen all food types and foraging techniques being used even if an individual has a low probability of eating/using a given food type/foraging technique. This model takes the form of:

$tech_{i}$ ~ Binomial(10, $p$) *[likelihood]*,

logit($p$) ~ $\alpha_{i}$[$treatment$] + $\beta_{i}$$time$ *[model]*,

where $tech_{i}$ is the number of foraging techniques used (out of the total possible 10 foraging techniques that were observed across the populations) by individual, i, $p$ is the probability of using a given technique, $\alpha_{i}$ is the intercept (one per level of $treatment$: control and manipulated), and $\beta_{i}$ is the slope for the interaction with total number of seconds of observation $time$ for individual, i. Note that the model is the same when analyzing the number of food types eaten for each individual, $foods_{i}$, which replaces $tech_{i}$ in the above model, as well as replacing the 10 with the maximum of X food types eaten. 

The second model is a **Poisson** that evaluates how many food types or foraging techniques an individual knows. It assumes that an individual is equally likely to switch among food types or foraging techniques in a given amount of time, but, if there is a difference between the groups, the manipulated birds have a different total number of food types or foraging techniques from which they can choose. Here, any differences between the two groups (manipulated and control) are most visible when individuals are observed for a long time because this reveals how many food types and foraging techniques individuals know in total. This model takes the form of: 

$tech_{i}$ ~ Poisson($\lambda_{i}$) *[likelihood]*,

log($\lambda_{i}$) ~ $\alpha_{i}$[$treatment$] + $\beta_{i}$$time$ *[model]*,

where $tech_{i}$ is the number of foraging techniques used by individual, i, $\lambda_{i}$ is the expected rate of using a given technique per unit time, $\alpha_{i}$ is the intercept (one per level of $treatment$: control and manipulated), and $\beta_{i}$ is the slope for the interaction with total number of seconds of observation $time$ for individual, i. Note that the model is the same when analyzing the number of food types eaten for each individual, $foods_{i}$, which replaces $tech_{i}$ in the above model. 

For both models, we use contrasts to determine whether there is a difference between $treatment$’s and conclude that there is a difference if the 89% compatibility interval does not cross zero.


## P3:


## P4: Flexibility and social bonds

**Analysis:** A GLMM was conducted as in P1-P2.

To quantify social relationships, we will conduct at least four 10-minute focal follows on each subject spaced equally across breeding and non-breeding seasons. We will find subjects in the wild because we will attach radio transmitter tags to all grackles that are released from the aviaries upon completion of their test battery. To ensure we fully sample social and foraging behavior, we will prioritize conducting focal follows on these tagged grackles for which we have a much larger amount of individualized data, including multiple measures of flexibility. We will also sample many other color marked grackles that were never tested in the aviaries, and thus do not have measures of flexibility. By conducting focal follows on grackles that were not in captivity, we can verify that the time in captivity had no effect on grackle social behavior after release because aviary-tested birds should be indistinguishable from non-aviary-tested birds in these analyses.

To measure affiliative bonds, during each focal follow we will record when another grackle comes within one body length of the focal bird (and does not engage in aggressive interactions). In case we do not observe enough of these close associations, we will also record when another grackle comes within 3m of the focal subject (and does not engage in aggressive interactions). Finally, we will conduct a scan sample at the end of the follow to determine group size as the number of other grackles within 10m of the focal individual. Unmarked grackles that are seen in proximity of the focal individual will be recorded and included in the count of group size and individual degree (the number of unique associates), but because we cannot distinguish unmarked individuals from each other, we will exclude unmarked bird data from calculations of an individual’s summed bond strengths (see details in the next paragraph).  

We will also measure aggressive behavioral interactions, as indicated in our ethogram. The outcome of these dyadic interactions will be used to create our index of dominance (wins - losses / wins + losses). 

We will conduct subsequent follows on the same individual only when 3 or more weeks have passed since the previous focal follow to prevent temporal autocorrelation in behavior (@whitehead2008analyzing). From the data sheet of dyadic associations during focal follows, we will create a matrix of association strengths between all marked grackles by calculating the Half-Weight association index. This index determines association strength based on the proportion of observations in which two individuals are seen together versus separately, and accounts for bias arising from subjects that are more likely to be observed separately rather than together in the same group (@cairns1987comparison). From the matrix of association values, we will use the R package igraph (@csardi2006igraph) to create a social network, and calculate each individual’s strength (sum of all association values) and degree (maximum number of unique associates) values (@croft2008exploring).

Before analyzing degree and strength, we will determine if these values differ between breeding (Apr - Aug) and non-breeding seasons (Sept - Mar) because social associations could change as a result of breeding behaviors. If there is no difference, we will combine all data for the analyses described below. Neither of the social network metrics (strength or degree) varied by season (sexes combined), so we proceed with the analysis of the breeding and non-breeding season data combined (INSERT STATS THAT SHOW THIS).

```{r p4pt2season, eval = F}
### Social network values differ by season? ###
#Load social data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

#Exclude unbanded birds
ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 

ff1 <- subset(ff1, is.na(ff1$FocalBirdID) == FALSE) #257 banded-banded bird associations
ff1aff <- subset(ff1, ff1$BehavType == "affiliative") #171 affiliative (86 aggressive for use in dominance calculations)

# Recreate social network graphs with association data separated by season (breeding or non-breeding)
unique(ff1aff$Date) #Dates from our raw data of banded-banded bird affiliative associations from above

# separate Sites because breeding started earlier in AZ
ff_AZ = ff1aff[which(ff1aff$Site == "AZ"),]
ff_AZ$Date = as.Date(ff_AZ$Date, format = "%Y-%m-%d")
ffAZ_bs19 = ff_AZ[which(ff_AZ$Date > "2019-03-08" & ff_AZ$Date < "2019-09-01"),] #2019 breeding season = 9 Mar to 31 Aug
ffAZ_bs19$Season = "BS"
ffAZ_bs20 = ff_AZ[which(ff_AZ$Date > "2020-03-08" & ff_AZ$Date < "2020-09-01"),] #2020 breeding season
ffAZ_bs20$Season = "BS"
ffAZ_nbs = ff_AZ[which(ff_AZ$Date < "2019-03-08" | c(ff_AZ$Date > "2019-08-31" & ff_AZ$Date < "2020-03-08")),] # nonbreeding season = 1 Sept 2019 - 8 Mar 2020
ffAZ_nbs$Season = "NBS"

ffsAZ = rbind(ffAZ_nbs,ffAZ_bs19,ffAZ_bs20)

#now repeat in CA
ff_CA = ff1aff[which(ff1aff$Site == "CA"),]
ff_CA$Date = as.Date(ff_CA$Date, format = "%Y-%m-%d")
ffCA_bs21 = ff_CA[which(ff_CA$Date > "2021-03-31" & ff_CA$Date < "2021-09-01"),] #2021 breeding season = 1 Apr to 31 Aug
ffCA_bs21$Season = "BS"
ffCA_bs22 = ff_CA[which(ff_CA$Date > "2022-03-29" & ff_CA$Date < "2022-09-01"),] #2022 breeding season = 30 Mar to 31 Aug
ffCA_bs22$Season = "BS"
ffCA_nbs = ff_CA[which(ff_CA$Date > "2021-08-31" & ff_CA$Date < "2022-03-30"),] # nonbreeding season = 1 Sept 2021 - 29 Mar 2022
ffCA_nbs$Season = "NBS"

ffsCA = rbind(ffCA_nbs,ffCA_bs21,ffCA_bs22)

#combine sites together again
ffs = rbind(ffsAZ,ffsCA)
#make new network graphs and re-calculate sna metrics by season
ffs2 = aggregate(TimeStamp ~ Date + FocalBirdID + NonFocalBirdID + Site + Season, data = ffs, FUN = "max") #only one observation of banded-banded pair per sampling period is allowed, for 111 banded-banded associations

#but only the following grackles (n = 15) had at least 2 follows per season: Burrito, Chalupa, Chilaquile, Diablo, Fideo, Taco, Taquito, Yuca, Polvorones, Dulce de Leche, Zapote Negro, Galandra, Cuervo, Kel, Cutuy
ffs3 = ffs2[which(ffs2$FocalBirdID == "Burrito" | ffs2$FocalBirdID == "Chilaquile" | ffs2$FocalBirdID == "Diablo" | 
                             ffs2$FocalBirdID == "Fideo" |  ffs2$FocalBirdID == "Taco" | ffs2$FocalBirdID == "Taquito" | 
                             ffs2$FocalBirdID == "Yuca" | ffs2$FocalBirdID == "Chalupa" | 
                             ffs2$FocalBirdID == "Polvorones" | ffs2$FocalBirdID == "Dulce de Leche" | ffs2$FocalBirdID == "Zapote Negro" | 
                             ffs2$FocalBirdID == "Cuervo" | ffs2$FocalBirdID == "Galandra" | ffs2$FocalBirdID == "Cutuy" | 
                             ffs2$FocalBirdID == "Kel"),]
#this decreases the sample size from 111 banded-banded associations to 27. And, the majority of these are in the non-breeding season (only 5 breeding season)

#Create an edgelist - a two column matrix of birds seen together
els.nb = ffs3[which(ffs3$Season == "NBS"),c(2:3)] #FocalBirdID and NonFocalBirdID in non-breeding season only (because 5 breeding season associations do not need to be symmetrized)
#since these are undirected associations, symmetrize the associations so all are in the same order and repeat pairs can be identified
colnames(els.nb)[c(1,2)]=c("ID.1","ID.2")
els.nb$ID.1 = as.character(els.nb$ID.1)
els.nb$ID.2 = as.character(els.nb$ID.2)
for (i in 1:nrow(els.nb)) {
  tmp = els.nb[i, c("ID.1", "ID.2")]
  tmp = tmp[,sort.list(tmp)] #produces warning messages, but works
  els.nb[i, "ID.1"] = tmp[,1]
  els.nb[i, "ID.2"] = tmp[,2]
}

#calculate edge weights using the half-weight index by quantifying the number of times two birds are seen together (x), the number of times bird 1 is seen without bird 2 (Y.1), and the number of times bird 2 is seen without bird 1 (Y.2)
els.nb$count = 1
x = aggregate(count ~ ID.1 + ID.2, data = els.nb, FUN = "sum") #how many times are bird 1 and bird 2 observed together in each season
colnames(x)[3]="x"
#add back in season and site variables
x$Season = "NBS"
x$Site = ifelse(x$ID.1 == "Camote" | x$ID.1 == "Cuervo" | x$ID.1 == "Cutuy" | x$ID.1 == "Galandra", "CA", "AZ")
x2 = ffs3[which(ffs3$Season == "BS"),-c(1,6)]
colnames(x2)[c(1:2)] = c("ID.1","ID.2")
x2$x = 1 #no repeated observations of the same two birds together across follows
x = rbind(x, x2) #combine with breeding season association data

tmp = ffs3[,c(2,4:5)] #FocalBirdID, Site, Season
colnames(tmp)[1] = "ID"
tmp2 = ffs3[,c(3:5)] #NonFocalBirdID, Site, Season
colnames(tmp2)[1] = "ID"
y = rbind(tmp, tmp2)
y$count = 1
y = aggregate(count ~ ID + Site + Season, data = y, FUN = "sum") #how many times each bird is seen individually each season
colnames(y)[4] = "y"

colnames(y)[1] = "ID.1" 
hwis = merge(x,y, by = c("ID.1","Site","Season"), all = T)
hwis$Y.1 = hwis$y - hwis$x #the number of times bird 1 was seen without bird 2 by season
hwis = hwis[,-6]
colnames(y)[1] = "ID.2"
hwis = merge(hwis,y, by = c("ID.2","Site","Season"), all = T)
hwis$Y.2 = hwis$y - hwis$x #the number of times bird 2 was seen without bird 1 by season
hwis = hwis[-which(is.na(hwis$x)),-7] #data frame ready for half-weight index equation
hwis$hwi = hwis$x/(0.5*(hwis$Y.1 + hwis$Y.2)+hwis$x)

library(igraph)
### Breeding season network
Y2bs = as.matrix(hwis[which(hwis$Season == "BS"),])
labels <- unique( c(Y2bs[,1], Y2bs[,4]) )
A2bs <- matrix(0, length(labels), length(labels))
rownames(A2bs) <- colnames(A2bs) <- labels
A2bs[ Y2bs[,c(1,4)] ] <- as.numeric( Y2bs[,8] )
Ya2bs = graph.adjacency(A2bs, weighted = T, mode = "max", diag = F)
### Nonbreeding season network
Y2nbs = as.matrix(hwis[which(hwis$Season == "NBS"),])
labels <- unique( c(Y2nbs[,1], Y2nbs[,4]) )
A2nbs <- matrix(0, length(labels), length(labels))
rownames(A2nbs) <- colnames(A2nbs) <- labels
A2nbs[ Y2nbs[,c(1,4)] ] <- as.numeric( Y2nbs[,8] )
Ya2nbs = graph.adjacency(A2nbs, weighted = T, mode = "max", diag = F)



### Now we can quantify social network metrics by season ###
### Calculate MaxBondStrength
bonds1 = hwis[,c(1,3,8)] #ID.2, Season, hwi
colnames(bonds1)[1] = "ID"
bonds2 = hwis[,c(3,4,8)] #ID.1, Season, hwi
colnames(bonds2)[2] = "ID"
bonds = rbind(bonds1, bonds2)
maxBond2 = aggregate(hwi ~ ID + Season, data = bonds, FUN = "max")

#include only grackles that had the minimum number of focal follows
maxBond2 = maxBond2[which(maxBond2$ID == "Burrito" | maxBond2$ID == "Chilaquile" | maxBond2$ID == "Diablo" | 
                             maxBond2$ID == "Fideo" |  maxBond2$ID == "Taco" | maxBond2$ID == "Taquito" | 
                             maxBond2$ID == "Yuca" | maxBond2$ID == "Chalupa" | 
                             maxBond2$ID == "Polvorones" | maxBond2$ID == "Dulce de Leche" | maxBond2$ID == "Zapote Negro" | 
                             maxBond2$ID == "Cuervo" | maxBond2$ID == "Galandra" | maxBond2$ID == "Cutuy" | 
                             maxBond2$ID == "Kel"),]


### Calculate IndividualStrength
strength.bs = strength(Ya2bs, V(Ya2bs))
strength.bs = data.frame(names(strength.bs),strength.bs)
colnames(strength.bs) = c("ID","strength")
strength.bs$Season = "BS"
strength.nbs = strength(Ya2nbs, V(Ya2nbs))
strength.nbs = data.frame(names(strength.nbs),strength.nbs)
colnames(strength.nbs) = c("ID","strength")
strength.nbs$Season = "NBS"
strength2 = rbind(strength.bs,strength.nbs)

#include grackles that had the minimum number of focal follows: 
strength2 = strength2[which(strength2$ID == "Burrito" | strength2$ID == "Chilaquile" | strength2$ID == "Diablo" | 
                             strength2$ID == "Fideo" |  strength2$ID == "Taco" | strength2$ID == "Taquito" | 
                             strength2$ID == "Yuca" | strength2$ID == "Chalupa" | 
                             strength2$ID == "Polvorones" | strength2$ID == "Dulce de Leche" | strength2$ID == "Zapote Negro" | 
                             strength2$ID == "Cuervo" | strength2$ID == "Galandra" | strength2$ID == "Cutuy" | 
                             strength2$ID == "Kel"),]

### Calculate Degree
degree.bs <- igraph::degree(Ya2bs,V(Ya2bs))
degree.bs = data.frame(names(degree.bs),degree.bs)
colnames(degree.bs) = c("ID","degree")
degree.bs$Season = "BS"
degree.nbs <- igraph::degree(Ya2nbs,V(Ya2nbs))
degree.nbs = data.frame(names(degree.nbs),degree.nbs)
colnames(degree.nbs) = c("ID","degree")
degree.nbs$Season = "NBS"
degree2 = rbind(degree.bs,degree.nbs)

#include grackles that had the minimum number of focal follows: 
degree2 = degree2[which(degree2$ID == "Burrito" | degree2$ID == "Chilaquile" | degree2$ID == "Diablo" | 
                             degree2$ID == "Fideo" |  degree2$ID == "Taco" | degree2$ID == "Taquito" | 
                             degree2$ID == "Yuca" | degree2$ID == "Chalupa" | 
                             degree2$ID == "Polvorones" | degree2$ID == "Dulce de Leche" | degree2$ID == "Zapote Negro" | 
                             degree2$ID == "Cuervo" | degree2$ID == "Galandra" | degree2$ID == "Cutuy" | 
                             degree2$ID == "Kel"),]

### Analyze sna metrics as a function of season
### We only have 7 data points from the breeding season with no variability in the social network metrics. Therefore, we do not think we have an adequate breeding season sample to be able to compare social network metrics across season. 
### There could be a season difference that we are unable to detect with our sample size and as preregistered, we will proceed using only the non-breeding season data.


# library(MCMCglmm)
# prior = list(R=list(R1=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0)))
# 
# # hwi = half-weight index, the social association indices that we said we would use to weight the edges in the social network analysis
# hist(log(maxBond2$hwi))
# seasonmb = MCMCglmm(log(hwi) ~ Season, random=~ID, family="gaussian", data=maxBond2, verbose=F, prior=prior, nitt=300000, thin=200, burnin=30000)
# autocorr(seasonmb$Sol) #Did fixed effects converge?
# autocorr(seasonmb$VCV) #Did random effects converge?
# summary(seasonmb) 
# boxplot(hwi~Season,data = maxBond2)
# 
# hist(log(strength2$strength))
# seasons = MCMCglmm(log(strength) ~ Season, random=~ID, family="gaussian", data=strength2, verbose=F, prior=prior, nitt=200000, thin=200, burnin=30000)
# autocorr(seasons$Sol) #Did fixed effects converge?
# autocorr(seasons$VCV) #Did random effects converge?
# summary(seasons) 
# boxplot(strength~Season,data = strength2)
# 
# prior = list(R=list(R1=list(V=1,nu=0)))
# hist(degree2$degree)
# degree2$Season <- as.factor(degree2$Season) #factor to see if it makes the fixed effects converge. It helped
# seasond = MCMCglmm(degree ~ Season, family="poisson", data=degree2, verbose=F, prior=prior, nitt=300000, thin=1000, burnin=50000)
# autocorr(seasond$Sol) #Did fixed effects converge? No so factored season, increased nitt/burnin, decreased thin and it worked
# autocorr(seasond$VCV) #Did random effects converge?
# summary(seasond) 
# boxplot(degree~Season,data = degree2)
```

Social network data are not independent (@croft2011hypothesis), therefore, to determine whether individuals are associating non-randomly based on flexibility (i.e., association strength between two grackles is larger than would be expected by random chance), we will compare our model results to those obtained from random networks. To make a random network, we will use the R package sna (@butts2016sna) and the function “rperm” to randomly rearrange the association strengths (edges) of grackles in our network. We will conduct this edge randomization (called permutation) 10,000 times to create our sample of random networks. We will then re-calculate our dependent variables from the random networks and re-run the same models (as in @croft2011hypothesis and @whitehead2005testing). We will conclude that social bonds are significantly related to flexibility if the coefficients describing the relationship in our observed data are in the top 2.5% and bottom 2.5% of the coefficients resulting from models run on the random networks.


## P5: Flexibility and immigration

The model takes the form of:

$pimmigrant_{i}$ ~ Binomial(1, $p$) *[likelihood]*,

logit($p$) ~ $\alpha_{i}$[habitat] + $\beta_{i}$$\phi$ *[model]*,

where $pimmigrant_{i}$ is the probability of being an immigrant for each individual i, $p$ is the probability of being an immigrant, $\alpha_{i}$ is the intercept (one per observation), and $\beta_{i}$ is the slope for the interaction with $\phi$. Note that the model is the same when analyzing $\lambda$, which replaces $\phi$ in the above model. We determine that $\phi$ and $\lambda$ are strongly related to the probability of being an immigrant if the compatibility interval for the slope does not cross zero.


## P6: Flexibility and habitat diversity

The model takes the form of:

$div_{i}$ ~ Normal($\mu_{i}$, $\sigma_{i}$) *[likelihood]*,

log($\mu_{i}$) ~ $\alpha$ + $\beta_{p}$$\phi$ + $\beta_{r}$$rank$ *[model]*,

where $div_{i}$ is the Shannon Diversity Index [see @vegan for mathematical definition] for each individual i, $\mu_{i}$ is the mean and $\sigma_{i}$ is the standard deviation, $\alpha$ is the intercept, $\beta_{p}$ is the slope for the interaction with $\phi$, and $\beta_{r}$ is the slope for the interaction with dominance $rank$. Note that the model is the same when analyzing $\lambda$, which replaces $\phi$ in the above model. We determine that $\phi$ and $\lambda$ are strongly related to the diversity index if the compatibility interval for the slope does not cross zero.


## P7: human population density across sites

Human population density (population per square mile) is obtained from the U.S. Census Bureau for Tempe, Arizona (https://www.census.gov/quickfacts/fact/table/tempecityarizona,US/POP060220), Woodland, California (https://www.census.gov/quickfacts/fact/table/woodlandcitycalifornia/POP060220), and Sacramento, California (https://www.census.gov/quickfacts/fact/table/sacramentocitycalifornia,tempecityarizona,US/POP060220) for 2010 and 2020 (the Census data), and from the U.S. Census American Community Survey (https://www.opendatanetwork.com/entity/1600000US0664000-1600000US0686328-1600000US0473000/Sacramento_CA-Woodland_CA-Tempe_AZ/geographic.population.density?year=2018&ref=compare-entity) for the rest of the years from 2009 to 2018 (note that there is no data for 2019). The Woodland population consists of two trapping locations: one in Woodland and the other in Sacramento. The two locations represent the same population because some of the same individuals are found at both locations. We design a bespoke Bayesian model to determine whether there are differences between populations and we conduct a simulation to determine how much of a difference between the means (at least 250 people per square mile) would result in there being a difference between the cities.

The model takes the form of:

$p_{i}$ ~ Normal($\mu_{i}$, $\sigma_{i}$) *[likelihood]*,

log($\mu_{i}$) ~ $\alpha$[city]  *[model]*,

where $p_{i}$ is the human population density (total population divided by the land area per square mile) for each observation i, $\mu_{i}$ is the mean and $\sigma_{i}$ is the standard deviation, and $\alpha$[city] is the intercept for each city.

## P8: flexibility and microhabitat types

The model takes the form of:

$follows_{i}$ ~ Binomial(1, $p$) *[likelihood]*,

logit($p$) ~ $\alpha_{i}$[habitat] + $\beta_{i}$$\phi$ *[model]*,

where $follows_{i}$ is the proportion of focal follows that were recorded in a particular microhabitat for each individual i, $p$ is the probability of being in a given microhabitat, $\alpha_{i}$ is the intercept (one per observation), and $\beta_{i}$ is the slope for the interaction with $\phi$. Note that the model is the same when analyzing $\lambda$, which replaces $\phi$ in the above model. We determine that $\phi$ and $\lambda$ are strongly related to the proportion of focal follows in a given habitat if the compatibility interval for the slope does not cross zero.


# Results {-}

## P1: FLexibility and foraging behavior 

A total of 22 food types were eaten and 13 foraging techniques used across both populations, which included 35 grackles (8 of which were in the flexibility manipulated condition) who had an average of 4.5 focal follows and a range of 1-8 focal follows.

### Analysis plan: P1-P2

**Analysis:** Because the independent variables could influence each other, we will analyze them in a single model: Generalized Linear Mixed Model (GLMM; MCMCglmm function, MCMCglmm package; [@hadfield2010mcmc]) with a Poisson distribution and log link using 130,000 iterations with a thinning interval of 10, a burnin of 30,000, and minimal priors (V=1, nu=0) [@hadfield2014coursenotes]. We will ensure the GLMM shows acceptable convergence (lag time autocorrelation values <0.01; [@hadfield2010mcmc]), and adjust parameters if necessary to meet this criterion. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

 - **Deviation from the plan:** we added the independent variable, total seconds of observation time, to account for the different amounts of observation time with regard to the number of foods eaten and foraging techniques used per individual.

```{r p1foodsanalysis, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(rethinking)
library(rstan)
library(cmdstanr)
library(dplyr)
options(cmdstanr_verbose=TRUE) #turns on the warning messages when running ULAM models. Useful for troubleshooting errors

# LOAD the General data sheet
b1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
b1 <- data.frame(b1)


### NUMBER OF FORAGING TECHNIQUES and flexibility measures (phi, lambda, switch latency) across both populations
# How many different food types across both pops? 22 (from R code chunk p2manipunregistered)
#fry, lizard, unknown, grains, insect, rock, cat food, worm, seed, food crumbs, vegetation, fruit, bird poop, candy, vomit, misc. trash, soil, condiment, carcass, chicken, peanut, mulch

# How many different foraging techniques? 11 (from R code chunk p2manipunregistered)
#eat, gape, lift or nudge, stalk catch, flip, food share, break into pieces, dunk in water, tolerated theft, theft, dig, pick up, sweep


### FOOD TYPES: exclude NAs from the variables in this model
fo <- subset(b1, is.na(b1$NumFoodTypes) == FALSE) #note that this also eliminates the NAs for foraging techniques for the same birds bc NAs were always in both variables for the same birds
fo <- subset(fo, is.na(fo$SumFocalTime) == FALSE)
fo <- subset(fo, is.na(fo$Phi) == FALSE)
fo <- subset(fo, is.na(fo$Lambda) == FALSE)
fo <- subset(fo, is.na(fo$DomRank) == FALSE)
#length(unique(fo$BirdID)) #35 individuals
#mean(fo$NumFollows) #4.5 follows
#range(fo$NumFollows) #1-8 follows

#Separate the sexes
f <- fo[fo$Sex=="F",]
m <- fo[fo$Sex=="M",]

#sample sizes
length(unique(f$BirdID)) #9 females
length(unique(m$BirdID)) #26 males
mean(f$NumFollows) #4.2 follows for females
range(f$NumFollows) #1-6 follows for females
mean(m$NumFollows) #4.6 follows for females
range(m$NumFollows) #1-8 follows for females


# SIMULATION
n = 100
ph = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
la =  rnorm(n,mean=0,sd=1) #lambda can range from 0 to 9, but standardize by making mean=0 and SD=2
r = rnorm(n,mean=0,sd=1) #rank can range from -1 to 1, but standardize it
time =  600-rexp(n=n,rate=1/50) #each focal follow was 10 min (600 sec), but many weren't able to be conducted for this long bc the bird went out of view. Expect most follows to have met the 10 min criteria
#model = rbinom(n=n,size=22, prob=inv_logit(rnorm(n,mean=(0.25*ph + 0.5*la + 1*r + (1/6000)*time),sd=0.2))) #22 food types eaten. Now change the mean: a=4 which makes the phis and lambdas positive which is what we need, betas are the 1s before p, l, and r;  b=1/6000. If you have been observed for the full 600s, the probability of having more foraging techniques increases by 0.1 with the 1/6000 term
mod = rbinom(n=n,size=22, prob=inv_logit(rnorm(n,mean=(0.25*ph + 0.5*la + 1*r + (1/6000)*time),sd=0.2))) #22 food types eaten.
plot(mod~ph)
plot(mod~la)
#plots look good - any relationship is possible, but all values are within the feasible range

#run the simulated data through the model
s_type <- list(mod = mod,
               phi = ph,
               lambda = la,
               r = r,
               time = time
              )
simtype <- ulam( alist(
        mod ~ dbinom(22,p), #max 22 food types across AZ & CA (from data_FlexForaging > Foraging > How, and then counted the categories)
        logit(p) <- a + bp*phi + bl*lambda + br*r + bf*time, #include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), 
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        bf ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=s_type , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
s_outputtype <- precis( simtype , depth=2 )
#   mean   sd  5.5% 94.5% n_eff Rhat4
#a  -0.85 0.52 -1.68  0.00 1.00  1390.25
#bp  0.26 0.05  0.18  0.34 1.00  1415.52
#bl  0.54 0.05  0.46  0.62 1.00  1339.72
#br  0.96 0.06  0.87  1.06 1.01  1442.50
#bf  0.00 0.00  0.00  0.00 1.00  1394.67
#check bp and bl to see if it crosses zero. neff and rhat look good


# RUN the models
## BINOMIAL model FEMALE - food types
fe <- list(foods = f$NumFoodTypes,
            obstime = standardize(f$SumFocalTime),
            phi = standardize(as.numeric(f$Phi)),
            lambda = standardize(as.numeric(f$Lambda)),
            rank = standardize(f$DomRank)
              )
set.seed(9)
fe_binom <- ulam( alist(
        foods ~ dbinom(22,p), #max 22 food types
        logit(p) <- a + bp*phi + bl*lambda + br*rank + be*obstime, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        be ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=fe , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_fe_binom <- precis( fe_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -2.81 0.33 -3.37 -2.32    1   957.42
#bp -0.30 0.51 -1.14  0.47    1  1106.18
#bl -0.27 0.35 -0.83  0.28    1  1293.82
#br  0.28 0.28 -0.13  0.73    1  1310.38
#be  0.73 0.44  0.06  1.43    1  1182.97
#look at bp and bl to see if a relationship with foods: food types and phi/lambda are not strongly related in females

## BINOMIAL model FEMALE - food types & MAB switch latency
fm <- f[!f$MABavgLatencySwitch=="-",]

fef <- list(foodlat = fm$NumFoodTypes,
            obstime = standardize(fm$SumFocalTime),
            latency = standardize(as.numeric(fm$MABavgLatencySwitch)),
            rank = standardize(fm$DomRank)
              )
set.seed(14)
fe_binomfoodlat <- ulam( alist(
        foodlat ~ dbinom(11,p), #max 22 techniques
        logit(p) <- a + blat*latency + br*rank + be*obstime, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        blat ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=fef , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_fe_binomfoodlat <- precis( fe_binomfoodlat , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a    -2.20 0.40 -2.84 -1.61    1  1139.09
#be    0.56 0.48 -0.14  1.35    1  1216.65
#blat  0.67 0.38  0.08  1.29    1  1201.19
#br    0.29 0.30 -0.17  0.77    1  1483.59
#look at blat to see if a relationship with foods: those females with more food types have slower latencies to switch on the MAB (less flexible)



## BINOMIAL model FEMALE - techniques
fet <- list(tech = f$NumForageTechs,
            obstime = standardize(f$SumFocalTime),
            phi = standardize(as.numeric(f$Phi)),
            lambda = standardize(as.numeric(f$Lambda)),
            rank = standardize(f$DomRank)
              )
set.seed(10)
fe_binomtech <- ulam( alist(
        tech ~ dbinom(11,p), #max 11 techniques
        logit(p) <- a + be*obstime + bp*phi + bl*lambda + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=fet , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_fe_binomtech <- precis( fe_binomtech , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -2.01 0.33 -2.55 -1.50    1  1330.82
#be  0.40 0.45 -0.29  1.11    1  1311.79
#bp -0.76 0.51 -1.60  0.00    1  1235.05
#bl -0.91 0.43 -1.61 -0.25    1  1046.97
#br  0.16 0.28 -0.26  0.61    1  1429.19
#look at bp and bl to see if a relationship with techs: more techniques and lower phi (less flexible) and lower lambda (more flexible)



## BINOMIAL model FEMALE - techniques & MAB switch latency
fm <- f[!f$MABavgLatencySwitch=="-",]

fel <- list(techlat = fm$NumForageTechs,
            obstime = standardize(fm$SumFocalTime),
            latency = standardize(as.numeric(fm$MABavgLatencySwitch)),
            rank = standardize(fm$DomRank)
              )
set.seed(10)
fe_binomtechlat <- ulam( alist(
        techlat ~ dbinom(11,p), #max 22 techniques
        logit(p) <- a + be*obstime + blat*latency + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        blat ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=fel , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_fe_binomtechlat <- precis( fe_binomtechlat , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a    -2.19 0.41 -2.88 -1.56 1.01  1216.04
#be    0.53 0.50 -0.26  1.39 1.00  1261.84
#blat  1.15 0.42  0.53  1.87 1.01  1003.76
#br    0.36 0.27 -0.05  0.80 1.00  1706.95
#look at blat to see if a relationship with techs: those females with more techniques have slower latencies to switch on the MAB (less flexible)



## BINOMIAL model MALE - food types
ma <- list(foods = m$NumFoodTypes,
            obstime = standardize(m$SumFocalTime),
            phi = standardize(as.numeric(m$Phi)),
            lambda = standardize(as.numeric(m$Lambda)),
            rank = standardize(m$DomRank)
              )
set.seed(11)
ma_binom <- ulam( alist(
        foods ~ dbinom(22,p), #max 22 food types
        logit(p) <- a + be*obstime + bp*phi + bl*lambda + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=ma , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_ma_binom <- precis( ma_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -2.05 0.14 -2.28 -1.82 1.00  1206.98
#be  0.79 0.16  0.54  1.06 1.00  1103.14
#bp  0.41 0.14  0.19  0.63 1.00  1308.01
#bl  0.36 0.16  0.10  0.62 1.01  1036.66
#br  0.07 0.16 -0.18  0.33 1.00  1536.81
#look at bp and bl to see if a relationship with foods: food types and lambda are positively related in males (more food types used by the less flexible males bc higher lambda=less flexible), and food types and phi/lambda are positively related


## BINOMIAL model MALE - food types & MAB switch latency
mm <- subset(m, is.na(m$MABavgLatencySwitch) == FALSE)
mm <- m[!m$MABavgLatencySwitch=="-" & !m$BirdID=="Diablo",] #Diablo had NA for MAB latency and for some reason this was the only way to exclude that NA and make the model run

maf <- list(foodlat = mm$NumFoodTypes,
            obstime = standardize(mm$SumFocalTime),
            latency = standardize(as.numeric(mm$MABavgLatencySwitch)),
            rank = standardize(mm$DomRank)
              )
set.seed(14)
ma_binomfoodlat <- ulam( alist(
        foodlat ~ dbinom(11,p), #max 22 techniques
        logit(p) <- a + be*obstime + blat*latency + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        blat ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=maf , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_ma_binomfoodlat <- precis( ma_binomfoodlat , depth=2 )
#a    -1.16 0.17 -1.43 -0.90    1  1739.38
#be    0.71 0.18  0.43  1.00    1  1519.05
#blat -0.47 0.20 -0.79 -0.18    1  1641.22
#br    0.06 0.24 -0.33  0.44    1  1389.62
#look at blat to see if a relationship with foods: those males with more food types have faster latencies to switch on the MAB (more flexible)


## BINOMIAL model MALE - techniques
mat <- list(techs = m$NumForageTechs,
            obstime = standardize(m$SumFocalTime),
            phi = standardize(as.numeric(m$Phi)),
            lambda = standardize(as.numeric(m$Lambda)),
            rank = standardize(m$DomRank)
              )
set.seed(12)
ma_binomtech <- ulam( alist(
        techs ~ dbinom(11,p), #max 11 techniques
        logit(p) <- a + be*obstime + bp*phi + bl*lambda + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=mat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_ma_binomtech <- precis( ma_binomtech , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -1.30 0.15 -1.54 -1.06    1  1848.40
#be  0.51 0.17  0.24  0.78    1  1429.43
#bp  0.19 0.16 -0.07  0.45    1  1460.61
#bl  0.21 0.18 -0.10  0.49    1  1230.75
#br  0.15 0.18 -0.13  0.43    1  1624.02
#look at bp and bl to see if a relationship with foods: food types and phi/lambda are not strongly related in males


## BINOMIAL model MALE - techniques & MAB switch latency
mm <- subset(m, is.na(m$MABavgLatencySwitch) == FALSE)
mm <- m[!m$MABavgLatencySwitch=="-" & !m$BirdID=="Diablo",] #Diablo had NA for MAB latency and for some reason this was the only way to exclude that NA and make the model run

matl <- list(teclat = mm$NumForageTechs,
            obstime = standardize(mm$SumFocalTime),
            latency = standardize(as.numeric(mm$MABavgLatencySwitch)),
            rank = standardize(mm$DomRank)
              )
set.seed(14)
ma_binomteclat <- ulam( alist(
        teclat ~ dbinom(11,p), #max 22 techniques
        logit(p) <- a + be*obstime + blat*latency + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        be ~ dnorm(0,1), #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
        blat ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=matl , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_ma_binomteclat <- precis( ma_binomteclat , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a    -1.42 0.18 -1.70 -1.13 1.00  1567.74
#be    0.47 0.18  0.18  0.74 1.01  1463.67
#blat -0.79 0.24 -1.19 -0.42 1.00  1574.42
#br   -0.10 0.24 -0.48  0.29 1.00  1588.30
#look at blat to see if a relationship with techs: those males with more techniques have faster latencies to switch on the MAB (more flexible)



#VISUALIZE
#food types (males, females, phi, lambda, MAB latency)
op <- par(mfrow=c(2,3), mar=c(5.9,4.9,2,0.9))
plot(f$NumFoodTypes ~ f$Phi , pch=1 , col="black" , xlab="" , ylab="Food types used" , xlim=c(0,0.2), cex.lab=2, cex.axis=2, cex=2 )
mtext("A: Females",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(f$NumFoodTypes ~ f$Lambda , pch=1 , col="black" , xlab="" , ylab="", xlim=c(-2.5,8.5), cex.lab=2, cex.axis=2, cex=2 )
mtext("B: Females",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(f$NumFoodTypes ~ f$MABavgLatencySwitch , pch=1 , col="black" , xlab="" , ylab="", xlim=c(0,1600), cex.lab=2, cex.axis=2, cex=2 )
mtext("C: Females",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(m$NumFoodTypes ~ m$Phi , pch=1 , col="black" , xlab="Phi" , ylab="Food types used", xlim=c(0,0.2), cex.lab=2, cex.axis=2, cex=2 )
mtext("D: Males",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(m$NumFoodTypes ~ m$Lambda , pch=1 , col="black" , xlab="Lambda" , ylab="", xlim=c(-2.5,8.5), cex.lab=2, cex.axis=2, cex=2)
mtext("E: Males",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(m$NumFoodTypes ~ m$MABavgLatencySwitch , pch=1 , col="black" , xlab="MAB switch latency" , ylab="", xlim=c(0,1600), cex.lab=2, cex.axis=2, cex=2 )
mtext("F: Males",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
par(op)

#foraging techniques (males, females, phi, lambda, latency)
op <- par(mfrow=c(2,3), mar=c(5.9,4.9,2,0.9))
plot(f$NumForageTechs ~ f$Phi , pch=1 , col="black" , xlab="" , ylab="Foraging techniques used" , xlim=c(0,0.2), cex.lab=2, cex.axis=2, cex=2 )
mtext("A: Females",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(f$NumForageTechs ~ f$Lambda , pch=1 , col="black" , xlab="" , ylab="", xlim=c(-2.5,8.5), cex.lab=2, cex.axis=2, cex=2 )
mtext("B: Females",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(f$NumForageTechs ~ f$MABavgLatencySwitch , pch=1 , col="black" , xlab="" , ylab="", xlim=c(0,1600), cex.lab=2, cex.axis=2, cex=2 )
mtext("C: Females",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(m$NumForageTechs ~ m$Phi , pch=1 , col="black" , xlab="Phi" , ylab="Foraging techniques used", xlim=c(0,0.2), cex.lab=2, cex.axis=2, cex=2 )
mtext("D: Males",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(m$NumForageTechs ~ m$Lambda , pch=1 , col="black" , xlab="Lambda" , ylab="", xlim=c(-2.5,8.5), cex.lab=2, cex.axis=2, cex=2)
mtext("E: Males",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
plot(m$NumForageTechs ~ m$MABavgLatencySwitch , pch=1 , col="black" , xlab="MAB switch latency" , ylab="", xlim=c(0,1600), cex.lab=2, cex.axis=2, cex=2 )
mtext("F: Males",side=3,outer=FALSE,adj=0,font=1,cex=1.3,line=0.6)
par(op)
```

**Figure.** Scatterplots for females (top row) and males (bottom row) showing the relationship between the number of different food types eaten per second and phi (left column) or lambda (right column). Larger diameter circles indicate a larger phi or lambda.

```{r p1alt2calories, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(rethinking)
library(dplyr)

# Load focal follow data
fc <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
fc <- data.frame(fc)

# Include only eat in the How column so that each What is a food item
fc1 <- fc[fc$How=="eat",]

# Load calorie data. Note that calories were calculated based on the broader food type category in the What column so it was standardized
cal <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_FlexForaging_data_calories.csv"), header=T, sep=",", stringsAsFactors=F)
cal <- data.frame(cal)
cal2 <- subset(cal, select=-c(Item,Source,Notes))
colnames(cal2) = c("What","CaloriesPer100g")

# Assign each food type its caloric value in the focal follow data sheet
fc2 <- left_join(fc,cal2,by="What") #1st entry=data sheet (fc) to which I want to add the info from the second entry (cal)
#write.csv(fc2,file="g_flexforaging_data_foraging.csv") #uploaded this to github so now can just use the CaloriesPer100g column in the foraging data sheet

# Add to the data sheet: phi and lambda values per bird
# Load the General data sheet
b1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
b1 <- data.frame(b1)
#select only the phi and lambda columns
b2 <- subset(b1, select=c(BirdID,Phi,Lambda))

# Assign each food type its caloric value in the focal follow data sheet
fc3 <- left_join(fc2,b2,by="BirdID")
#write.csv(fc3,file="g_flexforaging_data_foraging.csv") 

# calculate AVERAGE calories per bird and plug into the General data sheet
fc4 <- as.data.frame(fc3 %>% group_by(BirdID) %>% summarize(mean(CaloriesPer100g)))
fc5 <- left_join(fc4,b1,by="BirdID")
#entered the data for this column to the general data sheet by hand because something was odd about the write.csv version, then I uploaded it to github

# REload the General data sheet with the new column for avg calories
b1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
b1 <- data.frame(b1)

# only males had a negative relationship between food types and flexibility. We only look at reversal learning here. The females did show a negative relationship with latency to switch on the MAB, but their sample size is only 6 and none of the chains finished so the sample size is too small (the other 3 females with focals dropped out of this analysis bc they ate 0 food items)
b2 <- b1[b1$Sex=="M",]

#select only the columns in the model
b3 <- subset(b2, select=c(BirdID,Phi,Lambda,AvgCaloriesPer100g))

# Remove the NAs
b3 <- subset(b3, is.na(b3$AvgCaloriesPer100g) == FALSE)
b3 <- subset(b3, is.na(b3$Phi) == FALSE)
b3 <- subset(b3, is.na(b3$Lambda) == FALSE)

# summary stats
unique(b3$BirdID) #n=19 males
mean(b3$AvgCaloriesPer100g) #254
sd(b3$AvgCaloriesPer100g) #97

# SIMULATE
N_ind <- 20

sat <- list(
    cals = rnorm(N_ind,mean=254,sd=97),
    ph = rnorm(N_ind,mean=0,sd=1), #standardized
    la = rnorm(N_ind,mean=0,sd=1) #standardized  
    )

sim_cal <- ulam( alist(
        cals ~ normal( mu , sigma ),
        mu <- a + bp*ph + bl*la,
        a ~ normal(0,0.5), 
        bp ~ normal(0,0.5), #standardized
        bl ~ normal(0,0.5), #standardized
        sigma ~ exponential(1)
    ) , data=sat , chains=4 , cores=4 , log_lik=TRUE , cmdstan = TRUE)

precis(sim_cal,depth=2)
#       mean   sd  5.5%  94.5% n_eff Rhat4
#a       0.11 0.52  -0.72   0.92  2667     1
#bp      0.06 0.50  -0.77   0.87  2288     1
#bl      0.04 0.50  -0.79   0.84  2544     1
#sigma 124.45 6.29 114.57 134.48  3024     1
#n_eff and rhat look good, no strong relationship between avg calories and phi and lambda. Ran it 3x & same results

plot(sat$cals~sat$ph)
plot(sat$cals~sat$la)
#plots looks like any relationship is feasible and they are within the boundaries


# RUN the model: calories of the food types taken per bird by phi and lambda to see if the more flexible birds took more valuable food (higher calories)
# MALES with lambda
datc <- list(
    avgcal = b3$AvgCaloriesPer100g,
    phi = standardize(b3$Phi),
    lambda = standardize(b3$Lambda) )

mod_cal <- ulam( alist(
        avgcal ~ normal( mu , sigma ),
        mu <- a + bp*phi + bl*lambda,
        a ~ normal(0,0.5), 
        bp ~ normal(0,0.5), 
        bl ~ normal(0,0.5), 
        sigma ~ exponential(1)
    ) , data=datc , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE), log_lik=TRUE)

precis(mod_cal,depth=2)
#       mean   sd  5.5%  94.5% n_eff Rhat4
#a       0.11 0.52 -0.74   0.93  2168     1
#bp     -0.02 0.49 -0.81   0.77  2207     1
#bl      0.01 0.49 -0.75   0.79  2398     1
#sigma 106.33 5.46 98.05 115.39  2267     1
#no relationship between avg calories (food type value) and phi or lambda


# FEMALES with latency
bf <- b1[b1$Sex=="F",]

#select only the columns in the model
bf2 <- subset(bf, select=c(BirdID,MABavgLatencySwitch,AvgCaloriesPer100g))

# Remove the NAs
bf2 <- subset(bf2, is.na(bf2$AvgCaloriesPer100g) == FALSE)
bf2 <- subset(bf2, is.na(bf2$MABavgLatencySwitch) == FALSE)
bf2 <- bf2[!bf2$MABavgLatencySwitch=="-",]

# summary stats
unique(bf2$BirdID) #n=4 females
mean(bf2$AvgCaloriesPer100g) #228
sd(bf2$AvgCaloriesPer100g) #181

# RUN the model
datf <- list(
    avgcal = bf2$AvgCaloriesPer100g,
    latency = standardize(as.numeric(bf2$MABavgLatencySwitch))
    )

mod_calf <- ulam( alist(
        avgcal ~ normal( mu , sigma ),
        mu <- a + blat*latency,
        a ~ normal(0,0.5), 
        blat ~ normal(0,0.5), 
        sigma ~ exponential(1)
    ) , data=datf , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE), log_lik=TRUE)

precis(mod_calf,depth=2)
#       mean   sd  5.5%  94.5% n_eff Rhat4
#a      0.04 0.48 -0.74  0.78  1866     1
#blat  -0.03 0.50 -0.84  0.80  2035     1
#sigma 69.81 4.86 62.42 78.06  1756     1
#no relationship between avg calories (food type value) and latency
```

We will quantify the number of different food types and foraging techniques during focal follows according to the [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing). If a grackle forages during a focal follow we record WHAT it eats, as well as HOW the bird is searching for food. Foraging techniques include: Flipping over objects (flip), digging in ground with bill or feet (dig), sweeping head back and forth [i.e., actually sweeping the bill across the substrate; (sw)], extracting from a substrate (ex), lowers body posture to be parallel to ground to stalk/catch prey from air, from ground, from tree, etc (sc), using gaping bill to search through substrate (ga), lifting or nudging objects with bill (ln). 

## P1 alternative 2: flexible = more valuable food types

Prediction: If there is a negative correlation between flexibility and the number of different foods eaten, this might indicate that the more flexible individuals target particular food items. If this prediction is supported, we will conduct an additional analysis to examine what food types the more flexible grackles eat and whether these food types are potentially more valuable (measured as having more calories).

**Analysis:** We will rank all food types eaten by the grackles by their caloric value, examine the food types eaten per individual and relate this to their flexibility scores on their most recent reversal learning color tube experiment. This will allow us to see whether the more flexible individuals (faster to reverse) eat more valuable (i.e., higher calorie) food types than the less flexible individuals.

## P2: Flexibility manipulation and foraging behavior 

In this dataset, there are 8 manipulated birds and 10 control birds who have 1-8 focal follows per bird with a mean of 4.7 follows. 

Using the **binomial model** to determine, of the known food types and foraging techniques, how many are used, we find that flexibility manipulated individuals take an average of 1.8 more food types and use an average of 1.3 more foraging techniques than control individuals because the compatibility interval did not cross zero (food types: mean=-1.82, sd=0.74, 89% compatibility interval=-3.03 - -0.64; techniques: mean=-1.31, sd=0.80, 89% compatibility interval=-2.62 - -0.02; Figure). Not all birds were followed for the same amount of time and our expectation is that the number of food types and foraging techniques increases with increasing observation time. Therefore, we use the model to predict the number of food types and foraging techniques used if all birds were observed for the maximum amount of time. The model predicts that manipulated birds have an average of 8.9 food types and 5.8 techniques, and control birds an average of 5.4 food types and 4.3 techniques. These differences of 3.5 (food types) and 1.5 (techniques) are higher than the differences we observe with our dataset (1.8 and 1.3, respectively) because most birds were not observed for the maximum period of time. The manipulated birds have a 1.9 (food types) and 1.6 (techniques) higher likelihood of using any of the 22 food types or 10 foraging techniques than the control birds, regardless of the amount of observation time.

```{r p2manipvsctrl, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
### NUMBER OF FOOD TYPES AND FORAGING TECHNIQUES for flexibility manipulated vs control birds
library(rethinking)
c1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
c1 <- data.frame(c1)

#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
c1 <- c1[c1$Population=="AZ",]

# AZ population: How many different food types? 20 (from R code chunk p2manipunregistered)
#length(unique(ft1$What)) #20
#unique(ft1$What) #fry, lizard, unknown, grains, insect, rock, cat food, worm, seed, food crumbs, vegetation, fruit, bird poop, candy, vomit, misc. trash, soil, condiment, carcass, chicken

# AZ population: How many different foraging techniques? 9 (from R code chunk p2manipunregistered)
#length(unique(ft1$How)) # 11 - 1 (eat) - 1 (tolerated theft) = 9
#unique(ft1$How) #eat, gape, lift or nudge, stalk catch, flip, food share, break into pieces, dunk in water, tolerated theft, theft, dig


### FOOD TYPES: exclude NAs from the variables in this model
fo <- subset(c1, is.na(c1$NumFoodTypes) == FALSE)
fo <- subset(fo, is.na(fo$SumFocalTime) == FALSE)
fo <- subset(fo, is.na(fo$FlexibilityManipulated) == FALSE)
#length(unique(fo$BirdID)) #18 individuals
#fo$FlexibilityManipulated #manipulated=8, control=10
#mean(fo$NumFollows) #4.7 follows
#range(fo$NumFollows) #1-8 follows


# SIMULATION
n = 18
t = sample(1:2,size=n,replace=T) #treatment is a categorical variable
time =  600-rexp(n=n,rate=1/50) #each focal follow was 10 min (600 sec), but many weren't able to be conducted for this long bc the bird went out of view. Expect most follows to have met the 10 min criteria
m = rbinom(n=n,size=20, prob=rnorm(n,mean=(ifelse(t==1,0.4,0.41)+(1/6000)*time),sd=0.2)) #22 food types eaten. Now change the mean: a=the ifelse term giving each t a different intercept (a[1]=0.4), a[2]=0.5, b=1/6000. If you have been observed for the full 600 s, the probability of having more foraging techniques increases by 0.1 with the 1/6000 term
sim_boxtype <- boxplot(m~t)
sim_plottype <- plot(m~time)
#plots look good - any relationship is possible, but all values are within the feasible range

#run the simulated data through the model
s_type <- list(m = m,
            time = standardize(time),
            t = t
              )
simtype <- ulam( alist(
        m ~ dbinom(20,p), #max 22 food types in AZ (from data_FlexForaging > Foraging > How, and then counted the categories)
        logit(p) <- a[t] + b*time, #include total observation time because this varied per focal (with a target max time of 10 min)
        a[t] ~ dnorm(0,1), #each treatment gets its own intercept, mean=0 bc response variable is standardized
        b ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=s_type , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
s_outputtype <- precis( simtype , depth=2 )

#contrast
postt <- extract.samples(simtype)
diff <- inv_logit( postt$a[,1]) - inv_logit( postt$a[,2])
diftype <- precis( diff )
#shows a difference between the treatment groups when means differ by 0.01 or more when sd=0.2


# RUN the models
#rebuild_cmdstan() #run this if you get an error about a PCH file

## BINOMIAL model - food types
tr <- list(foods = fo$NumFoodTypes,
            obstime = standardize(fo$SumFocalTime),
            treatment = as.integer(as.factor(fo$FlexibilityManipulated)) #1=control, 2=manipulated
              )
set.seed(9)
tr_binom <- ulam( alist(
        foods ~ dbinom(20,p), #max 20 food types in the AZ population
        logit(p) <- a[treatment] + b*obstime, #the intercept is the probability of observing any of the food types is different between groups, but this probability doesn't change over time (bc birds are observed only AFTER the manipulation is over). Include total observation time because this varied per focal (with a target max time of 10 min)
        a[treatment] ~ dnorm(0,1), #each treatment gets its own intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        b ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=tr , chains=4 , cores=4 , cmdstan = TRUE) #, control = list(adapt_delta = .95, force_recompile = TRUE)

output_tr_binom <- precis( tr_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a[1] -2.23 0.24 -2.60 -1.85  1480     1
#a[2] -1.45 0.21 -1.80 -1.11  1618     1
#b     0.79 0.16  0.54  1.04  1399     1

#contrast to see if treatment groups differ
posttr <- extract.samples(tr_binom)
difftr <- inv_logit( posttr$a[,1])*20 - inv_logit( posttr$a[,2])*20 #it shows a probability so multiply by 20 food types
contrasttr <- precis( difftr )
#         mean   sd  5.5% 94.5%   histogram
# difftr -1.85 0.75 -3.02 -0.65 ▁▁▁▃▇▇▅▂▁▁▁
#control group has 1.9 fewer food types than the manipulated group

#look at the predicted number of techniques that manipulated individuals are expected to show if they would be observed for the full 10 min
# manipulatedtype <- link(tr_binom,data=list(treatment=2,obstime=max(tr$obstime)))*20
# contrasttrm <- precis(manipulatedtype[,1])
#                 mean   sd 5.5% 94.5% histogram
#manipulatedtype...1. 9.71 1.52 7.26 12.18 ▁▁▂▅▇▇▃▂▁▁
#they would eat an average of 9.7 food types

#look at the predicted number of techniques that control individuals are expected to show if they would be observed for the full 10 min
# controltype <- link(tr_binom,data=list(treatment=1,obstime=max(tr$obstime)))*20
# contrasttrc <- precis(controltype[,1])
#                 mean   sd 5.5% 94.5%   histogram
#controltype...1. 5.93 1.12 4.23  7.75  ▁▁▃▇▇▃▁▁
#they would use an average of 5.9 techniques

#Probability of using a food type
inv_logit( output_tr_binom[1,1]) # 0.09748999 control
inv_logit( output_tr_binom[2,1]) # 0.1893969 manipulated
#how much more likely are manipulated birds to use a food type?
inv_logit( output_tr_binom[2,1]) / inv_logit( output_tr_binom[1,1]) #manipulated birds are 1.94 times more likely



### FORAGING TECHNIQUES: exclude NAs from the variables in this model
c2 <- subset(c1, is.na(c1$NumForageTechs) == FALSE)
c2 <- subset(c2, is.na(c2$SumFocalTime) == FALSE)
c2 <- subset(c2, is.na(c2$FlexibilityManipulated) == FALSE)

#Separate the sexes - too few females (n=3) to separate the sexes so combining the sexes for this analysis
#f3 <- c2[c2$Sex=="F",]
#m3 <- c2[c2$Sex=="M",]

#sample sizes
#length(unique(c2$BirdID)) #18 individuals
#mean(c2$NumFollows) #4.7 follows
#range(c2$NumFollows) #1-8 follows

# SIMULATION
n = 100
t = sample(1:2,size=n,replace=T) #treatment is a categorical variable
time =  600-rexp(n=n,rate=1/50) #each focal follow was 10 min (600 sec), but many weren't able to be conducted for this long bc the bird went out of view. Expect most follows to have met the 10 min criteria
m = rbinom(n=n,size=9, prob=rnorm(n,mean=(ifelse(t==1,0.4,0.45)+(1/6000)*time),sd=0.15)) #9 techniques used. Now change the mean: a=the ifelse term giving each t a different intercept (a[1]=0.4), a[2]=0.5, b=1/6000. If you have been observed for the full 600 s, the probability of having more foraging techniques increases by 0.1 with the 1/6000 term
boxplot(m~t)
plot(m~time)
#plots look good - any relationship is possible, but all values are within the feasible range

#run the simulated data through the model
s_manip <- list(m = m,
            time = standardize(time),
            t = t
              )
set.seed(11)
simmanip <- ulam( alist(
        m ~ dbinom(12,p), #max 12 foraging techniques used across both populations (from data_FlexForaging > Foraging > How, and then counted the categories)
        logit(p) <- a[t] + b*time, #include total observation time because this varied per focal (with a target max time of 10 min)
        a[t] ~ dnorm(0,1), #each treatment gets its own intercept, mean=0 bc response variable is standardized
        b ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=s_manip , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
s_output <- precis( simmanip , depth=2 )

#contrast
posts <- extract.samples(simmanip)
diffs <- inv_logit( posts$a[,1]) - inv_logit( posts$a[,2])
contrastsim_binom <- precis( diffs )
#shows a difference between the treatment groups when means differ by 0.05 or more when sd=0.15


# RUN the models
## BINOMIAL model - foraging techniques
manip <- list(tech = c2$NumForageTechs,
            obstime = standardize(c2$SumFocalTime),
            treatment = as.integer(as.factor(c2$FlexibilityManipulated)) #1=control, 2=manipulated
              )

# Run the model: binomial distribution bc it is a count of events occurring over a continuous period of time that is a bounded period of time (McElreath 2nd edition, Fig 10.6)
set.seed(12)
phimanip <- ulam( alist(
        tech ~ dbinom(9,p), #max 9 foraging techniques used in the AZ population
        logit(p) <- a[treatment] + b*obstime, #the intercept is the probability of observing any of the techs is different between groups, but this probability doesn't change over time (bc birds are observed only AFTER the manipulation is over). Include total observation time because this varied per focal (with a target max time of 10 min)
        a[treatment] ~ dnorm(0,1), #each treatment gets its own intercept, mean=0 bc assume an average bird might show half of the total techs, so 0 on inverse logit = 50%
        b ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=manip , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputtphimanipp <- precis( phimanip , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a[1] -1.41 0.26 -1.83 -1.00  1826     1
#a[2] -0.75 0.28 -1.20 -0.32  1787     1
#b     0.87 0.20  0.56  1.19  1928     1

#contrast to see if treatment groups differ
postphi <- extract.samples(phimanip)
diffpm <- inv_logit( postphi$a[,1])*9 - inv_logit( postphi$a[,2])*9 #it shows a probability so multiply by 9 techniques
contrastbinomtech <- precis( diffpm )
#         mean   sd  5.5% 94.5%  histogram
# diffpm -1.12 0.65 -2.16 -0.09 ▁▁▂▅▇▇▃▁▁▁
#control group has 1.1 fewer foraging techniques than the manipulated group

#look at the predicted number of techniques that manipulated individuals are expected to show if they would be observed for the full 10 min
# manipulated<- link(phimanip,data=list(treatment=2,obstime=max(manip$obstime)))*10
# contrastbinomm <- precis(manipulated[,1])
#                 mean   sd 5.5% 94.5% histogram
#manipulated...1. 6.39 0.86 4.95   7.7 ▁▁▁▂▃▅▇▇▅▂▁▁
#they would use an average of 6.4 techniques

#look at the predicted number of techniques that control individuals are expected to show if they would be observed for the full 10 min
# control<- link(phimanip,data=list(treatment=1,obstime=max(manip$obstime)))*10
# contrastbinomc <- precis(control[,1])
#             mean   sd 5.5% 94.5%   histogram
#control...1. 4.83 0.78 3.56  6.04 ▁▁▁▃▅▇▇▃▁▁▁▁
#they would use an average of 4.8 techniques

#Probability of using a technique
inv_logit( outputtphimanipp[1,1]) # 0.1967045 control
inv_logit( outputtphimanipp[2,1]) # 0.3216786 manipulated
#how much more likely are manipulated birds to use a technique?
inv_logit( outputtphimanipp[2,1]) / inv_logit( outputtphimanipp[1,1]) #manipulated birds 1.64 times more likely


#VISUALIZE
op <- par(mfrow=c(2,1), mar=c(5.9,4.9,2,0.9))
k<-1 #used to standardize the plotting
#types binomial plot
plot( fo$SumFocalTime , fo$NumFoodTypes , xlab="" , ylab="Total food types" ,
    col=ifelse( tr$treatment==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,
    ylim=c(0,22) , cex=1+normalize(k) )
time_seq <- seq(from=min(tr$obstime),to=max(tr$obstime),length=100)
time_seq_unst<-seq(from=min(fo$SumFocalTime),to=max(fo$SumFocalTime),length=100)
lambda <- link( tr_binom , data=data.frame( obstime=time_seq , treatment=1 ) )*10
lmu <- apply( lambda , 2 , mean )
lci <- apply( lambda , 2 , PI )
lines( time_seq_unst , lmu , lty=2 , lwd=1.5 )
shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(4,0.3))
lambda <- link( tr_binom , data=data.frame( obstime=time_seq , treatment=2 ) )*10
lmu <- apply( lambda , 2 , mean )
lci <- apply( lambda , 2 , PI )
lines( time_seq_unst , lmu , lty=1 , lwd=1.5 )
shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(2,0.3) )
points(fo[fo$FlexibilityManipulated=="No",]$NumFoodTypes~fo[fo$FlexibilityManipulated=="No",]$SumFocalTime,pch=1)
points(fo[fo$FlexibilityManipulated=="Yes",]$NumFoodTypes~fo[fo$FlexibilityManipulated=="Yes",]$SumFocalTime,pch=2,col="black")
legend(x="topleft", y=8, legend=c(pch1="Control", pch2="Manipulated"), pch=c(1,2), col=c("Black","Black"), box.lty=1, cex=1)
mtext("A: Binomial",side=3,outer=FALSE,adj=0,font=1,cex=1,line=0.6)
##techs binomial plot: the manipulated birds had consistently more techniques across all observation times and the rate of observing a given technique is higher for manipulated birds, therefore the difference between them and the control group gets larger as time increases
plot( c2$SumFocalTime , c2$NumForageTechs , xlab="Observation time (sec)" , ylab="Total foraging techniques" ,
    col=ifelse( manip$treatment==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,
    ylim=c(0,10) , cex=1+normalize(k) )
time_seq <- seq(from=min(manip$obstime),to=max(manip$obstime),length=100)
time_seq_unst<-seq(from=min(c2$SumFocalTime),to=max(c2$SumFocalTime),length=100)
lambda <- link( phimanip , data=data.frame( obstime=time_seq , treatment=1 ) )*10
lmu <- apply( lambda , 2 , mean )
lci <- apply( lambda , 2 , PI )
lines( time_seq_unst , lmu , lty=2 , lwd=1.5 )
shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(4,0.3))
lambda <- link( phimanip , data=data.frame( obstime=time_seq , treatment=2 ) )*10
lmu <- apply( lambda , 2 , mean )
lci <- apply( lambda , 2 , PI )
lines( time_seq_unst , lmu , lty=1 , lwd=1.5 )
shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(2,0.3) )
points(c2[c2$FlexibilityManipulated=="No",]$NumForageTechs~c2[c2$FlexibilityManipulated=="No",]$SumFocalTime,pch=1)
points(c2[c2$FlexibilityManipulated=="Yes",]$NumForageTechs~c2[c2$FlexibilityManipulated=="Yes",]$SumFocalTime,pch=2,col="black")
mtext("C: Binomial",side=3,outer=FALSE,adj=0,font=1,cex=1,line=0.6)
par(op)


# USE THE BINOMIAL MODELS because Poisson goes beyond the data and tries to get causal about things that aren't causal. But here is the POISSON model - foraging techniques just so we have it - equally likely to switch among techs, but the manipulated birds have a different total number of techniques, which is reflected by the intercept. Time is just a control variable and don't want to interpret any output from this variable
# set.seed(10)
# tr_poi <- ulam( alist(
#         foods ~ dpois(lambda),
#         log(lambda) <- a[treatment] + b*obstime, #include total observation time because this varied per focal (with a target max time of 10 min)
#         a[treatment] ~dnorm(0,1) , #expect 1 technique as soon as start collecting data (time can never be zero)
#         b ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
#     ) , data=tr , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
# outputtr_poi <- precis(tr_poi,depth=2)
# #     mean   sd 5.5% 94.5% n_eff Rhat4
# #a[1] 0.50 0.23 0.11  0.86  1062     1
# #a[2] 1.14 0.20 0.81  1.43  1066     1
# #b    0.71 0.15 0.48  0.96  1086     1
# 
# #contrast to see if treatment groups differ
# posttrpoi <- extract.samples(tr_poi)
# difftrpoi <- exp( posttrpoi$a[,1]) - exp( posttrpoi$a[,2])
# contrasttrpoi <- precis( difftrpoi )
# #         mean   sd  5.5% 94.5%  histogram
# #difftrpoi -1.51 0.67 -2.57 -0.47 ▁▁▁▁▃▇▇▃▂▁▁
# #manipulated birds used more food types

# USE THE BINIOMIAL MODEL! POISSON model - foraging techniques - equally likely to switch among techs, but the manipulated birds have a different total number of techniques, which is reflected by the intercept. Time is just a control variable and don't want to interpret any output from this variable
# set.seed(13)
# manippoi <- ulam( alist(
#         tech ~ dpois(lambda),
#         log(lambda) <- a[treatment] + b*obstime, #include total observation time because this varied per focal (with a target max time of 10 min)
#         a[treatment] ~dnorm(0,1) , #expect 1 technique as soon as start collecting data (time can never be zero)
#         b ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
#     ) , data=manip , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
# precis(manippoi,depth=2)
# #     mean   sd 5.5% 94.5% n_eff Rhat4
# #a[1] 0.43 0.24 0.05  0.79  1464     1
# #a[2] 0.86 0.23 0.48  1.20  1287     1
# #b    0.64 0.17 0.38  0.91  1227     1
# 
# #contrast to see if treatment groups differ
# postpoi <- extract.samples(manippoi)
# diffpoi <- exp( postpoi$a[,1]) - exp( postpoi$a[,2])
# precis( diffpoi )
# #         mean   sd  5.5% 94.5%  histogram
# #diffpoi -0.84 0.61 -1.84   0.1 ▁▁▁▂▇▇▅▂▁▁


# #types poisson plot
# plot( fo$SumFocalTime , fo$NumFoodTypes , xlab="" , ylab="Total food types" ,
#     col=ifelse( tr$treatment==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,
#     ylim=c(0,22) , cex=1+normalize(k) )
# time_seq <- seq(from=min(tr$obstime),to=max(tr$obstime),length=100)
# time_seq_unst<-seq(from=min(fo$SumFocalTime),to=max(fo$SumFocalTime),length=100)
# lambda <- link( tr_poi , data=data.frame( obstime=time_seq , treatment=1 ) )
# lmu <- apply( lambda , 2 , mean )
# lci <- apply( lambda , 2 , PI )
# lines( time_seq_unst , lmu , lty=2 , lwd=1.5 )
# shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(4,0.3))
# lambda <- link( tr_poi , data=data.frame( obstime=time_seq , treatment=2 ) )
# lmu <- apply( lambda , 2 , mean )
# lci <- apply( lambda , 2 , PI )
# lines( time_seq_unst , lmu , lty=1 , lwd=1.5 )
# shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(2,0.3) )
# points(fo[fo$FlexibilityManipulated=="No",]$NumFoodTypes~fo[fo$FlexibilityManipulated=="No",]$SumFocalTime,pch=1)
# points(fo[fo$FlexibilityManipulated=="Yes",]$NumFoodTypes~fo[fo$FlexibilityManipulated=="Yes",]$SumFocalTime,pch=2,col="black")
# mtext("B: Poisson",side=3,outer=FALSE,adj=0,font=1,cex=1,line=0.6)

# #techs poisson plot
# plot( c2$SumFocalTime , c2$NumForageTechs , xlab="Observation time (sec)" , ylab="Total foraging techniques" ,
#     col=ifelse( manip$treatment==1 , 4 , 2 ) , lwd=4+4*normalize(k) ,
#     ylim=c(0,10) , cex=1+normalize(k) )
# time_seq <- seq(from=min(manip$obstime),to=max(manip$obstime),length=100)
# time_seq_unst<-seq(from=min(c2$SumFocalTime),to=max(c2$SumFocalTime),length=100)
# lambda <- link( manippoi , data=data.frame( obstime=time_seq , treatment=1 ) )
# lmu <- apply( lambda , 2 , mean )
# lci <- apply( lambda , 2 , PI )
# lines( time_seq_unst , lmu , lty=2 , lwd=1.5 )
# shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(4,0.3))
# lambda <- link( manippoi , data=data.frame( obstime=time_seq , treatment=2 ) )
# lmu <- apply( lambda , 2 , mean )
# lci <- apply( lambda , 2 , PI )
# lines( time_seq_unst , lmu , lty=1 , lwd=1.5 )
# shade( lci , time_seq_unst , xpd=TRUE , col=col.alpha(2,0.3) )
# points(c2[c2$FlexibilityManipulated=="No",]$NumForageTechs~c2[c2$FlexibilityManipulated=="No",]$SumFocalTime,pch=1)
# points(c2[c2$FlexibilityManipulated=="Yes",]$NumForageTechs~c2[c2$FlexibilityManipulated=="Yes",]$SumFocalTime,pch=2,col="black")
# mtext("D: Poisson",side=3,outer=FALSE,adj=0,font=1,cex=1,line=0.6)

#### the difference between the poisson and binomial models: 
#binomial model indicates that manipulated birds use more techniques bc, of the techniques they know, they switch between them more frequently than control birds in a given time frame
#poisson model indicates that there is no difference in how many techniques a bird potentially knows
#assume observe a bird for 3 min and it shows techs a b and c. Assume a 2nd bird for 3 min, shows a and b. Why are fewer techs observed in the 2nd bird? Option 1 = it knows fewer techs, Option 2= it changes between techs at a lower rate. The binomial model captures the rate of switching among techs at a given time point, so as long as you look at the difference between the treatment groups away from the two ends of observation time (not close to zero and not once the techniques have asymptoted), the you will be able to see the difference between the groups, if any. 
#With binomial, assume every bird can reach the full 10 maximum techniques, whereas the poisson tries to extrapolate the maximum number of techs each bird could have and it says that this number is not different between the groups. 
```


**UNREGISTERED ANALYSES:** The results from the binomial suggest that the difference between manipulated and control individuals could be due to differences in the probability that birds will switch among foraging techniques. We predict that manipulated birds have a higher probability of switching techniques per second or per minute because switching is a measure of flexibility, which was manipulated in the aviaries for these individuals. The food type data set consisted of 13 individuals (6=manipulated, 7=control), and the foraging technique data set consisted of 12 individuals (n=5 manipulated, n=7 control) who had data that involved eating at least one food type or using at least one foraging technique. For each focal follow, we calculate the number of switches between food types or techniques that occur and the total amount of time that the bird was observed. We sum both measures across focal follows to have one data point per bird. This model takes the form of:

$switches_{i}$ ~ Binomial($totaltime_{i}$, $p$) *[likelihood]*,

logit($p$) ~ $\alpha_{i}$[$treatment$] *[model]*,

where $switches_{i}$ is the number of times individual, i, changed foraging techniques across all of their focal follows, $totaltime_{i}$ is the number of seconds individual, i, was observed across all of its focal follows, $p$ is the probability of switching to a different technique per second, and $\alpha_{i}$ is the intercept (one per level of $treatment$: control and manipulated). Note that the model is the same when analyzing the number of food types eaten for each individual, $foodswitches_{i}$, which replaces $switches_{i}$ in the above model.

We find that the manipulated birds on average have a 1.9 times higher probability to switch to a different food type (mean=1.93, sd=0.31, 89% compatibility interval=1.44 - 2.38), and a 1.7 times higher probability to switch to a different foraging technique (mean=1.69, sd=0.33, 89% compatibility interval=1.19 - 2.21) compared to control birds (\ref{fig:p2manipunregistered}). The manipulated birds have an average probability of switching among food types of 16% per minute and among techniques of 11% per minute, whereas control birds on average switch food types with a probability of 8% per minute and foraging techniques with a probability of 7% per minute.

```{r p2manipunregistered, eval=T, out.width="10cm",fig.align = "center", fig.cap="The probability of switching among food types (A) and foraging techniques (B) per minute for the control and manipulated birds. The small circles are the data points per individual and the large circles are the estimated means with their 89% compatibility intervals represented by the vertical lines."}
### NUMBER OF FORAGING TECHNIQUES for flexibility manipulated vs control birds - did manipulated switch more?
library(rethinking)
library(dplyr)
ft <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
ft <- data.frame(ft)

# ONLY AZ: select only the AZ birds who were manipulated or control individuals in the flexibility experiment
ft1 <- ft[ft$Population=="AZ",]

# AZ population: How many different food types?
#length(unique(ft1$What)) #20
#unique(ft1$What) #fry, lizard, unknown, grains, insect, rock, cat food, worm, seed, food crumbs, vegetation, fruit, bird poop, candy, vomit, misc. trash, soil, condiment, carcass, chicken

# AZ population: How many different foraging techniques?
#length(unique(ft1$How)) # 11 - 1 (eat) - 1 (tolerated theft) = 9
#unique(ft1$How) #eat, gape, lift or nudge, stalk catch, flip, food share, break into pieces, dunk in water, tolerated theft, theft, dig


#FOOD TYPES: count the number of technique switches during each focal
#exclude NAs from the variables in this model
fo <- subset(ft1, is.na(ft1$What) == FALSE)

#calculate food type switches per bird across all follows
fo$FoodSwitch<-NA
fo[1,]$FoodSwitch<-0
for(i in 2:nrow(fo)){
  ifelse(fo[i,]$FocalID==fo[i-1,]$FocalID & fo[i,]$What !=fo[i-1,]$What, fo[i,]$FoodSwitch<-1,fo[i,]$FoodSwitch<-0)
}

fo2 <- fo %>% group_by(BirdID,FocalID) %>% summarise(foodswitchesperfocal=sum(FoodSwitch),timeperfocal=mean(TotalTimeInView))
fo3 <- fo2 %>% group_by(BirdID) %>% summarise(totalfoodswitches=sum(foodswitchesperfocal),totaltime=sum(timeperfocal))

# link with general datasheet to identify which birds were manipulated
c1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
c1 <- data.frame(c1)
#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
c1 <- c1[c1$Population=="AZ",]
ca<- c1 %>% group_by(BirdID) %>% summarise (Treatment=unique(FlexibilityManipulated))

fo4 <- left_join(fo3,ca,by="BirdID")
fo4 <- subset(fo4, is.na(fo4$Treatment) == FALSE)
#nrow(fo4) #NOTE: n=13 (6=manipulated, 7=control) birds because some dropped out due to not having any foraging events in their focals or not having any focals


# What is the average number of focals per bird? 
ff <- fo2 %>% group_by(BirdID,FocalID) %>% summarise (Count=n()) #Doesn't work yet, so just looked at fo2 and hand calculated
ff1 <- data.frame(ff)
##Total number of focals per bird in this dataset
#Manipulated: Adobo=1, Burrito=7, Chalupa=3, Chilaquile=5, Diablo=2, Habanero=1.
#mean(c(1,7,3,5,2,1)) #3.2 focals per manipulated bird
#Control: Fideo=5, Mofongo=2, Queso=3, Taco=7, Tapa=2, Taquito=3, Tomatillo=3
#mean(c(5,2,3,7,2,3,3)) #3.6 focals per control bird


# RUN the models
dat_swfo <- list(foodswitches = fo4$totalfoodswitches,
            totaltime = fo4$totaltime, 
            treatment = as.integer(as.factor(fo4$Treatment)) #1=control, 2=manipulated
              )
swfo <- ulam( alist(
        foodswitches ~ dbinom(totaltime,p),
        logit(p) <- a[treatment], #the intercept is the probability of observing any of the types is different between groups, but this probability doesn't change over time (bc birds are observed only AFTER the manipulation is over). Include total observation time because this varied per focal (with a target max time of 10 min)
        a[treatment] ~ dnorm(0,1) #each treatment gets its own intercept, mean=0 bc assume an average bird might show half of the total techs, so 0 on inverse logit = 50%
    ) , data=dat_swfo , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_swfo <- precis( swfo , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a[1] -6.60 0.20 -6.94 -6.30  1321     1
#a[2] -5.94 0.16 -6.20 -5.69  1358     1

#contrast to see if treatment groups differ
postswfo <- extract.samples(swfo)
diffswfo <- inv_logit( postswfo$a[,1]) - inv_logit( postswfo$a[,2])
contrast_swfo <- precis( diffswfo )
#         mean   sd  5.5% 94.5%  histogram
#diffswfo    0  0    0     0  ▁▁▁▃▇▃▁▁

#numbers are too small to distinguish, so check the actual intervals...
HPDI(diffswfo) #Highest Posterior Density intervals, which are the same as is used in the precis (described as compatibility intervals) because our samples are from the posterior distribution
#        |0.89         0.89| 
#-0.0020248513 -0.0004803254 
#does not cross zero so the groups differ: manipulated birds have higher probability of switching
#mean(diffswfo) # -0.001279503 per sec
#sd(diffswfo) # 0.0004892852 per sec
#mean(diffswfo)*60 # -0.07677021 per min

# What is the probability that manipulated birds switch techniques per second or minute?
#mean(inv_logit(postswfo$a[,2])) #0.002658024/sec
#mean(inv_logit(postswfo$a[,2]))*60 # 0.1594814/min
# What is the probability that control birds switch techniques per second or minute?
#mean(inv_logit(postswfo$a[,1])) #0.00137852/sec
#mean(inv_logit(postswfo$a[,1]))*60 # 0.08271122/min

# How much more likely are the manipulated birds to switch?
#mean(inv_logit(postswfo$a[,2]))/mean(inv_logit(postswfo$a[,1])) # 1.928172
#sd(inv_logit(postswfo$a[,2]))/mean(inv_logit(postswfo$a[,1])) # 0.3055382
#HPDI(inv_logit(postswfo$a[,2]))/mean(inv_logit(postswfo$a[,1]))
#   |0.89    0.89| 
#1.435329 2.382249 


#TECHNIQUES: count the number of technique switches during each focal
#exclude NAs from the variables in this model
ft2 <- subset(ft1, is.na(ft1$How) == FALSE)
ft2 <- ft2[!ft2$How=="eat",]

ft2$TechSwitch<-NA
ft2[1,]$TechSwitch<-0
for(i in 2:nrow(ft2)){
  ifelse(ft2[i,]$FocalID==ft2[i-1,]$FocalID & ft2[i,]$How !=ft2[i-1,]$How, ft2[i,]$TechSwitch<-1,ft2[i,]$TechSwitch<-0)
}

ft3 <- ft2 %>% group_by(BirdID,FocalID) %>% summarise(switchesperfocal=sum(TechSwitch),timeperfocal=mean(TotalTimeInView))
ft4 <- ft3 %>% group_by(BirdID) %>% summarise(totalswitches=sum(switchesperfocal),totaltime=sum(timeperfocal))

# link with general datasheet to identify which birds were manipulated
c1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
c1 <- data.frame(c1)
#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
c1 <- c1[c1$Population=="AZ",]
ca<- c1 %>% group_by(BirdID) %>% summarise (Treatment=unique(FlexibilityManipulated))

ft5 <- left_join(ft4,ca,by="BirdID")
ft5 <- subset(ft5, is.na(ft5$Treatment) == FALSE)
#nrow(ft5) #NOTE: n=12 (5=manipulated, 7=control) birds because 6 dropped out due to not having any foraging events in their focals or not having any focals

# RUN the models
dat_sw <- list(switches = ft5$totalswitches,
            totaltime = ft5$totaltime, 
            treatment = as.integer(as.factor(ft5$Treatment)) #1=control, 2=manipulated
              )
sw <- ulam( alist(
        switches ~ dbinom(totaltime,p), 
        logit(p) <- a[treatment], #the intercept is the probability of observing any of the techs is different between groups, but this probability doesn't change over time (bc birds are observed only AFTER the manipulation is over). Include total observation time because this varied per focal (with a target max time of 10 min)
        a[treatment] ~ dnorm(0,1) #each treatment gets its own intercept, mean=0 bc assume an average bird might show half of the total techs, so 0 on inverse logit = 50%
    ) , data=dat_sw , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_sw <- precis( sw , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a[1] -6.83 0.28 -7.30 -6.41  1316     1
#a[2] -6.29 0.19 -6.61 -5.98  1449     1

#contrast to see if treatment groups differ
postsw <- extract.samples(sw)
diffsw <- inv_logit( postsw$a[,1]) - inv_logit( postsw$a[,2])
contrast_sw <- precis( diffsw )
#         mean   sd  5.5% 94.5%  histogram
#diffsw    0  0    0     0   ▁▁▅▇▅▁▁

#numbers are too small to distinguish, so check the actual intervals...
#HPDI(diffsw) #Highest Posterior Density intervals, which are the same as is used in the precis (described as compatibility intervals) because our samples are from the posterior distribution
#        |0.89         0.89| 
#-1.488057e-03 -1.877975e-05 
#does not cross zero so the groups differ: manipulated birds have higher probability of switching
#mean(diffsw) #-0.000773443
#sd(diffsw) #0.0004663716
#mean(diffsw)*60 #-0.04640658

# What is the probability that manipulated birds switch techniques per second or minute?
#mean(inv_logit(postsw$a[,2])) #0.001888756/sec, 0.1133254/min

# What is the probability that control birds switch techniques per second or minute?
#mean(inv_logit(postsw$a[,1])) #0.001115313/sec, 0.0669188/min

# How much more likely are the manipulated birds to switch?
#mean(inv_logit(postsw$a[,2]))/mean(inv_logit(postsw$a[,1])) # 1.693476
#sd(inv_logit(postsw$a[,2]))/mean(inv_logit(postsw$a[,1])) # 0.3263996
#HPDI(inv_logit(postsw$a[,2]))/mean(inv_logit(postsw$a[,1]))
#   |0.89    0.89| 
#1.187837 2.211168 


# EXTRA ANALYSIS: Do the control and manipulated birds differ in the amount of time they were in view? YES: manipulated were in view for more time
timeperfocal<-ft %>% group_by(BirdID,TotalTimeInView) %>% summarise(mean(TotalTimeInView))
timeperfocal <-left_join(timeperfocal,ca,by="BirdID")
timeperfocal <- subset(timeperfocal, is.na(timeperfocal$Treatment) == FALSE)
#boxplot(timeperfocal$TotalTimeInView~timeperfocal$Treatment) # doesn't look like a difference between groups
#hist(timeperfocal$TotalTimeInView) #normally distributed
#mean(900-timeperfocal$TotalTimeInView)/60 # an average of 1.9 min out of view per focal
v <- list(  totaltime = timeperfocal$TotalTimeInView, 
            treatment = as.integer(as.factor(timeperfocal$Treatment)) #1=control, 2=manipulated
              )
vm <- ulam( alist(
        totaltime ~ dnorm(mu,sigma), 
        mu <- a[treatment], 
        a[treatment] ~ dnorm(800,100), #using the estimated average and sd from the histogram above
        sigma ~ dexp(1)
    ) , data=v , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

#contrast to see if treatment groups differ
postvm <- extract.samples(vm)
diffvm <- ( postvm$a[,1]) - ( postvm$a[,2])
contrast_vm <- precis( diffvm )
#         mean   sd  5.5% 94.5%  histogram
#diffvm -56.21 30.12 -104.26 -9.07 ▁▁▂▃▇▇▅▂▁▁▁
#manipulated birds have more time in view than control birds. Control birds had less time in view and had fewer switches so we need to figure out of their lower switching rate was due to having less time in view using a simulation

# SIMULATION: Did the time out of view affect the switch rate that we are estimating and can this potentially explain the difference the switch rate between manipulated and control birds?

#get the proportion of different food types eaten so can model the prabability of eating different food types
fop <- as.factor(fo$What)
propfoodtypes <- table(fop$What) 

# The time out of view does not affect observed switch rate. Confirmed this using a simulation that shows that the estimation of the switching rate is not affected by excluding the time period in which the bird was out of view when using an average of 2.2 min out of view over a 15 min focal follow period (similar to the actual average 1.9 min out of view in our sample (see calculation above). While the target maximum was 10 min per focal, 15 min was allowed if the bird went out of view to give the observer time to re-find the bird if possible)
library(rethinking)
library(tidyr)
library(dplyr)

#make lists for storing results
observedtime_different<-NA
missing_minutes<-NA
mean_difference<-NA

max_obstime<-15 # a given focal could last for a maximum of 15 minutes
individuals<-12 # number of individuals for whom we have both actual observations and observations with missing time - similar to the number of control individuals

for(simulations in 1:100) { # repeat the simulation 100 times to see how often missing minutes leads to a difference in the estimated switching rate
control_birds<-as.data.frame(matrix(rbern(individuals*max_obstime,prob=0.22),ncol=max_obstime,nrow=individuals)) # there is a 22% probability that a bird will eat anything at a given minute, 0.22 * 15 min = avg 3.3 feeding events per focal, which should lead to the observed switching rate of 1.8 (0.12 switches per minute * 15 min focal was the avg switching rate across all birds). Wanted the observed feeding events to be at least the switching rate plus 1 because the number of swtiches is always at least 1 smaller than the number of feeding events. Checked after the simulation whether the resulting switching rate in the simulation is 0.12 and it is.

control_birds$totaleatingobs<-apply(control_birds,1,sum) #add a column
foodeaten<-control_birds[,1:max_obstime]*sample(c(1:20),sum(control_birds[,1:max_obstime]),replace=T,prob=c(0.45,0.2,0.1,0.05,0.05,rep(0.01,15))) # 20 different food types; most common one occurs 45% of times, others 20%, 10%, 5%, 5%, and 15 food types 1% of times). Converts each eating event to one of the 20 food types

#convert 1 row/focal to 1 row/min = 15 rows per focal
foodeaten_l<-as.data.frame(pivot_longer(foodeaten,cols=c(1:max_obstime)))
foodeaten_l$focalid<-rep(1:individuals,each=max_obstime)

#remove minutes where a bird didn't eat anything
foodeaten_l_r<-foodeaten_l[foodeaten_l$value!=0,]
foodeaten_l_r$TechSwitch<-0

#calculate whether switch occurred or not in any given minute
for(obsswitches in 2:nrow(foodeaten_l_r)){
  ifelse(foodeaten_l_r[obsswitches,]$focalid==foodeaten_l_r[obsswitches-1,]$focalid & foodeaten_l_r[obsswitches,]$value != foodeaten_l_r[obsswitches-1,]$value,foodeaten_l_r[obsswitches,]$TechSwitch<-1,foodeaten_l_r[obsswitches,]$TechSwitch<-0)
}

#calculate the sum of switches per focal
actual_switches_sim<-data.frame(foodeaten_l_r %>% group_by(focalid) %>% summarise(actualsimswitchesperfocal=sum(TechSwitch)))

#add unique focal id to join data sheets
control_birds$focalid<-c(1:individuals)
control_birds<-left_join(control_birds,actual_switches_sim,by="focalid")

#create data for individuals who were not observed the whole time
missing_birds<-control_birds
missing_birds$observedtime<-max_obstime
foodeaten_missing<-foodeaten
for(missingobs in 1:nrow(foodeaten_missing)){
  missingminutes<-rbinom(1,max_obstime,prob=0.15) # there is a 15% chance that any minute will be missing, which means that on average 0.15 * 15 = 2.25 minutes will be missing from a 15 minute focal
  if(missingminutes>0){
    startminute<-round(runif(1,1,max_obstime-missingminutes),0)
    foodeaten_missing[missingobs,startminute:(startminute+(missingminutes-1))]<-NA
    missing_birds[missingobs,]$observedtime<-max_obstime-missingminutes
  }
}

#repeat calculations of number of switches for birds with missing data
foodeaten_l_missing<-as.data.frame(pivot_longer(foodeaten_missing,cols=c(1:max_obstime)))
foodeaten_l_missing$focalid<-rep(1:individuals,each=max_obstime)
foodeaten_l_r_missing<-foodeaten_l_missing[foodeaten_l_missing$value!=0,]
foodeaten_l_r_missing<-foodeaten_l_r_missing[is.na(foodeaten_l_r_missing)==F,]
foodeaten_l_r_missing$TechSwitch<-0
for(missingswitches in 2:nrow(foodeaten_l_r_missing)){
    ifelse(foodeaten_l_r_missing[missingswitches,]$focalid==foodeaten_l_r_missing[missingswitches-1,]$focalid & foodeaten_l_r_missing[missingswitches,]$value != foodeaten_l_r_missing[missingswitches-1,]$value,foodeaten_l_r_missing[missingswitches,]$TechSwitch<-1,foodeaten_l_r_missing[missingswitches,]$TechSwitch<-0)
}

observed_switches_sim<-data.frame(foodeaten_l_r_missing %>% group_by(focalid) %>% summarise(observedsimswitchesperfocal=sum(TechSwitch)))
missing_birds<-left_join(missing_birds,observed_switches_sim,by="focalid")
missing_birds$actualtime<-max_obstime
missing_birds<-missing_birds[is.na(missing_birds$actualsimswitchesperfocal)==F,]
missing_birds<-missing_birds[is.na(missing_birds$observedsimswitchesperfocal)==F,]

#calculate the rate of switching for birds with full and partial observation time
mean(missing_birds$actualsimswitchesperfocal/missing_birds$actualtime)
mean(missing_birds$observedsimswitchesperfocal/missing_birds$observedtime)

#create data frame to calculate contrst
dat_list<-list(
  time=c(missing_birds$actualtime,missing_birds$observedtime),
  switch_sim=c(missing_birds$actualsimswitchesperfocal,missing_birds$observedsimswitchesperfocal),
  missing=c(rep(1,nrow(missing_birds)),rep(2,nrow(missing_birds))) # category 1 is full observation time, category 2 is with reduced time due to birds being out of view
)

#run the model
m_missing<-ulam(
  alist(
    switch_sim ~ dbinom(time,p),
    logit(p)<-a[missing],
    a[missing]~dnorm(-0.5,1)
  ),data=dat_list,chains=4,cores=4,cmdstan=T,messages=FALSE,refresh=0)

#calculate contrast to see if birds with missing time have a different switching rate than birds with full observation time
precis(m_missing,depth=2)
post<-extract.samples(m_missing)
contrast<-inv_logit(post$a[,2])-inv_logit(post$a[,1])

#extract simulation results
observedtime_different[simulations]<-ifelse(as.numeric(HPDI(contrast)[1])*as.numeric(HPDI(contrast)[2])<0,0,1)
missing_minutes[simulations]<-mean(missing_birds$actualtime-missing_birds$observedtime)
mean_difference[simulations]<-precis(contrast)[1,1]
print(simulations)
}

#summarizing results
sum(observedtime_different)/100 # In what percentage of the simulations is there an observable difference (contrast does not overlap zero)
hist(mean_difference,xlim=c(-0.06,0.06)) # The contrast is for how different observations of birds with missing time are compared to birds with a full observation. In more than half of cases, the estimated probability of switching is smaller when birds were out of view because we are missing the rare feeding events, but there are also instances where the estimated probability of switching is higher because all feeding events were observed so the number of switches is calculated over the reduced instead of the total time leading to a higher rate. 
mean(mean_difference) # -0.00675478 - we would expect that on average a reduction in observation time of 2.25 minutes leads to a 0.6% lower estimated probability of switching
mean(missing_birds$actualsimswitchesperfocal)/mean(missing_birds$actualtime) # 12% switching probability per minute - halfway between the 16% of manipulated and the 8% of control birds




# VISUALIZE
#make new variables of probability of switching per minute
fo4$probswitchfo <- (fo4$totalfoodswitches/fo4$totaltime)*60
ft5$probswitch <- (ft5$totalswitches/ft5$totaltime)*60

op <- par(mfrow=c(1,2), mar=c(3,4.9,2,0.9))
plot( as.integer(as.factor(fo4$Treatment))+rnorm(13,0,0.1) , fo4$probswitchfo , xlab="" , ylab="Probability of switching among food types / min" , ylim=c(0,0.3), xlim=c(0.5,2.5), xaxt="n")
points(inv_logit(precis(swfo,depth=2)[1,1])*60 ~ c(1.1),cex=2)
lines(c(inv_logit(precis(swfo,depth=2)[1,3])*60,inv_logit(precis(swfo,depth=2)[1,4])*60) ~ c(1.1,1.1))
points(inv_logit(precis(swfo,depth=2)[2,1])*60 ~ c(1.9),cex=2)
lines(c(inv_logit(precis(swfo,depth=2)[2,3])*60,inv_logit(precis(swfo,depth=2)[2,4])*60) ~ c(1.9,1.9))
mtext("A",side=3,outer=FALSE,adj=0,font=1,cex=1,line=0.2)
mtext("Control",side=1,at=0.9,outer=FALSE,adj=0,font=1,cex=1,line=0.6)
mtext("Manipulated",side=1,at=1.7,outer=FALSE,adj=0,font=1,cex=1,line=0.6)

plot( as.integer(as.factor(ft5$Treatment))+rnorm(12,0,0.1) , ft5$probswitch , xlab="" , ylab="Probabiity of switching among foraging techniques / min" , ylim=c(0,0.3), xlim=c(0.5,2.5), xaxt="n")
points(inv_logit(precis(sw,depth=2)[1,1])*60 ~ c(1.1),cex=2)
lines(c(inv_logit(precis(sw,depth=2)[1,3])*60,inv_logit(precis(sw,depth=2)[1,4])*60) ~ c(1.1,1.1))
points(inv_logit(precis(sw,depth=2)[2,1])*60 ~ c(1.9),cex=2)
lines(c(inv_logit(precis(sw,depth=2)[2,3])*60,inv_logit(precis(sw,depth=2)[2,4])*60) ~ c(1.9,1.9))
mtext("B",side=3,outer=FALSE,adj=0,font=1,cex=1,line=0.2)
mtext("Control",side=1,at=0.9,outer=FALSE,adj=0,font=1,cex=1,line=0.6)
mtext("Manipulated",side=1,at=1.7,outer=FALSE,adj=0,font=1,cex=1,line=0.6)
par(op)

# a plot with time along the xaxis, but the above plot better shows our results
#op <- par(mfrow=c(2,1), mar=c(5.9,4.9,2,0.9))
#food types plot
#plot( fo4$totaltime , fo4$totalfoodswitches , xlab="" , ylab="Switches among food types" , col=ifelse( dat_swfo$treatment==1 , 4 , 2 ) , lwd=4+4*normalize(k) , ylim=c(0,15) , cex=1+normalize(k) )
#time_seq <- seq(from=min(dat_swfo$totaltime),to=max(dat_swfo$totaltime),length=100)
#time_seq_unst<-seq(from=min(fo4$totaltime),to=max(fo4$totaltime),length=100)
#lambda <- link( swfo , data=data.frame( totaltime=time_seq , treatment=1 ) )
#lmu <- apply( lambda , 2 , mean )
#lci <- apply( lambda , 2 , PI )
#lci.plot<-matrix(NA,ncol=length(time_seq_unst),nrow=2)
#lci.plot[1,]<-lci[1,1]*time_seq_unst
#lci.plot[2,]<-lci[2,1]*time_seq_unst
#lines( time_seq_unst , lmu*time_seq_unst , lty=2 , lwd=1.5 )
#shade( lci.plot , time_seq_unst , xpd=TRUE , col=col.alpha(4,0.3))
#lambda <- link( swfo , data=data.frame( totaltime=time_seq , treatment=2 ) )
#lmu <- apply( lambda , 2 , mean )
#lci <- apply( lambda , 2 , PI )
#lci.plot<-matrix(NA,ncol=length(time_seq_unst),nrow=2)
#lci.plot[1,]<-lci[1,1]*time_seq_unst
#lci.plot[2,]<-lci[2,1]*time_seq_unst
#lines( time_seq_unst , lmu*time_seq_unst , lty=1 , lwd=1.5 )
#shade( lci.plot , time_seq_unst , xpd=TRUE , col=col.alpha(2,0.3) )
#points(fo4[fo4$Treatment=="No",]$totalfoodswitches~fo4[fo4$Treatment=="No",]$totaltime,pch=1)
#points(fo4[fo4$Treatment=="Yes",]$totalfoodswitches~fo4[fo4$Treatment=="Yes",]$totaltime,pch=2,col="black")
#legend(x="topleft", y=8, legend=c(pch1="Control", pch2="Manipulated"), pch=c(1,2), col=c("Black","Black"), box.lty=1, cex=1.5)
#mtext("A",side=3,outer=FALSE,adj=0,font=1,cex=1.5,line=0.6)
#techs plot
#plot( ft5$totaltime, ft5$totalswitches , xlab="Total observation time (sec)" , ylab="Switches among foraging techniques" , col=ifelse( dat_sw$treatment==1 , 4 , 2 ) , lwd=4+4*normalize(k) , ylim=c(0,15) , cex=1+normalize(k) )
#time_seq <- seq(from=min(dat_sw$totaltime),to=max(dat_sw$totaltime),length=100)
#time_seq_unst<-seq(from=min(ft5$totaltime),to=max(ft5$totaltime),length=100)
#lambda <- link( sw , data=data.frame( totaltime=time_seq , treatment=1 ) )
#lmu <- apply( lambda , 2 , mean )
#lci <- apply( lambda , 2 , PI )
#lci.plot<-matrix(NA,ncol=length(time_seq_unst),nrow=2)
#lci.plot[1,]<-lci[1,1]*time_seq_unst
#lci.plot[2,]<-lci[2,1]*time_seq_unst
#lines( time_seq_unst , lmu*time_seq_unst , lty=2 , lwd=1.5 )
#shade( lci.plot , time_seq_unst , xpd=TRUE , col=col.alpha(4,0.3))
#lambda <- link( sw , data=data.frame( totaltime=time_seq , treatment=2 ) )
#lmu <- apply( lambda , 2 , mean )
#lci <- apply( lambda , 2 , PI )
#lci.plot<-matrix(NA,ncol=length(time_seq_unst),nrow=2)
#lci.plot[1,]<-lci[1,1]*time_seq_unst
#lci.plot[2,]<-lci[2,1]*time_seq_unst
#lines( time_seq_unst , lmu*time_seq_unst , lty=1 , lwd=1.5 )
#shade( lci.plot , time_seq_unst , xpd=TRUE , col=col.alpha(2,0.3) )
#points(ft5[ft5$Treatment=="No",]$totalswitches~ft5[ft5$Treatment=="No",]$totaltime,pch=1)
#points(ft5[ft5$Treatment=="Yes",]$totalswitches~ft5[ft5$Treatment=="Yes",]$totaltime,pch=2,col="black")
#mtext("B",side=3,outer=FALSE,adj=0,font=1,cex=1.5,line=0.6)
#par(op)
```


## P3: flexible = more human foods

**Analysis:** A GLMM was conducted as in P1-P2, except this GLMM used a binomial distribution (called "categorical" in MCMCglmm) due to the response variable being a proportion.

```{r p3humanfood, eval=FALSE}
library(rethinking)
library(dplyr)

# LOAD the General data sheet
b1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
b1 <- data.frame(b1)


### PROPORTION HUMAN FOOD
#exclude NAs from the variables in this model
fo <- subset(b1, is.na(b1$PropHumanFood) == FALSE) #note that this also eliminates the NAs for foraging techniques for the same birds bc NAs were always in both variables for the same birds
fo <- subset(fo, is.na(fo$SumFocalTime) == FALSE)
fo <- subset(fo, is.na(fo$Phi) == FALSE)
fo <- subset(fo, is.na(fo$Lambda) == FALSE)
fo <- subset(fo, is.na(fo$DomRank) == FALSE)
length(unique(fo$BirdID)) #35 individuals

#Separate the sexes
f <- fo[fo$Sex=="F",]
m <- fo[fo$Sex=="M",]

#sample sizes
length(unique(f$BirdID)) #9 females
length(unique(m$BirdID)) #26 males
mean(f$NumFollows) #4.2 follows for females
range(f$NumFollows) #1-6 follows for females
mean(m$NumFollows) #4.6 follows for females
range(m$NumFollows) #1-8 follows for females


# SIMULATION
n = 50
ph = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
la =  rnorm(n,mean=0,sd=1) #lambda can range from 0 to 9, but standardize by making mean=0 and SD=2
r = rnorm(n,mean=0,sd=1) #rank can range from -1 to 1, but standardize it
mod = rbinom(n=n,size=1, prob=inv_logit(rnorm(n,mean=(0.5*ph + 0.25*la + 0.5*r),sd=0.1))) #Now change the mean: a=4 which makes the phis and lambdas positive which is what we need, betas are the 1s before p, l, and r;  b=1/6000. If you have been observed for the full 600s, the probability of having more foraging techniques increases by 0.1 with the 1/6000 term
plot(mod~ph)
plot(mod~la)
#plots look good - any relationship is possible, but all values are within the feasible range

#run the simulated data through the model
s_type <- list(mod = mod,
               phi = ph,
               lambda = la,
               r = r
              )
simtype <- ulam( alist(
        mod ~ dbinom(1,p), #max 22 food types across AZ & CA (from data_FlexForaging > Foraging > How, and then counted the categories)
        logit(p) <- a + bp*phi + bl*lambda + br*r, #include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), 
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=s_type , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
precis( simtype , depth=2 )
#   mean   sd  5.5% 94.5% n_eff Rhat4
#
#check bp and bl to see if it crosses zero. neff and rhat look good


# RUN the models
## FEMALE - food types - bc the dependent variable is a proportion, it already accounts for the total number of observations, therefore don't need to include observation time
fe <- list(foods = f$PropHumanFood,
            phi = standardize(as.numeric(f$Phi)),
            lambda = standardize(as.numeric(f$Lambda)),
            rank = standardize(f$DomRank)
              )
set.seed(19)
fe_binom <- ulam( alist(
        foods ~ dbinom(1,p), 
        logit(p) <- a + bp*phi + bl*lambda + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        bp ~ dnorm(0,1), #standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=fe , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

precis( fe_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -1.05 0.64 -2.08 -0.01  1568     1
#bp -0.35 0.78 -1.63  0.87  1897     1
#bl  1.01 0.69 -0.07  2.12  1914     1
#br  0.14 0.70 -0.97  1.27  2107     1
#prophumanfoods are not strongly related with phi/lambda


## MALE - food types - bc the dependent variable is a proportion, it already accounts for the total number of observations, therefore don't need to include observation time
ma <- list(foods = m$PropHumanFood,
            phi = standardize(as.numeric(m$Phi)),
            lambda = standardize(as.numeric(m$Lambda)),
            rank = standardize(m$DomRank)
              )
set.seed(119)
ma_binom <- ulam( alist(
        foods ~ dbinom(1,p), 
        logit(p) <- a + bp*phi + bl*lambda + br*rank, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        bp ~ dnorm(0,1), #standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1)
    ) , data=ma, chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

precis( ma_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -1.25 0.47 -2.03 -0.51  2053     1
#bp -0.07 0.49 -0.83  0.70  1816     1
#bl  0.64 0.48 -0.12  1.43  2092     1
#br  0.60 0.55 -0.23  1.52  1580     1
#prophumanfoods are not strongly related with phi/lambda

#Have a look at the data to confirm
plot(f$PropHumanFood~f$Phi)
plot(f$PropHumanFood~f$Lambda)
plot(m$PropHumanFood~m$Phi)
plot(m$PropHumanFood~m$Lambda)

#sample sizes
head(fe) #n=9 females
head(ma) #n=26 males



### Correlation between proportion HUMAN FOODS taken and foraging TECHNIQUES
## FEMALE - prop human food and foraging TECHNIQUES
fet <- list(foods = f$PropHumanFood,
            tech = standardize(as.numeric(f$NumForageTechs))
              )
set.seed(190)
fet_binom <- ulam( alist(
        foods ~ dbinom(1,p), #max 22 food types
        logit(p) <- a + bt*tech, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        bt ~ dnorm(0,1) #standardized
    ) , data=fet , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

precis( fet_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -0.87 0.64 -1.95  0.12  1018     1
#bt -0.33 0.64 -1.40  0.67  1161     1
#prophumanfoods are not strongly related with foraging techniques


## MALE - prop human food and foraging TECHNIQUES
mat <- list(foods = m$PropHumanFood,
            tech = standardize(m$NumForageTechs)
              )
set.seed(119)
mat_binom <- ulam( alist(
        foods ~ dbinom(1,p), #max 22 food types
        logit(p) <- a + bt*tech, 
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        bt ~ dnorm(0,1) 
    ) , data=mat, chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

precis( mat_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -1.15 0.43 -1.85 -0.46  1014  1.01
#bt -0.73 0.50 -1.54  0.05  1258  1.00
#prophumanfoods are not strongly related with foraging techniques

#Have a look at the data to confirm
plot(f$PropHumanFood~f$NumForageTechs)
plot(m$PropHumanFood~m$NumForageTechs)

#sample sizes
head(fet) #n=9 females
head(mat) #n=26 males



### DISTANCE to outdoor human food sources
#If distance per bird is repeatable, then use the avg distance per bird as the dependent variable

# REPEATABILITY of DISTANCE: Is distance from outdoor cafes a REPEATABLE trait within individuals, as measured with a GPS point of individual locations during several separate focal follows
library(DHARMa)
rpt.dist <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_P3repeatability.csv"), header=T, sep=",", stringsAsFactors=F)
rpt.dist <- data.frame(rpt.dist)
rpt.dist$BirdID = as.factor(rpt.dist$BirdID)
rpt.dist$Sex = as.factor(rpt.dist$Sex)
rpt.dist$Season = as.factor(rpt.dist$Season)
#check which distribution to use
hist(log(rpt.dist$DistHumanFood))
simulationOutput <- simulateResiduals(fittedModel = lmer(log(DistHumanFood) ~ FollowNumber + Sex + Season + (1|BirdID), data=rpt.dist), n=500)

plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor. = Yes
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation.
#p.g=0.7, p.p=0.1
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p>0.05.
#p.g=1, p.p=1
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05.
#p.g=0.01, p.p<0.001
plot(simulationOutput) 
# log-transformed distance with a gaussian distribution is best. Though there is some evidence for heteroscedasticity. KS test p=0.0072 deviation significant

#run the model to test for repeatability
library(rptR)
library(MCMCglmm)
d1 <- rpt(log(DistHumanFood) ~ FollowNumber + Sex + Season + (1|BirdID), grname = "BirdID", data = rpt.dist, datatype = "Gaussian", nboot = 1000, npermut = 300)
d1 # R = 0.28, CI = 0.16-0.39, p = 0.003

prior = list(R=list(R1=list(V=1,nu=0.002)), G=list(G1=list(V=1,nu=0.002))) #weak priors
mc1 = MCMCglmm(log(DistHumanFood) ~ FollowNumber + Sex + Season, random = ~BirdID, family = "gaussian", data = rpt.dist,
               verbose=F, prior=prior, nitt=500000, thin=500, burnin=3000)
plot(mc1) #all chains look good
autocorr(mc1$Sol) #Did fixed effects converge? (<0.1)? Yes
autocorr(mc1$VCV) #Did random effects converge? (<0.1)? Yes
repeata <- mc1$VCV[,"BirdID"]/(mc1$VCV[,"BirdID"]+mc1$VCV[,"units"]) #latent scale adjusted repeatability and its credible interval
mean(repeata) # Repeatability: 0.27
var(repeata) # 0.004
posterior.mode(repeata) # 0.26
HPDinterval(repeata, 0.95) # 0.14 - 0.39

## YES - distance is repeatable of each individual to a human food location across focal follows

#If repeatable, take average distance across focal follows per bird to model relationship with flexibility
tmp = aggregate(DistHumanFood ~ BirdID, FUN = "mean", data = rpt.dist)
general = read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
general = merge(tmp, general, by = "BirdID",all = T)
general = general[!is.na(general$Sex),]
#write.csv(general, "g_flexforaging_data_general.csv")





### Number of outdoor human food sources PER HOME RANGE
# LOAD the foraging data sheet
f1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
f1 <- data.frame(f1)

# only include the columns I want to add to the general data sheet
f2 <- subset(f1, select=c(BirdID,NumberHumanFood))
colnames(f2) = c("BirdID","NumberHumanFoodSourcesInHomeRance")

###### I AM HERE!!!! To do next....
#reduce the number of rows to only 1 per bird

# Add the column number of human food sources inside a home range to the general data sheet
hr <- left_join(b1,f2,by="BirdID")
ft3 <-  #1st entry=data sheet (b1) to which I want to add the info from the second entry (ft2)
ft3[is.na(ft3$SumFoodEvents)==TRUE,]$SumFoodEvents <- 0  #add zeros to birds who had focals but were never observed eating
ft3[ft3$SumFocalTime==0,]$SumFoodEvents <- NA 
#write.csv(ft3,file="g_flexforaging_data_general.csv") #uploaded this to github so now can just use the SumFoodEvents column in the general data sheet



# SIMULATION
n = 100
ph = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
la =  rnorm(n,mean=0,sd=1) #lambda can range from 0 to 9, but standardize by making mean=0 and SD=2
r = rnorm(n,mean=0,sd=1) #rank can range from -1 to 1, but standardize it
fevent = rnorm(n,mean=0,sd=1) #number of food events per bird can range from 0 and up, but standardize it
mod = rbinom(n=n,size=22, prob=inv_logit(rnorm(n,mean=(0.25*ph + 0.5*la + 1*r + 1*fevent),sd=0.2))) #22 food types eaten.
plot(mod~ph)
plot(mod~la)
#plots look good - any relationship is possible, but all values are within the feasible range

#Simulation with observation time in
#time =  600-rexp(n=n,rate=1/50) #each focal follow was 10 min (600 sec), but many weren't able to be conducted for this long bc the bird went out of view. Expect most follows to have met the 10 min criteria
#model = rbinom(n=n,size=22, prob=inv_logit(rnorm(n,mean=(0.25*ph + 0.5*la + 1*r + (1/6000)*time),sd=0.2))) #22 food types eaten. Now change the mean: a=4 which makes the phis and lambdas positive which is what we need, betas are the 1s before p, l, and r;  b=1/6000. If you have been observed for the full 600s, the probability of having more foraging techniques increases by 0.1 with the 1/6000 term

#run the simulated data through the model
s_type <- list(mod = mod,
               phi = ph,
               lambda = la,
               r = r,
               fevent = fevent
              )
simtype <- ulam( alist(
        mod ~ dbinom(22,p), #max 22 food types across AZ & CA (from data_FlexForaging > Foraging > How, and then counted the categories)
        logit(p) <- a + bp*phi + bl*lambda + br*r + bf*fevent, #include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), 
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        bf ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=s_type , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
s_outputtype <- precis( simtype , depth=2 )
#   mean   sd  5.5% 94.5% n_eff Rhat4
#a  0.06 0.05 -0.02  0.14  2546     1
#bp 0.25 0.06  0.17  0.34  2238     1
#bl 0.50 0.06  0.40  0.59  2539     1
#br 1.00 0.06  0.90  1.10  2112     1
#bf 1.06 0.06  0.97  1.15  2292     1
#check bp and bl to see if it crosses zero. neff and rhat look good


# RUN the models
## FEMALE - food types
fe <- list(foods = f$,
            events = standardize(f$SumFoodEvents),
            phi = standardize(as.numeric(f$Phi)),
            lambda = standardize(as.numeric(f$Lambda)),
            rank = standardize(f$DomRank)
              )
set.seed(9)
fe_binom <- ulam( alist(
        foods ~ dbinom(22,p), #max 22 food types
        logit(p) <- a + bp*phi + bl*lambda + br*rank + be*events, #the intercept is the probability of observing any of the food types. Include total observation time because this varied per focal (with a target max time of 10 min)
        a ~ dnorm(0,1), #intercept, mean=0 bc assume an average bird might show half of the total food types, so 0 on inverse logit = 50%
        bp ~ dnorm(0,1),
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        be ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=fe , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output_fe_binom <- precis( fe_binom , depth=2 )
#      mean   sd  5.5% 94.5% n_eff Rhat4
#a  -2.69 0.31 -3.18 -2.22  1297     1
#bp -0.61 0.47 -1.41  0.05  1066     1
#bl -0.46 0.35 -1.03  0.10  1240     1
#br  0.27 0.32 -0.21  0.79  1402     1
#be  0.26 0.27 -0.19  0.69  1129     1
#look at bp and bl to see if a relationship with foods: food types and phi/lambda are not strongly related in females







#---OLD---
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)

ff <- data.frame(ff)

#exclude NAs from the DomRank column
ff <- subset(ff, is.na(ff$DomRank) == FALSE)

#Separate the sexes
ff <- ff[ff$Sex=="F",]
mal <- ff[ff$Sex=="M",]

#Factor the random effect variables
ff$ID <- as.factor(ff$BirdID)
ff$Population <- as.factor(ff$Population)
mal$ID <- as.factor(mal$BirdID)
mal$Population <- as.factor(mal$Population)

#sample sizes
length(unique(ff$ID)) #9 ffales
length(unique(mal$ID)) #26 males

# DATA CHECKING
library(DHARMa)
library(lme4)

#Data checking for ffale GLMM
simulationOutput <- simulateResiduals(fittedModel = glmer(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime + (1|ID) + (1|Population), family=binomial, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(ProportionFoodsEatenHumanFood, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM
simulationOutput <- simulateResiduals(fittedModel = glmer(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime + (1|ID) + (1|Population), family=binomial, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(ProportionFoodsEatenHumanFood, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet


#GLMM
library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0),R2=list(V=1,nu=0),R3=list(V=1,nu=0),R4=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0),G2=list(V=1,nu=0)))

#GLMM with response variable = NumberFoodsEaten
#females
set.seed(15)
f1 <- MCMCglmm(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime, random=~Population+ID, family="categorical", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
set.seed(16)
f2 <- MCMCglmm(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime, random=~Population+ID, family="categorical", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?





# P3 Distance to human food locations and flexibility

d2 <- MCMCglmm(avg_dist ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="categorical", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
d2

# Number of outdoor cafes within the home range of each individual, measured by calculating home range size and then summing the number of cafes.
distance <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
distance <- data.frame(distance)

#Load packages
library(adehabitatHR)
library(sf)
#Point to the correct data file and load it
setwd("~/Documents/Grackle project/Space use")
pts<-read.csv("gtgr_points.csv", header = T)
#Set variables to ensure the models read the data properly
pts$Latitude = as.numeric(as.character(pts$Latitude))
pts$Longitude = as.numeric(as.character(pts$Longitude))
pts$Date = as.character(pts$Date)
pts$Time = as.character(pts$Time)
pts$da.ti = as.POSIXct(paste(pts$Date, pts$Time), format="%Y-%m-%d %H:%M:%S")
#Home range size can only be calculated when a bird has more than 5 relocations
#Count the number of relocations for each bird, then exclude individuals with less than 6
tmp = pts
tmp$count = 1
tmp = aggregate(count ~ Bird.Name, FUN = "sum", data = tmp)
pts.min = merge(pts, tmp, by = "Bird.Name", all = T)
pts.min = pts.min[-which(pts.min$count<6),]
pts.min$Bird.Name = as.factor(as.character(pts.min$Bird.Name))
#Convert dataframe to Spatial file type
p.sf <- st_as_sf(pts.min, coords = c("Longitude", "Latitude"), crs = 4326) 
class(p.sf) 
p.spatial <- as(p.sf, "Spatial")
class(p.spatial)
#Calculate home range in square meters for each individual, excluding outliers
hr = mcp(p.spatial[1], percent = 100, unout = "m2")
plot(hr)
#Read in dataframe with cafe locations
cafs<-read.csv("cafe_points.csv", header = T)
#Convert to spatial points dataframe
c <- SpatialPointsDataFrame(cafs)
#Count the number of cafes in each home range polygon
cafes <- over(c, hr)
cafe_data <- table(cafes$NAME_1)
cafe_data <- merge(cafe_data, ff, by = "ID")

set.seed(17)
c1 <- MCMCglmm(NumberCafesInTerritory ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="categorical", data=cafe_data, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(c1)
```

## P4: Flexibility and social bonds

The social network is... (say something general about Figure) (Figure).

```{r p4pt1socialnetwork, eval=T}
### Create social network graph figure from associations between banded birds ###
#Load social data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

#Exclude unbanded birds
ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 

ff1 <- subset(ff1, is.na(ff1$FocalBirdID) == FALSE) #257 banded-banded bird associations
ff1aff <- subset(ff1, ff1$BehavType == "affiliative")
ff2 = aggregate(TimeStamp ~ Date + FocalBirdID + NonFocalBirdID + Site, data = ff1aff, FUN = "max") #only one observation of banded-banded pair per sampling period is allowed, for 111 banded-banded associations

library(igraph)
library(sna)
#Create an edgelist - a two column matrix of birds seen together
el = ff2
#since these are undirected associations, symmetrize the associations so all are in the same order and repeat pairs can be identified
colnames(el)[c(2,3)]=c("ID.1","ID.2")
el$ID.1 = as.character(el$ID.1)
el$ID.2 = as.character(el$ID.2)
for (i in 1:nrow(el)) {
  tmp = el[i, c("ID.1", "ID.2")]
  tmp = tmp[,sort.list(tmp)] 
  el[i, "ID.1"] = tmp[,1]
  el[i, "ID.2"] = tmp[,2]
}

#calculate edge weights using the half-weight index by quantifying the number of times two birds are seen together (x), the number of times bird 1 is seen without bird 2 (Y.1), and the number of times bird 2 is seen without bird 1 (Y.2)
el$count = 1
x = aggregate(count ~ ID.1 + ID.2, data = el, FUN = "sum") #how many times are bird 1 and bird 2 observed together
colnames(x)[3]="x"

tmp = el[,c(2,4)]
colnames(tmp)[1] = "ID"
tmp2 = el[,c(3,4)]
colnames(tmp2)[1] = "ID"
y = rbind(tmp, tmp2)
y$count = 1
y = aggregate(count ~ ID + Site, data = y, FUN = "sum") #how many times each bird is seen individually
colnames(y)[3] = "y"

colnames(y)[1] = "ID.1" 
hwi = merge(x,y, by = "ID.1", all = T)
hwi$Y.1 = hwi$y - hwi$x #the number of times bird 1 was seen without bird 2
hwi = hwi[,-5]
colnames(y)[1] = "ID.2"
hwi = merge(hwi,y, by = c("ID.2","Site"), all = T)
hwi$Y.2 = hwi$y - hwi$x #the number of times bird 2 was seen without bird 1
hwi = hwi[-which(is.na(hwi$x)),-6] #data frame ready for half-weight index equation
hwi$hwi = hwi$x/(0.5*(hwi$Y.1 + hwi$Y.2)+hwi$x)

#convert data to adjacency graph for calculating social network metrics
Y = as.matrix(hwi)
labels <- unique( c(Y[,1], Y[,3]) ) #make sure the matrix indices labels match hwi columns for ID.1 and ID.2
A <- matrix(0, length(labels), length(labels))
rownames(A) <- colnames(A) <- labels
A[ Y[,c(1,3)] ] <- as.numeric( Y[,7] ) #make sure the matrix numeric index is matched with the hwi column for hwi.
Ya = graph.adjacency(A, weighted = T, mode = "max", diag = F)

#graphical representation of the data, including all individuals seen from both sites (ie. we did not exclude grackles who did not meet the minimum focal follow sample size for the plot)
l <- layout_with_fr(Ya)
l <- norm_coords(l, ymin=-8, ymax=8, xmin=-8, xmax=8)
E(Ya)$weight <- hwi$hwi #link hwi to graph for edge weights
V(Ya)$Site=as.character(y$Site[match(V(Ya)$name,y$ID.2)])#link Site info to graph vertices (bird IDs)
V(Ya)$color=V(Ya)$Site 
V(Ya)$color=gsub("AZ","gray",V(Ya)$color) 
V(Ya)$color=gsub("CA","lightblue",V(Ya)$color)
deg <- igraph::degree(Ya)
V(Ya)$size <- deg*2

plot(Ya, layout = l*8.0, 
     edge.width =E(Ya)$weight*10,
     vertex.color = V(Ya)$color,
     size = V(Ya)$size*10,
     vertex.label.cex=1,
     vertex.label.color = "black")
```

**Figure.** Social network of the Arizona (red) and California (blue) grackles.


```{r p4pt2socnetmetrics, eval = F}
### Now we can quantify social network metrics on individuals with the minimum number of focal follows ###
### We do not have enough breeding season data, so we are only using nonbreeding season data. Which birds meet the minimum requirement of 4 total follows?

#load attribute data
g <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
g <- data.frame(g)

#load social association data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

#Exlude aggressive assocations
ff1aff <- subset(ff, ff$BehavType == "affiliative")

# Only want non-breeding season data
# separate Sites because breeding started earlier in AZ
ff_AZ = ff1aff[which(ff1aff$Site == "AZ"),]
ff_AZ$Date = as.Date(ff_AZ$Date, format = "%Y-%m-%d")
ffAZ_nbs = ff_AZ[which(ff_AZ$Date < "2019-03-08" | c(ff_AZ$Date > "2019-08-31" & ff_AZ$Date < "2020-03-08")),] # nonbreeding season = 1 Sept 2019 - 8 Mar 2020
ffAZ_nbs$Season = "NBS"
#now repeat in CA
ff_CA = ff1aff[which(ff1aff$Site == "CA"),]
ff_CA$Date = as.Date(ff_CA$Date, format = "%Y-%m-%d")
ffCA_nbs = ff_CA[which(ff_CA$Date > "2021-08-31" & ff_CA$Date < "2022-03-30"),] # nonbreeding season = 1 Sept 2021 - 29 Mar 2022
ffCA_nbs$Season = "NBS"
#combine sites together again
ffs = rbind(ffAZ_nbs,ffCA_nbs) 
#aggregate to only one association per pair per follow
els.nb = aggregate(TimeStamp ~ Date + FocalBirdID + NonFocalBirdID + Site, data = ffs, FUN = "max") 

## For the strength of bonds, we use the half-weight index to quantify the association strength between two banded birds.
# For the half-weight index we need the number of times bird 1 is seen without bird 2 (Y.1), and the number of times bird 2 is seen without bird 1 (Y.2). Use raw data, including UB and UNK birds, to get the number of times each bird is seen.
tmp = els.nb[,c(2,4)] #FocalBirdID, Site
colnames(tmp)[1] = "ID"
tmp2 = els.nb[,c(3:4)] #NonFocalBirdID, Site
colnames(tmp2)[1] = "ID"
y = rbind(tmp, tmp2)
y$count = 1
y = aggregate(count ~ ID + Site, data = y, FUN = "sum") #how many times each bird is seen individually
colnames(y)[3] = "y"

#For the half-weight index we also need the number of times two banded birds are seen together (x). 
#Filter for Focal birds that went through flexibility assays and had the minimum number of focal follows (at least 2 in non-breeding season) from data frame of affiliative, non-breeding season associations.
els.nb = els.nb[which(els.nb$FocalBirdID == "Adobo" | els.nb$FocalBirdID == "Burrito" | els.nb$FocalBirdID == "Chilaquile" | els.nb$FocalBirdID == "Chalupa" | els.nb$FocalBirdID == "Diablo" | els.nb$FocalBirdID == "Fideo" | els.nb$FocalBirdID == "Taco" | els.nb$FocalBirdID == "Taquito" |  els.nb$FocalBirdID == "Yuca" | els.nb$FocalBirdID == "Tembleque" | els.nb$FocalBirdID == "Polvorones" | els.nb$FocalBirdID == "Camote" | els.nb$FocalBirdID == "Dulce de Leche" | els.nb$FocalBirdID == "Zapote Negro" | els.nb$FocalBirdID == "Cuervo" | els.nb$FocalBirdID == "Xunub" | els.nb$FocalBirdID == "Galandra" | els.nb$FocalBirdID == "Kel" | els.nb$FocalBirdID == "Kau" | els.nb$FocalBirdID == "Cutuy"),]

#Exclude unbanded birds
els.nb2 <- els.nb[!els.nb$NonFocalBirdID=="NA" & !els.nb$NonFocalBirdID=="unbanded adult female" & !els.nb$NonFocalBirdID=="unbanded adult male" & !els.nb$NonFocalBirdID=="unbanded juvenile" & !els.nb$NonFocalBirdID=="unbanded juvenile female" & !els.nb$NonFocalBirdID=="unbanded juvenile male" & !els.nb$NonFocalBirdID=="unbanded unknown female" & !els.nb$NonFocalBirdID=="unbanded unknown male"  & !els.nb$NonFocalBirdID=="unknown adult female" & !els.nb$NonFocalBirdID=="unknown adult male" & !els.nb$NonFocalBirdID=="unknown adult male " & !els.nb$NonFocalBirdID=="unknown banded female" & !els.nb$NonFocalBirdID=="unknown female" & !els.nb$NonFocalBirdID=="unknown grackle"  & !els.nb$NonFocalBirdID=="unknown individual" & !els.nb$NonFocalBirdID=="unknown juvenile" & !els.nb$NonFocalBirdID=="unknown juvenile female"  & !els.nb$NonFocalBirdID=="unknown juvenile male" & !els.nb$NonFocalBirdID=="unknown male" & !els.nb$NonFocalBirdID=="unknown unbanded male",] 


#Create an edgelist - a two column matrix of birds seen together
#since these are undirected associations, symmetrize the associations so all are in the same order and repeat pairs can be identified
colnames(els.nb2)[c(2,3)]=c("ID.1","ID.2")
els.nb2$ID.1 = as.character(els.nb2$ID.1)
els.nb2$ID.2 = as.character(els.nb2$ID.2)
for (i in 1:nrow(els.nb2)) {
  tmp = els.nb2[i, c("ID.1", "ID.2")]
  tmp = tmp[,sort.list(tmp)] #produces warning messages, but works
  els.nb2[i, "ID.1"] = tmp[,1]
  els.nb2[i, "ID.2"] = tmp[,2]
}


#For the half-weight index, calculate the number of times two birds are seen together (x)
els.nb2$count = 1
x = aggregate(count ~ ID.1 + ID.2 + Site, data = els.nb2, FUN = "sum") #how many times are bird 1 and bird 2 observed together in each season
colnames(x)[4]="x"


colnames(y)[1] = "ID.1" 
hwis = merge(x,y, by = c("ID.1","Site"))
hwis$Y.1 = hwis$y - hwis$x #the number of times bird 1 was seen without bird 2
hwis = hwis[,-5]
colnames(y)[1] = "ID.2"
hwis = merge(hwis,y, by = c("ID.2","Site"))
hwis$Y.2 = hwis$y - hwis$x #the number of times bird 2 was seen without bird 1 by season
#data frame ready for half-weight index equation
### Half-weight index is used to weight the edges in the network for the calculation of the social network metric "strength". The equation is:
hwis$hwi = hwis$x/(0.5*(hwis$Y.1 + hwis$Y.2)+hwis$x)


### Calculate MaxBondStrength - the strength of the strongest association value (half-weight index) for each individual
bonds1 = hwis[,c(1,8)] #select only ID.2/ID.1 and hwi
colnames(bonds1)[1] = "ID"
bonds2 = hwis[,c(3,8)] #select only ID.2/ID.1 and hwi
colnames(bonds2)[1] = "ID"
bonds = rbind(bonds1, bonds2)
maxBond = aggregate(hwi ~ ID, data = bonds, FUN = "max")
# only interested in data from grackles that were in the aviaries and for which we have the minimum number of focal follows (2 per season)
maxBond = maxBond[-which(maxBond$ID == "Aquaman" | maxBond$ID == "Guapo" | maxBond$ID == "Morada" | maxBond$ID == "Naranja" | maxBond$ID == "Pepino" | maxBond$ID == "Pico" | maxBond$ID == "Tortilla" | maxBond$ID == "Urraca" | maxBond$ID == "Wachil"),]
### n = 18


#Combining MaxBond strength with general data sheet that will be used for analyses
colnames(maxBond) = c("BirdID","MaxBondStrength")
#Edit names of 2 birds to match across data sheets
g$BirdID[which(g$BirdID == "Piña")]<-"Pina"
g$BirdID[which(g$BirdID == "Tzanatl preciosa")]<-"Tzanatl Preciosa"
g = merge(g, maxBond, by = "BirdID", all = T)





### Calculate IndividualStrength - the sum of the association values for each individual
strength = aggregate(hwi ~ ID, data = bonds, FUN = "sum")
# only interested in data from grackles that were in the aviaries and for which we have the minimum number of focal follows (2 per season)
strength = strength[-which(strength$ID == "Aquaman" | strength$ID == "Guapo" | strength$ID == "Morada" | strength$ID == "Naranja" | strength$ID == "Pepino" | strength$ID == "Pico" | strength$ID == "Tortilla" | strength$ID == "Urraca" | strength$ID == "Wachil"),]
### n = 18

#Combining strength with general data sheet that will be used for analyses
colnames(strength) = c("BirdID","Strength")
g = merge(g, strength, by = "BirdID", all = T)




### Calculate Degree
bonds$degree = 1
degree = aggregate(degree ~ ID, data = bonds, FUN = "sum")
degree = degree[-which(degree$ID == "Aquaman" | degree$ID == "Guapo" | degree$ID == "Morada" | degree$ID == "Naranja" | degree$ID == "Pepino" | degree$ID == "Pico" | degree$ID == "Tortilla" | degree$ID == "Urraca" | degree$ID == "Wachil"),]
### n = 18

#Combining degree with general data sheet that will be used for analyses
colnames(degree) = c("BirdID","Degree")
g = merge(g, degree, by = "BirdID", all = T)

### We also said we would calculate a degree-like variable using the group size from the scan sample at the end of the focal follow.

### TO DO: Add to data sheet Relatedness of strongest bonds - dyadic data? Have to wait for DNA data to be available (Sep 2023) 

write.csv(g, "g_flexforaging_data_general.csv")
```


```{r p4pt4results, eval = F}
### Do social network metrics vary as a function of flexibility (and dominance, population)
g <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
g <- data.frame(g)


### OLD

#Factor the random effect variables
ID <- as.factor(ff$ID)
Population <- as.factor(ff$Site)
ID <- as.factor(mal$ID)
Population <- as.factor(mal$Site)

# DATA CHECKING
library(DHARMa)
library(lme4)


### MAX BOND STRENGTH ###
#Data checking for female GLMM 1
simulationOutput <- simulateResiduals(fittedModel = glmer(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(MaxBondStrength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 1
simulationOutput <- simulateResiduals(fittedModel = glmer(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(MaxBondStrength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet


library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0),R2=list(V=1,nu=0),R3=list(V=1,nu=0),R4=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0),G2=list(V=1,nu=0)))

#GLMM 1 with response variable = MaxBondStrength#
#females
set.seed(19)
f1 <- MCMCglmm(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
set.seed(20)
f2 <- MCMCglmm(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?



### STRENGTH ###
#Data checking for female GLMM 2
simulationOutput <- simulateResiduals(fittedModel = glmer(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Strength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 2
simulationOutput <- simulateResiduals(fittedModel = glmer(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Strength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#GLMM 2 with response variable = AvgBondStrength
#female
set.seed(21)
f3 <- MCMCglmm(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f3)
#autocorr(f3$Sol) #Did fixed effects converge?
#autocorr(f3$VCV) #Did random effects converge?

#male
set.seed(22)
f4 <- MCMCglmm(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f4)
#autocorr(f4$Sol) #Did fixed effects converge?
#autocorr(f4$VCV) #Did random effects converge?


### DEGREE ###
#Data checking for female GLMM 3
simulationOutput <- simulateResiduals(fittedModel = glmer(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Degree, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 3
simulationOutput <- simulateResiduals(fittedModel = glmer(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Degree, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#GLMM 3 with response variable = Degree
#female
set.seed(23)
f5 <- MCMCglmm(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f5)
#autocorr(f5$Sol) #Did fixed effects converge?
#autocorr(f5$VCV) #Did random effects converge?

#male
set.seed(24)
f6 <- MCMCglmm(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f6)
#autocorr(f6$Sol) #Did fixed effects converge?
#autocorr(f6$VCV) #Did random effects converge?



### MALE TERRITORY OVERLAP ###
#Data checking for male GLMM 4
simulationOutput <- simulateResiduals(fittedModel = glmer(MaleSharesTerritory ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(MaleSharesTerritory, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#GLMM 4 with response variable = MaleSharesTerritory
#male
f8 <- MCMCglmm(MaleSharesTerritory ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f8)
#autocorr(f8$Sol) #Did fixed effects converge?
#autocorr(f8$VCV) #Did random effects converge?



### RELATEDNESS FOR MAX BOND ### TO DO
#Data checking for female GLMM 5
simulationOutput <- simulateResiduals(fittedModel = glmer(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(RelatednessForMaxBond, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 5
simulationOutput <- simulateResiduals(fittedModel = glmer(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(RelatednessForMaxBond, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet


#GLMM 5 with response variable = RelatednessForMaxBond
#female
set.seed(25)
f9 <- MCMCglmm(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f9)
#autocorr(f9$Sol) #Did fixed effects converge?
#autocorr(f9$VCV) #Did random effects converge?

#male
set.seed(26)
f10 <- MCMCglmm(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f4)
#autocorr(f10$Sol) #Did fixed effects converge?
#autocorr(f10$VCV) #Did random effects converge?
```


```{r p4results, eval=F}
### RUN THE MODELS
library(rethinking)

### MAX BOND - strength of the strongest bond (calculated as the half-weight index based on association behavior during focal follows)


### STRENGTH - the sum of all bonds an individual has


### DEGREE - maximum number of other individuals that the focal subject associated with


### PERCENT TERRITORY SHARED WITH ANOTHER MALE
te <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
te <- data.frame(te)

# remove NAs
te <- subset(te,!(is.na(te["PercentTerritoryShared"])))
te <- subset(te,!(is.na(te["Phi"])))
te <- subset(te,!(is.na(te["Lambda"])))
te <- subset(te,!(is.na(te["DomRank"])))

#Summary
te$BirdID <- as.factor(te$BirdID)
#length(levels(te$BirdID)) #26 males
#range(te$NumFollows) #1-8 focals per male
#mean(te$NumFollows) #avg 4.6 focals for males

# SIMULATE
n = 100
p = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
d = rnorm(n,mean=0,sd=0.3) #rank can range from -1 to 1, but standardize it
terr = rnorm(n,mean=(-1*p + -1*d),sd=0.5) #territory is a proportion. Now change the slope (b) - tried 0, 1, and -1
#plot(p,terr)
#plot(d,terr)
#plots look good - any relationship is possible, but all values are within the feasible range

# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# PHI
dat <- list(ter = te$PercentTerritoryShared, #range=0-1.54 so standardizing centers on 0
            phi = standardize(te$Phi),
            lambda = standardize(te$Lambda),
            rank = standardize(te$DomRank)
              )

# Run the model: normal distribution bc the index is a variable that has already been modified to account for presence in habitats, therefore it is more similar to a sum (McElreath 2nd edition, Fig 10.6)
tephi <- ulam(
    alist(
        ter ~ dnorm(mu,sigma),
        log(mu) <- a + bp*phi + br*rank ,
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bp ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputp <- precis( tephi , depth=2 ) #look at the bp mean and whether the interval crosses zero to determine whether phi is strongly related to the percent shared territory (does not cross 0) or not (does cross 0)
#        mean   sd  5.5% 94.5% n_eff Rhat4
#a      4.24 0.06  4.14  4.33  2096     1
#bp     0.05 0.06 -0.04  0.14  1490     1
#br    -0.01 0.06 -0.10  0.08  1978     1
#sigma 19.90 2.00 16.90 23.23  1868     1
# bp interval crosses zero so not much relationship between phi and the percent shared territory


# LAMBDA
telam <- ulam(
    alist(
        ter ~ dnorm(mu,sigma),
        log(mu) <- a + bl*lambda + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputl <- precis( telam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#a      4.24 0.06  4.14  4.33  1875     1
#bl    -0.02 0.06 -0.12  0.07  1960     1
#br    -0.02 0.06 -0.11  0.08  1639     1
#sigma 20.11 1.96 17.24 23.39  2256     1
# bl interval crosses zero so not much relationship between phi and the percent shared territory
```

```{r p4figterritory, eval=T}
library(rethinking)
te <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
te <- data.frame(te)

# remove NAs
te <- subset(te,!(is.na(te["PercentTerritoryShared"])))
te <- subset(te,!(is.na(te["Phi"])))
te <- subset(te,!(is.na(te["Lambda"])))
te <- subset(te,!(is.na(te["DomRank"])))

# set up the data sheet
dat <- list(ter = te$PercentTerritoryShared, #range=0-1.54 so standardizing centers on 0
            phi = standardize(te$Phi),
            lambda = standardize(te$Lambda),
            rank = standardize(te$DomRank)
              )

# the figure
op <- par(mfrow=c(2,1), mar=c(5.9,4.9,2,0.9))
plot(dat$ter ~ dat$phi , pch=1 , col="black" , xlab="Phi (std)" , ylab="Percent territory shared" , xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
plot(dat$ter ~ dat$lambda , pch=1 , col="black" , xlab="Lambda (std)" , ylab="Percent territory shared", xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
par(op)
```

**Figure.** Scatterplots showing the lack of relationship between the Shannon Diversity Index with $\phi$ and $\lambda$ for both sexes.


## P5: Flexibility and immigration

**Analysis:** Because the independent variables could influence each other, we will analyze them in a single model: Generalized Linear Mixed Model (GLMM; MCMCglmm function, MCMCglmm package; [@hadfield2010mcmc]) with a Poisson distribution and log link using 130,000 iterations with a thinning interval of 10, a burnin of 30,000, and minimal priors (V=1, nu=0) [@hadfield2014coursenotes]. We will ensure the GLMM shows acceptable convergence (lag time autocorrelation values <0.01; [@hadfield2010mcmc]), and adjust parameters if necessary to meet this criterion. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

```{r p5, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(rethinking)
p5 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
p% <- data.frame(p5)

# remove NAs
p5 <- subset(p5,!(is.na(p5["ProbImmigrant"])))
p5 <- subset(p5,!(is.na(p5["Phi"])))
p5 <- subset(p5,!(is.na(p5["Lambda"])))

#Separate the sexes
f5 <- p5[p5$Sex=="F",]
m5 <- p5[p5$Sex=="M",]

#Summary
f5$BirdID <- as.factor(f5$BirdID)
#length(levels(f8$BirdID)) # females
m5$BirdID <- as.factor(m5$BirdID)
#length(levels(m8$BirdID)) # males

# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# MALES, phi. Set up data sheet for model
datm5 <- list(follows = m5$Probimmigrant, 
            phi = standardize(m5$Phi),
            lambda = standardize(m5$Lambda)
              )

# Run the model
set.seed(27)
m5phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*phi , #microhabitat=random variable
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=datm5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm5p <- precis( m5phi , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 

set.seed(28)
m5lambda <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*lambda , 
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=datm5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm5l <- precis( m5lambda , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 


# FEMALES, phi. Set up data sheet for model
datf5 <- list(follows = f5$Probimmigrant, 
            phi = standardize(f5$Phi),
            lambda = standardize(f5$Lambda)
              )
set.seed(29)
f5phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*phi , #microhabitat=random variable
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=dat5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm5p <- precis( f5phi , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 

set.seed(30)
f5lambda <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*lambda , 
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=dat5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputf5l <- precis( f5lambda , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 


#GLMM 
#females
f1 <- MCMCglmm(ImmigrantProbability ~ Phi + Lambda, random=~Population, family="poisson", data=fem, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
f2 <- MCMCglmm(ImmigrantProbability ~ Phi + Lambda, random=~Population, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?
```


## P6: flexible = wider range of habitats

The Shannon Diversity Index does not have a strong relationship with either flexibility component, phi or lambda, for either sex as indicated by the low means and the compatibility interval crossing zero (Table X). As such, prediction 6 (the more flexible individuals have a higher diversity index) and prediction 6 alternative (the more flexible individuals have a low diversity index indicating that they are specialists) are not supported.

**Table.** Model output showing that phi and lambda did not have a strong relationship with the Shannon Diversity Index for either sex as indicated by the slopes. n_eff is the effective sample size and Rhat4 is an indicator of model convergence (1.00 is ideal).

```{r resltsp6table, eval=T}
library(kableExtra)
t6 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_tablep6.csv"), header=F, sep=",", stringsAsFactors=F)
t6 <- data.frame(t6)
colnames(t6) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)","n_eff","Rhat4")

knitr::kable(t6) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 11)
```

```{r p6, eval=F}
### Calculate the Shannon diversity index (SDI) per bird
sdi <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_proportionmicrohabitats.csv"), header=T, sep=",", stringsAsFactors=F)
sdi <- data.frame(sdi)
library(vegan)

#factor ID and make a data frame for each individual so each can get their own SDI
sdi$BirdID <- factor(sdi$BirdID)
#levels(unique(sdi$BirdID))
ado <- sdi[sdi$BirdID=="Adobo",]
#diversity(ado$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
akx <- sdi[sdi$BirdID=="Ak'xi",]
#diversity(akx$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
bun <- sdi[sdi$BirdID=="Buñuelo",]
#diversity(bun$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
bur <- sdi[sdi$BirdID=="Burrito",]
#diversity(bur$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.748781
cam <- sdi[sdi$BirdID=="Camote",]
#diversity(cam$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.386294
cha <- sdi[sdi$BirdID=="Chalupa",]
#diversity(cha$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.332179
chi <- sdi[sdi$BirdID=="Chilaquile",]
#diversity(chi$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6341786
cue <- sdi[sdi$BirdID=="Cuervo",]
#diversity(cue$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.013665
cut <- sdi[sdi$BirdID=="Cutuy",]
#diversity(cut$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.4558862
dia <- sdi[sdi$BirdID=="Diablo",]
#diversity(dia$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.9502705
ddl <- sdi[sdi$BirdID=="Dulce de Leche",]
#diversity(ddl$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #= 1.085262
fid <- sdi[sdi$BirdID=="Fideo",]
#diversity(fid$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.260804
fla <- sdi[sdi$BirdID=="Flan",]
#diversity(fla$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
gal <- sdi[sdi$BirdID=="Galandra",]
#diversity(gal$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.872114
hab <- sdi[sdi$BirdID=="Habanero",]
#diversity(hab$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
hel <- sdi[sdi$BirdID=="Helado",]
#diversity(hel$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6931472
kau <- sdi[sdi$BirdID=="Kau",]
#diversity(kau$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
kel <- sdi[sdi$BirdID=="Kel",]
#diversity(kel$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
mar <- sdi[sdi$BirdID=="Marisco",]
#diversity(mar$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
mof <- sdi[sdi$BirdID=="Mofongo",]
#diversity(mof$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.386294
mol <- sdi[sdi$BirdID=="Mole",]
#diversity(mol$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6931472
pin <- sdi[sdi$BirdID=="Piña",]
#diversity(pin$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.098612
piz <- sdi[sdi$BirdID=="Pizza",]
#diversity(piz$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #= 0.6341786
pol <- sdi[sdi$BirdID=="Pollito",]
#diversity(pol$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
pov <- sdi[sdi$BirdID=="Polvorones",]
#diversity(pov$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.334183
que <- sdi[sdi$BirdID=="Queso",]
#diversity(que$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6730117
tac <- sdi[sdi$BirdID=="Taco",]
#diversity(tac$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.748781
tap <- sdi[sdi$BirdID=="Tapa",]
#diversity(tap$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
taq <- sdi[sdi$BirdID=="Taquito",]
#diversity(taq$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
tem <- sdi[sdi$BirdID=="Tembleque",]
#diversity(tem$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.332179
tom <- sdi[sdi$BirdID=="Tomatillo",]
#diversity(tom$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
tza <- sdi[sdi$BirdID=="Tzanatl preciosa",]
#diversity(tza$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6931472
xun <- sdi[sdi$BirdID=="Xunub",]
#diversity(xun$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.5623351
yuc <- sdi[sdi$BirdID=="Yuca",]
#diversity(yuc$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
zan <- sdi[sdi$BirdID=="Zapote Negro",]
#diversity(zan$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.322879
#entered this data into the main data sheet used below

### RUN THE MODELS
library(rethinking)
p8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
p8 <- data.frame(p8)

# remove NAs
p8 <- subset(p8,!(is.na(p8["ShannonDiversityIndex"])))
p8 <- subset(p8,!(is.na(p8["Phi"])))
p8 <- subset(p8,!(is.na(p8["Lambda"])))
p8 <- subset(p8,!(is.na(p8["DomRank"])))

#Separate the sexes
f8 <- p8[p8$Sex=="F",]
m8 <- p8[p8$Sex=="M",]

#Summary
f8$BirdID <- as.factor(f8$BirdID)
#length(levels(f8$BirdID)) #9 females
#range(f8$NumFollows) #1-6 focals per female
#mean(f8$NumFollows) #avg 4.2 focals for males
m8$BirdID <- as.factor(m8$BirdID)
#length(levels(m8$BirdID)) #26 males
#range(m8$NumFollows) #1-8 focals per male
#mean(m8$NumFollows) #avg 4.6 focals for males

# SIMULATE
n = 100
p = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
d = rnorm(n,mean=0,sd=0.2) #rank can range from 0 to 1, but standardize it
sdi = rnorm(n,mean=(-1*p + 1*d),sd=0.5) #shannon diversity index, standardize it. Now change the slope (b) - tried 0, 1, and -1
#plot(p,sdi)
#plot(d,sdi)
#plots look good - any relationship is possible, but all values are within the feasible range

#Just to check: unstandardize for plotting to interpret: standardized value * sd of original data + mean of original data
pu = sd(m8$Phi)*p+mean(m8$Phi)
sdiu = sd(m8$ShannonDiversityIndex)*sdi+mean(m8$ShannonDiversityIndex)
#plot(pu,sdiu)


# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# MALES, phi. Set up data sheet for model
dat <- list(div = standardize(m8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(m8$Phi),
            lambda = standardize(m8$Lambda),
            rank = standardize(m8$DomRank)
              )

# Run the model: normal distribution bc the index is a variable that has already been modified to account for presence in habitats, therefore it is more similar to a sum (McElreath 2nd edition, Fig 10.6)
m8phi <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bp*phi + br*rank ,
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bp ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm8p <- precis( m8phi , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether phi is strongly related to the diversity index (does not cross 0) or not (does cross 0). Look at the direction of the relationship to determine whether higher phi (more flexible bc associated with reversing in fewer trials, see Lukas et al. 2023 figs 2 & 3) have lower SDIs, which would indicate that they are specializing in particular microhabitats
#        mean   sd  5.5% 94.5% n_eff Rhat4
#a     -1.87 0.57 -2.82 -1.03  1225  1.00
#bp     0.05 0.55 -0.81  0.92  1127  1.00
#br     0.27 0.51 -0.46  1.11   932  1.01
#sigma  1.04 0.15  0.82  1.30  1474  1.00
# The result here and for all of the below models is the same: bp interval crosses zero and the slope is negative (-0.02 to -0.33) so not much relationship between phi and the shannon diversity index, indicating that the more flexible individuals do not specialize or generalize in microhabitat types, but are somewhere in the middle. This means that P6 and P6 alt are not supported and do not need to be analyzed. Do need to analyze P8 though because can't tell from this analysis whether different birds preferred different habitats. We can only see how they split their time among the habitats, not what the habitats are.


# MALES, lambda
m8lam <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bl*lambda + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm8l <- precis( m8lam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#a     -1.86 0.58 -2.89 -1.00  1081     1
#bl    -0.02 0.47 -0.83  0.66  1071     1
#br     0.31 0.54 -0.48  1.23  1114     1
#sigma  1.05 0.15  0.83  1.32  1467     1


# FEMALES, phi
daf <- list(div = standardize(f8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(f8$Phi),
            lambda = standardize(f8$Lambda),
            rank = standardize(f8$DomRank)
              )

f8phi <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bp*phi + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bp ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=daf , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputfp <- precis( f8phi , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#a     -1.50 0.62 -2.54 -0.61   904     1
#bp    -0.14 0.58 -1.17  0.65   905     1
#br     0.44 0.70 -0.66  1.57  1005     1
#sigma  1.08 0.29  0.71  1.59  1180     1

f8lam <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bl*lambda + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=daf , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputfl <- precis( f8lam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#a     -1.50 0.60 -2.53 -0.60   975     1
#bl    -0.33 0.59 -1.30  0.59   943     1
#br     0.39 0.65 -0.56  1.47   805     1
#sigma  1.05 0.29  0.69  1.58  1153     1
```

```{r p6fig, eval=T}
library(rethinking)
p8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
p8 <- data.frame(p8)

# remove NAs
p8 <- subset(p8,!(is.na(p8["ShannonDiversityIndex"])))
p8 <- subset(p8,!(is.na(p8["Phi"])))
p8 <- subset(p8,!(is.na(p8["Lambda"])))
p8 <- subset(p8,!(is.na(p8["DomRank"])))

#Separate the sexes
f8 <- p8[p8$Sex=="F",]
m8 <- p8[p8$Sex=="M",]

#set up the data sheets
dat <- list(div = standardize(m8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(m8$Phi),
            lambda = standardize(m8$Lambda),
            rank = standardize(m8$DomRank)
              )
daf <- list(div = standardize(f8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(f8$Phi),
            lambda = standardize(f8$Lambda),
            rank = standardize(f8$DomRank)
              )

# the figure
op <- par(mfrow=c(2,2), mar=c(5.9,4.9,2,0.9))
plot(daf$div ~ daf$phi , pch=1 , col="black" , xlab="Female: Phi (std)" , ylab="Shannon Diversity Index (std)" , xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
plot(daf$div ~ daf$lambda , pch=1 , col="black" , xlab="Female: Lambda (std)" , ylab="", xlim=c(-2,2), cex.lab=2, cex.axis=2, cex=2 )
plot(dat$div ~ dat$phi , pch=1 , col="black" , xlab="Male: Phi (std)" , ylab="Shannon Diversity Index (std)", xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
plot(dat$div ~ dat$lambda , pch=1 , col="black" , xlab="Male: Lambda (std)" , ylab="", xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
par(op)
```

**Figure.** Scatterplots showing the lack of relationship between the Shannon Diversity Index with $\phi$ and $\lambda$ for both sexes.

This species is primarily found within urbanized environments, however there are many different substrates within urban habitats that could provide a variety of food items. Since we are interested in the flexibility of grackle foraging behaviors within the urban habitat, we have focused our habitat diversity measures on the different substrates on which we are mostly likely to see individual variability in foraging behaviors and food types, if present.  For example, cement, cafe, and dumpster substrates are all likely to contain human-provided food (either because people leave food out for wild animals or wild animals are able to scrounge human foods), whereas grass, gravel, or other natural substrates such as trees likely contain non-human provided prey items including insects and small vertebrates. Using the Shannon diversity index to understand the evenness of substrate use within urban habitats has been recommended by others in the field of urban ecology [@alberti2001quantifying; @tews2004animal].

## P7: no difference in human population density across sites

Human population density (population per square mile) is higher in Sacramento, California (mean=4,895, standard deviation=185), which is higher than Tempe, Arizona (mean=4,283, standard deviation=187), which is higher than Woodland, California (mean=3,710, standard deviation=140) (contrast: mean=572.84 sd=32.21 89% compatibility interval=520.78-622.69).

**Table.** Contrasts showing that the human population density at each trap site is different from the others.

```{r resltsp7table, eval=T}
library(kableExtra)
exptable <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_tablep7.csv"), header=F, sep=",", stringsAsFactors=F)
exptable <- data.frame(exptable)
colnames(exptable) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)")

knitr::kable(exptable) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 11)
```

```{r p7, eval=FALSE}
library(rethinking)

# Human population density 2009-2020 (but no data for 2019 so n=10 data points per city) from the Open Data Network, which used data from the U.S. Census American Community Survey ("Population Density is computed by dividing the total population by Land Area Per Square Mile"), except for the data points from 2010 and 2020, which were from the census.
pd <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_datap7.csv"), header=T, sep=",", stringsAsFactors=F)
pd <- data.frame(pd)

# look at the data: each city's pop is generally increasing every year
f <- plot(pd$HumanPopDensity~pd$Year)

# SIMULATE data to figure out the model boundaries
n=10 #sample size
offset=250 #expect no difference between the cities when offset=0 (bc they have the same means)
city1_mean=5000 #avg pop density of city 1
city2_mean=city1_mean+offset #avg pop density of city 2
act1=rnorm(n/2, mean=city1_mean, sd=100) #alpha simulation for city 1
act2=rnorm(n/2, mean=city2_mean, sd=100) #alpha simulation for city 2

#boxplot(c(act1,act2)~c(rep("City1",n/2),rep("City2",n/2))) #look at the sim
plotsim <- plot(c(act1,act2)~c(rep(1,n/2),rep(2,n/2))) #look at the sim
for (j in 1:(n/2) ) {
  lines(x=c(1,2),y=c(act1[j],act2[j]),lwd=2,col=2)
}

# will run a contrast on the actual data to determine whether the cities differ, so run simulated contrasts and look at the histogram to see if any values cross zero. Centered on the offset and the spread reflects the SD. Ran the contrasts with varying offsets and found the values stop crossing zero when the difference between the city means is at least 250 (at n=50 and n=10, SD always=100).
contrast <- act2-act1
hist(contrast)

# USING ACTUAL DATA: Set up the data sheet for the model
dat <- list(
  city = as.factor(pd$City),
  p = as.numeric(pd$HumanPopDensity)
)

# Run the model: normal distribution bc pop density is a sum with a large mean (McElreath 2nd edition, Fig 10.6)
pop <- ulam(
    alist(
        p ~ dnorm(mu,sigma),
        log(mu) <- a[city],
        a[city] ~ dnorm(8,2), #mean of 8 because the actual mean across the cities is around 3000 so log(3000)=8. Set the sd of expected values at 2 because pop densities could range from 100 (log=5) to 10,000 (log=9)
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output <- precis( pop , depth=2 ) #level 1=Sacramento, 2=Tempe, 3=Woodland
#        mean   sd  5.5% 94.5% n_eff Rhat4
#a[1]     8.50 0.01  8.49  8.50  3111     1
#a[2]     8.36 0.01  8.35  8.37  2850     1
#a[3]     8.22 0.01  8.21  8.23  3295     1
#a_bar    0.99 1.05 -0.64  2.67  1581     1
#sigma_a  5.11 1.37  3.33  7.47  1775     1
#sigma   87.91 5.11 80.00 96.21  1882     1

# run a CONTRAST to determine whether there is a difference between cities
post <- extract.samples(pop)
diff_a <- post$a[,1] - post$a[,2]
diff_p12 <- exp(post$a[,1]) - exp(post$a[,2]) #convert the log link to the probability scale p.341
diff_p13 <- exp(post$a[,1]) - exp(post$a[,3]) #convert the log link to the probability scale p.341
diff_p32 <- exp(post$a[,2]) - exp(post$a[,3]) #convert the log link to the probability scale p.341
precis( list( diff_p12=diff_p12 , diff_p13=diff_p13 , diff_p32=diff_p32 ) )
#        mean   sd  5.5% 94.5%     histogram
#diff_p12  612.15 36.01  556.47  670.68  ▁▁▁▂▃▇▇▇▅▂▁▁▁
#diff_p13 1184.74 36.10 1129.14 1241.31 ▁▁▁▁▂▃▇▇▅▃▁▁▁▁
#diff_p32  572.59 36.15  515.65  630.09  ▁▁▁▂▃▇▇▇▅▂▁▁▁
#there is a difference between all cities because diff interval crosses zero and there is a difference larger than 250 between the means

# summary
#mean(pd[pd$City=="Tempe",]$HumanPopDensity) #4282.755
#mean(pd[pd$City=="Woodland",]$HumanPopDensity) #3710.073
#mean(pd[pd$City=="Sacramento",]$HumanPopDensity) #4895.055
#sd(pd[pd$City=="Tempe",]$HumanPopDensity) #187.4377
#sd(pd[pd$City=="Woodland",]$HumanPopDensity) #140.2587
#sd(pd[pd$City=="Sacramento",]$HumanPopDensity) #185.2717

### land cover classifications (https://www.usgs.gov/media/images/land-cover-conterminous-us-shown-16-thematic-classes)
## Tempe and Sacramento = Developed, medium intensity
## Woodland = Cultivated crops
```

## P8: flexible = particular habitats

**Analysis:** We examine the proportion of focal follows associated with each microhabitat per individual and relate this to their flexibility scores on their most recent reversal in the tube experiment. This allows us to see whether the more flexible individuals (faster to reverse) are associated with particular microhabitats more than the less flexible individuals.

There is not a strong relationship between phi or lambda and the proportion of focal follows in a given micro habitat type: the compatibility intervals for the slopes cross zero in all microhabitat types (Table, Figure).

**Table.** Model output showing that phi and lambda did not have a strong relationship with the proportion of focal follows in a given microhabitat type for either sex as indicated by the slopes. n_eff is the effective sample size and Rhat4 is an indicator of model convergence (1.00 is ideal).

```{r resltsp8table, eval=T}
library(kableExtra)
t8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_tablep8.csv"), header=F, sep=",", stringsAsFactors=F)
t8 <- data.frame(t8)
colnames(t8) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)","n_eff","Rhat4")

knitr::kable(t8) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 11)
```


```{r p8, eval=F}
library(rethinking)
d8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_proportionmicrohabitats.csv"), header=T, sep=",", stringsAsFactors=F)
d8 <- data.frame(d8)

# remove NAs
d8 <- subset(d8,!(is.na(d8["ProportionFollows"])))
d8 <- subset(d8,!(is.na(d8["Phi"])))
d8 <- subset(d8,!(is.na(d8["Lambda"])))
d8 <- subset(d8,!(is.na(d8["Microhabitat"])))

#Separate the sexes
ff8 <- d8[d8$Sex=="F",]
mm8 <- d8[d8$Sex=="M",]

#Summary
ff8$BirdID <- as.factor(ff8$BirdID)
#length(levels(ff8$BirdID)) #9 females
mm8$BirdID <- as.factor(mm8$BirdID)
#length(levels(mm8$BirdID)) #26 males

# SIMULATE
n = 99 #99 rows / 9 microhabitat types = 11 individuals
ph = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
ha = rep(c(1:9),11) #go through all individuals 1 time (microhabitat is a categorical variable) 
slopes0 = rep(c(0,0,0,0,0,0,0,0,0),11) #repeat 0 nine times (one time per habitat) for 11 inds. Use zeros for no relationship. 
slopes1 = rep(c(-1,-1,-1,0,0,0,1,1,1),11) #use a mixture of slopes to simulate what happens at different values
pf = rnorm(n,mean=(0*ha + slopes1*ph),sd=0.5) #proportion follows
#plot(ha,pf,cex=ph*2) #Multiply by 2 so the tiny dots show up better
#plots look good - any relationship is possible, but all values are within the feasible range

# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# MALES, phi. Set up data sheet for model
dat8 <- list(follows = mm8$ProportionFollows, 
            phi = standardize(mm8$Phi),
            lambda = standardize(mm8$Lambda),
            hab = as.factor(mm8$Microhabitat)
              )

# Run the model
d8phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*phi , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=dat8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputd8p <- precis( d8phi , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to determine whether phi is strongly related to the proportion of follows (does not cross 0) or not (does cross 0). b1=building, b2=dumpster, b3=grass, b4=human surface, b5=misc human, b6=natural ground, b7=rock, b8=shrub, b9=tree
#        mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.02 0.58 -0.96  0.90  2345     1
#b[2]  0.23 0.54 -0.62  1.10  3214     1
#b[3] -0.02 0.61 -1.00  0.93  2660     1
#b[4] -0.27 0.55 -1.16  0.57  2854     1
#b[5] -0.01 0.59 -0.97  0.92  2987     1
#b[6] -0.02 0.57 -0.92  0.89  2601     1
#b[7] -0.03 0.57 -0.94  0.90  2815     1
#b[8] -0.02 0.58 -0.96  0.88  2693     1
#b[9] -0.33 0.47 -1.07  0.42  2810     1
# The result here and for all of the below models is the same: the b intervals cross zero in all microhabitat types and the slope is negative, so not much relationship between phi and the proportion of follows, indicating that the more flexible individuals do not specialize in a particular microhabitat type

# MALES, lambda
d8lam <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*lambda , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=dat8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputd8l <- precis( d8lam , depth=2 )
#       mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.08 0.59 -1.04  0.84  2610     1
#b[2] -0.26 0.56 -1.18  0.59  2123     1
#b[3] -0.08 0.58 -1.09  0.80  2531     1
#b[4] -0.11 0.56 -1.01  0.75  3014     1
#b[5] -0.07 0.58 -1.03  0.81  1705     1
#b[6] -0.08 0.58 -1.10  0.81  2744     1
#b[7] -0.07 0.57 -0.99  0.83  3115     1
#b[8] -0.09 0.59 -1.06  0.77  2644     1
#b[9]  0.42 0.45 -0.28  1.12  2415     1
#look at b9 Tree because it has a large mean relative to the others
#plot(mm8[mm8$Microhabitat=="Tree",]$ProportionFollows ~ mm8[mm8$Microhabitat=="Tree",]$Lambda)
#this relationship is pretty randomly scattered, with the zero proportions having lower lambdas

# FEMALES, phi
daf8 <- list(follows = ff8$ProportionFollows, 
            phi = standardize(ff8$Phi),
            lambda = standardize(ff8$Lambda),
            hab = as.factor(ff8$Microhabitat)
              )

df8phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*phi , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=daf8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputdfp <- precis( df8phi , depth=2 ) 
#      mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.12 0.73 -1.32  0.98  3283     1
#b[2] -0.11 0.72 -1.29  0.99  2439     1
#b[3] -0.13 0.71 -1.28  0.94  2915     1
#b[4] -0.11 0.70 -1.28  0.99  3604     1
#b[5] -0.26 0.71 -1.45  0.82  3307     1
#b[6] -0.11 0.67 -1.21  0.94  2994     1
#b[7] -0.09 0.71 -1.34  0.98  2787     1
#b[8] -0.11 0.71 -1.28  0.98  3012     1
#b[9] -0.29 0.72 -1.50  0.78  3101     1

df8lam <- ulam(alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*lambda , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=daf8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputdfl <- precis( df8lam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.03 0.67 -1.10  1.01  2861     1
#b[2] -0.01 0.67 -1.07  1.02  2932     1
#b[3] -0.06 0.71 -1.23  1.03  2212     1
#b[4] -0.04 0.69 -1.18  1.04  2739     1
#b[5]  0.56 0.66 -0.47  1.62  2977     1
#b[6] -0.02 0.69 -1.14  1.06  2949     1
#b[7]  0.00 0.67 -1.10  1.06  3289     1
#b[8] -0.02 0.67 -1.09  1.02  2355     1
#b[9] -0.09 0.66 -1.12  0.96  2884     1

#look at b5 MiscHuman because it has a large mean relative to the others
#plot(ff8[ff8$Microhabitat=="MiscHuman",]$ProportionFollows ~ ff8[ff8$Microhabitat=="MiscHuman",]$Lambda)
#this relationship is due to 1 female that spends 100% of her time in this habitat, while the others don't often visit it

# put all of the model outputs into a csv file
#write.csv(c(outputdfp,outputdfl,outputd8l,outputd8l),file="flexforaging_P8outputs.csv")
```

```{r p8figure, eval=T}
library(ggplot2)
library(cowplot)

d8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_proportionmicrohabitats.csv"), header=T, sep=",", stringsAsFactors=F)
d8 <- data.frame(d8)

# remove NAs
d8 <- subset(d8,!(is.na(d8["ProportionFollows"])))
d8 <- subset(d8,!(is.na(d8["Phi"])))
d8 <- subset(d8,!(is.na(d8["Lambda"])))
d8 <- subset(d8,!(is.na(d8["Microhabitat"])))

#Separate the sexes
ff8 <- d8[d8$Sex=="F",]
mm8 <- d8[d8$Sex=="M",]
ff8$BirdID <- as.factor(ff8$BirdID)
mm8$BirdID <- as.factor(mm8$BirdID)

# factor categorical variable
ff8$Microhabitat <- as.factor(ff8$Microhabitat)
mm8$Microhabitat <- as.factor(mm8$Microhabitat)

# visualize
mp <- ggplot() + geom_point(data=mm8,aes(x=Microhabitat, y=ProportionFollows, size=Phi), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "Proportion follows")
ml <- ggplot() + geom_point(data=mm8,aes(x=Microhabitat, y=ProportionFollows, size=Lambda), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "")
fp <- ggplot() + geom_point(data=ff8,aes(x=Microhabitat, y=ProportionFollows, size=Phi), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "Proportion follows")
fl <- ggplot() + geom_point(data=ff8,aes(x=Microhabitat, y=ProportionFollows, size=Lambda), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "")

theme_set(theme_cowplot(font_size=12))
plot_grid(mp, ml, fp, fl, align='h', ncol=2, labels=c('A','B','C','D'), label_size=12)
```

**Figure.** Scatterplots for females (top row) and males (bottom row) showing the relationship between the proportion of follows in a particular microhabitat and phi (left column) or lambda (right column). Larger diameter circles indicate a larger phi or lambda.


# DISCUSSION

Human population density varies within and between the grackle populations: it is the highest and lowest at the Woodland trap sites, which are different from each other and from Tempe. This indicates that the environments that individuals on the edge experience do not differ systematically in human population density.

In conclusion,


# ETHICS

This research is carried out in accordance with permits from the:

1) US Fish and Wildlife Service (scientific collecting permit number MB76700A-0,1,2)
2) US Geological Survey Bird Banding Laboratory (federal bird banding permit number 23872)
3) Arizona Game and Fish Department (scientific collecting license number SP594338 [2017], SP606267 [2018], and SP639866 [2019])
4) California Department of Fish and Wildlife (scientific collecting permit number S‐192100001‐19210‐001)
5) Institutional Animal Care and Use Committee at Arizona State University (protocol number 17-1594R)
6) Institutional Animal Care and Use Committee at the University of California Santa Barbara (protocol number 958)
7) University of Cambridge ethical review process (non-regulated use of animals in scientific procedures: zoo4/17 [2017])
8) RegionalSan access permit (number AP 2021-01)

# AUTHOR CONTRIBUTIONS

**Logan:** Hypothesis development, study design, materials, data collection, data analysis and interpretation, write up, funding.

**Lukas:** Hypothesis development, study design, data analysis and interpretation, write up, revising/editing.

**LeGrande-Rolls:** Data collection, data analysis and interpretation, revising/editing

**Bergeron:** Data collection, data interpretation, revising/editing.

**Folsom:** Data collection, data interpretation, revising/editing.

**Marfori:** Data collection, revising/editing.

**McCune:** Hypothesis development, study design, data collection, data analysis, data interpretation, revising/editing.

# FUNDING

This research was funded by the Department of Human Behavior, Ecology and Culture at the Max Planck Institute for Evolutionary Anthropology, and by a Leverhulme Early Career Research Fellowship to Logan (2017-2018).

# CONFLICT OF INTEREST DISCLOSURE

We, the authors, declare that we have no financial conflicts of interest with the content of this article. Logan and Lukas are Recommenders at PCI Ecology, and Logan was on the Managing Board at PCI Ecology (2018-2022).

# ACKNOWLEDGEMENTS

We thank Ben Trumble for providing us with a wet lab at Arizona State University and Angela Bond for lab support; Melissa Wilson for sponsoring our affiliations at Arizona State University and lending lab equipment; Kevin Langergraber for serving as local PI on the ASU IACUC; Kristine Johnson for technical advice on great-tailed grackles; Arizona State University School of Life Sciences Department Animal Care and Technologies for providing space for our aviaries and for their excellent support of our daily activities; Julia Cissewski for tirelessly solving problems involving financial transactions and contracts; Richard McElreath for project support; Aaron Blackwell and Ken Kosik for being the UCSB sponsors of the Cooperation Agreement with the Max Planck Institute for Evolutionary Anthropology; Julia Astegiano, our Recommender at PCI Ecology, and reviewers Esther Sebastian-Gonzalez and Pizza Ka Yee Chow for their wonderful feedback; Sawyer Lung for field support; Alexis Breen for assistance with data cleaning; Tiana Lam, Alexis Breen, and Vincent Kiepsch for video coding the multiaccess box switch latencies; and our research assistants: Aelin Mayer, Nancy Rodriguez, Brianna Thomas, Aldora Messinger, Elysia Mamola, Michael Guillen, Rita Barakat, Adriana Boderash, Olateju Ojekunle, August Sevchik, Justin Huynh, Jennifer Berens, Amanda Overholt, Michael Pickett, Sam Munoz, Sam Bowser, Emily Blackwell, Kaylee Delcid, Sofija Savic, Brynna Hood, Sierra Planck, and Elise Lange.

\newpage

# SUPPLEMENTARY MATERIAL 1: interobserver reliability

To be able to conduct focal follows [methods as in @altmann1974observational], a coder must pass interobserver reliability before the data they collect is used in the data set. To pass, coders must have an intra-class correlation [ICC; @hutcheon2010random] of 0.90 or greater based on at least six 10-min focal follows where both coders recorded the behavior of the same focal individual at the same time.

Bergeron was the first person to conduct focal follows, therefore she trained McCune and Folsom until they passed interobserver reliability (on 10 June 2019) for each of the 6 variables listed in the preregistration. In March 2021, Rolls passed interobserver reliability (training with McCune) in the California population.

```{r ior, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
# Inter/intra-rater reliability using Cohen's kappa when the variable is categorical (scale=1+) or intra-class correlation coefficient when the variable is continuous (Mandrekar 2011 J Thoracic Oncology 6(1):6-7 https://doi.org/10.1097/JTO.0b013e318200f983)

# Intra-class correlation / reliability coefficient / the
# degree of bias in the regression slope (Hutcheon et al.
# 2010. Random measurement error and regression dilution bias
# www.bmj.com/content/340/bmj.c2289). 'The ratio of variation
# in error-free (true) X values to the variation in the
# observed error-prone (observed) values is known as the
# reliability coefficient, attenuation factor, or intra-class
# correlation.'

#Cohen's kappa = Good for nominal data (where distance doesn't mean anything; don't use the weighted Kappa bc it is like the ICC) https://www.rdocumentation.org/packages/psych/versions/1.9.12.31/topics/cohen.kappa 

# ICC / Cohen's Kappa must be 0.90 or greater to be considered reliable and pass training
### ICCs for agreement between the 2 coders (live coder and video coder)

library(irr) #ICC package
library(psych) #Cohen's kappa package

### ICCs & Cohen's unweighted kappas for agreement between the 2 coders for 6-7 variables
#Note: c(4,5) is telling R to look at columns 4 ("1NumberForagingTechniques") and 5 ("2NumberForagingTechniques") and compare them

#ICCs for KM=Kelsey McCune, MF=Melissa Folsom, CLR=Christa Rolls
km <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/IOR_flexforagingKM.csv"), header=T, sep=",", stringsAsFactors=F) 
km #Check to make sure it looks right
km[,2]
km[,3]

#ICC for number different foods eaten not working
icc(km[,c(2,3)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentFoodsEaten. See note in text for why this is 1.00 rather than 0.64

icc(km[,c(4,5)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentForagingTechniques
icc(km[,c(6,7)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAffiliativeInteractions
icc(km[,c(8,9)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAggressiveInteractions
icc(km[,c(10,11)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberTimesSubjectInitiatedAggression
cohen.kappa(km[,c(12,13)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Microhabitat


#ICCs for MF=Melissa Folsom
mf <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/IOR_flexforagingMF.csv"), header=T, sep=",", stringsAsFactors=F) 
mf #Check to make sure it looks right
mf[,2]
mf[,3]
mf[,12]
mf[,13]

icc(mf[,c(2,3)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentFoodsEaten. See note in text for why this is 1.00 rather than 0.63
icc(mf[,c(4,5)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentForagingTechniques
icc(mf[,c(6,7)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAffiliativeInteractions
icc(mf[,c(8,9)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAggressiveInteractions
icc(mf[,c(10,11)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberTimesSubjectInitiatedAggression
cohen.kappa(mf[,c(12,13)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Microhabitat


#ICCs for CLR=Christa Rolls
clr <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/IOR_flexforagingCLR.csv"), header=T, sep=",", stringsAsFactors=F) 
clr #Check to make sure it looks right
clr[,9]
clr[,10]

icc(clr[,c(3,4)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentFoodsEaten
icc(clr[,c(5,6)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentForagingTechniques
icc(clr[,c(7,8)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAffiliativeInteractions
icc(clr[,c(9,10)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAggressiveInteractions
icc(clr[,c(11,12)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberTimesSubjectInitiatedAggression
cohen.kappa(clr[,c(13,14)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Microhabitat. Unweighted kappa=1
icc(clr[,c(15,16)], model="oneway", type="agreement", unit="single", conf.level=0.95) #Group size
```

**Scores for McCune (n=6 focal follows, Bergeron=baseline):**

Different Foods Eaten: ICC = 1.00

Different Foraging Techniques: ICC = 0.97 (95% confidence interval=0.823-1.00)

Number of Affiliative Interactions: ICC = 0.96 (95% confidence interval=0.794-1.00)

Number of Aggressive Interactions: ICC = 1.00 (95% confidence interval=0.986-1.00)

Number of Initiated Aggressive Interactions: ICC = 1.00 (95% confidence interval=0.974-1.00)

Microhabitat: Cohen's unweighted kappa = 1.00

**Scores for Folsom (n=6 focal follows, Bergeron=baseline):**

Different Foods Eaten: ICC = 1.00

Different Foraging Techniques: ICC = 1.00

Number of Affiliative Interactions: ICC = 1.00

Number of Aggressive Interactions: ICC = 0.96 (95% confidence interval=0.779-0.994)

Number of Initiated Aggressive Interactions: ICC = 0.94 (95% confidence interval=0.696-0.991)

Microhabitat: Cohen's unweighted kappa = 1.00

NOTE: the ICCs for the variable Different Foods Eaten for these focal follows was originally 0.63 (Folsom) and 0.64 (McCune) because Folsom and McCune recorded a "bug" being eaten while Bergeron recorded no food type because she couldn't identify it to a more specific category. At this point, we decided that we would prefer to enter a general category for food type rather than having no information about what was eaten. Therefore, this data point was removed from the interobserver reliability analysis. This resulted in ICCs of 1.00 for both McCune and Folsom on the Different Foods Eaten variable because they matched Bergeron in the other food type data points.

**Scores for Rolls (n=17 focal follows, McCune=baseline):**

Different Foods Eaten: ICC = 0.92 (95% confidence interval=0.791-0.971)

Different Foraging Techniques: ICC = 0.91 (95% confidence interval=0.758-0.966)

Number of Affiliative Interactions: ICC = 0.90 (95% confidence interval=0.751-0.965)

Number of Aggressive Interactions: ICC = 0.94 (95% confidence interval=0.830-0.977)

Number of Initiated Aggressive Interactions: ICC = 0.95 (95% confidence interval=0.874-0.983)

Microhabitat: Cohen's unweighted kappa = 1.00

Group size = 1.00

```{r iorrolls, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
#Cohen's kappa for CLR=Christa Rolls' recoded data vs the original transcribed data
library(psych) #Cohen's kappa package

#whether one or more errors were found by CLR (1=yes, 0=no). The assumption is that when the coders initially transcribed the data the first time, they did not think they were making any errors (0)
clr = c(1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0)
orig = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)

#the cohen.kappa calculation can't calculate it properly when the data are in this format because one string is calculating the errors of the other string. So assign numbers 1 through 37 to orig and the same for clr, but make the 4 data points that were different in the two strings a number that is out of sequence so the difference will register
orig <- c(1:37)
clr <- c(1:37)
clr[1] <- 38
clr[22] <- 39
clr[30] <- 10
clr[36] <- 40

cohen.kappa(x=cbind(clr,orig), w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Unweighted kappa = 0.89, confidence boundary 0.79-0.99
```

**Unregistered reliability analysis for data entry (Jun 2022):** The focal follow data were transferred from the Prim8 auto-generated data sheets and transcribed (from focals that were recorded using audio files) to two analyzable data sheets (one for social behavior and one for foraging behavior) containing data for all variables in this preregistration. During the data cleaning process, several data entry/transcription errors were found, which prompted us to conduct a reliability analysis on the data. We did not record who the data entry person / transcriber was, so we could not conduct an interoberver analysis. Instead, we conducted an intraobserver reliability analysis. Ten percent (37) of the focal follows (total 367) were randomly selected (using RAND() in MS Excel) and recoded by Christa Rolls in 2022. Rolls recorded for each focal follow whether one or more errors in the original data set were made (1) or not (0), and this vector was compared with a vector from the original data set where the assumption wsa that no errors were made (all data points were 0). The Cohen's kappa between the recoded and the original data set was 0.89 (confidence boundary 0.79-0.99), indicating that the data cleaning process corrected enough errors such that the rest of the data did not need to be recoded.


\newpage

# SUPPLEMENTARY MATERIAL 2: additional analyses for P2

##  2.1 Accounting for undersampling

If a bird has only been observed for a short period of time, we might not have had a chance to see a given behavior that it actually uses. This is called undersampling. We adapted a model that McElreath developed (https://github.com/rmcelreath/cg_vocal_repertoires/blob/main/model_ulam_covariates.r) that better accounts for undersampling. We applied the model to Prediction 2 where we examine whether there are differences between control and manipulated birds in the number of food types and foraging techniques they use. We omitted food types and foraging techniques that none of these individuals used, which resulted in 14 food types and X foraging techniques.

We found that these models came to the same conclusion that manipulated birds ate 1.6 more food types and used 1.1 more foraging techniques, however the model was much less certain about the results given that most individuals were not observed using very many food types and foraging techniques (Table S2.1). As such, all of the 89% compatibility intervals crossed zero. The model also revealed that there are some foods and foraging techniques that the manipulated birds were less likely to use, suggesting that they ate different food types and used different techniques, rather than more of the same.

**Table SM2.1.** Contrasts showing that, for each food type and each foraging technique as well as across food types and foraging techniques, whether manipulated birds are more likely to use them than control birds.

```{r p2manipvsctrlsupp1table, eval=T, warning=FALSE, results='asis', include=TRUE}
library(kableExtra)
library(dplyr)
smtable <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_table_sm_p2.csv"), header=T, sep=",", stringsAsFactors=F)
smtable <- data.frame(smtable)
colnames(sumtable) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)")

knitr::kable(sumtable) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 6)
```


```{r p2manipvsctrlsupp1, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(dplyr)
library(tidyr)
### NUMBER OF FOOD TYPES for flexibility manipulated vs control birds using Richard McElreath's vocalization Poisson model that accounts for undersampling (didn't observe all of the food types an individual eats) and for the baseline levels of each food type in the population (https://github.com/rmcelreath/cg_vocal_repertoires/blob/main/model_ulam_covariates.r)

#Lambda = fixed rate at which each behavior is exhibited
#P = probability that a given individual has the behavior (food type) in its repertoire. If a bird does not show as having taken a given food type, then this could be either because the behavior is not part of its repertoire or we haven't observed the bird for long enough to see the behavior given that the rate at which it is exhibited in the population is low. If a bird does show a given food type, it means it is definitely part of its repertoire and we can now calculate the rate at which it is exhibited. This allows for uncertainty around each food type.

#Load the foraging data
f1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
f1 <- data.frame(f1)

#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
c1 <- f1[f1$Population=="AZ",]

#Count per bird the number of times it took a food type for all food types
f <- c1 %>% group_by(BirdID,What) %>% summarise (Count=n())
f2 <- pivot_wider(f,names_from=What,values_from=Count)

# AZ population: How many different food types? 20 (from R code chunk p2manipunregistered)
#length(unique(ft1$What)) #20
#unique(ft1$What) #fry, lizard, unknown, grains, insect, rock, cat food, worm, seed, food crumbs, vegetation, fruit, bird poop, candy, vomit, misc. trash, soil, condiment, carcass, chicken

# AZ population: How many different foraging techniques? 9 (from R code chunk p2manipunregistered)
#length(unique(ft1$How)) # 11 - 1 (eat) - 1 (tolerated theft) = 9
#unique(ft1$How) #eat, gape, lift or nudge, stalk catch, flip, food share, break into pieces, dunk in water, tolerated theft, theft, dig

# link with general datasheet to identify which birds were manipulated and their sum focal time
g <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
g <- data.frame(g)
#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
g <- g[g$Population=="AZ",]
ca<- g %>% group_by(BirdID) %>% summarise (Treatment=unique(FlexibilityManipulated), obstime=unique(SumFocalTime))

ty <- left_join(f2,ca,by="BirdID")
ty <- subset(ty, is.na(ty$Treatment) == FALSE)
ty <- as.data.frame(ty)
#nrow(ty) #NOTE: n=13 (6=manipulated, 7=control) birds because some dropped out due to not having any foraging events in their focals or not having any focals

#replace NAs with zeros
ty[is.na(ty)] <- 0

# remove food types that neither the manipulated nor the control birds ate: we cannot say whether they are more or less likely to be part of their repertoire
for(i in 2:21){
  if(sum(ty[,i])==0){print(i)}
}

ty_minus<-ty[,-c(10,12,13,18,19,21)]


# Convert the table into long form: take the values from the matrix and put them one behind the other, starting with the first row (all counts for bird 1 for all food types) followed by the second row (all counts for bird 2 for all food types), etc.

# Make a matrix that only has the food types and their counts
dat<-ty_minus[,2:15]

YY <- rep(NA,length(dat))
MM <- YY
ID <- YY
JJ <- YY
k <- 1
for ( j in 1:nrow(dat) ) for ( m in 1:ncol(dat) ) {
    YY[k] <- dat[j,m]
    MM[k] <- m
    ID[k] <- ty_minus$BirdID[j]
    JJ[k] <- j
    k <- k + 1
}


### Richard's model: the probability for each bird for each food type that this food type is in their repertoire
dat_list <- list(
    Y = YY,    # behavior counts
    ID = as.integer(as.factor(ID)),   # individual ID
    BID = MM,  # behavior ID
    J = JJ,    # recording ID
    D = ty$obstime, # duration of recording
    M = max(MM), # total number of different food types
    vlen=rep(1,max(MM)), # each of the different food types takes 1 second to process
    group=as.integer(as.factor(ty_minus$Treatment)) # 1 = Control, 2 = manipulated
)

m0u <- ulam(
    alist(
        # Y > 0
        Y|Y>0 ~ custom( log(p) + poisson_log_lpmf(Y|log_lambda1) ),
        # Y = 0
        Y|Y==0 ~ custom( log_sum_exp( 
            log(p) + poisson_log_lpmf(0|log_lambda1) , 
            log1m(p)
         ) ),
        # models for rate of behavior and prob possess behavior
        log_lambda1 <- log(L[BID]) + log(D[J]),
        save> logit(p) <- 
            # vocialization intercepts for each group
            a_mean[BID] + a[BID,group[ID]]*sigma + 
            # association of vocalization length with intercept
            bvl*vlen[BID],
        # priors
        bvl ~ normal(0,1),
        vector[M]:L ~ exponential(1),
        vector[M]:a_mean ~ normal(0,1),
        matrix[M,2]:a ~ normal(0,1),
        sigma ~ exponential(1)
    ), data=dat_list , chains=4 , cores=4 , sample=TRUE , iter=500 )

precis(m0u,3,pars=c("a_mean","sigma","bvl"))

# Calculate contrast for each food type between control and manipulated birds
posterior_m0u<-extract.samples(m0u)
pairwisecontrast_byfoodtype<-as.data.frame(matrix(ncol=dat_list$M,nrow=nrow(posterior_m0u$a)))
for(i in 1:dat_list$M){
  pairwisecontrast_byfoodtype[,i]<-posterior_m0u$a[,i,2]-posterior_m0u$a[,i,1]
}
colnames(pairwisecontrast_byfoodtype)<-colnames(dat)
precis(pairwisecontrast_byfoodtype)



### group as treatment yes versus no rather than group as id 1 or 2
dat_list_binary <- list(
    Y = YY,    # behavior counts
    ID = as.integer(as.factor(ID)),   # individual ID
    BID = MM,  # behavior ID
    J = JJ,    # recording ID
    D = ty$obstime, # duration of recording
    M = max(MM), # total number of different food types
    vlen=rep(1,max(MM)), # each of the different food types takes 1 second to process
    group=as.integer(as.factor(ty_minus$Treatment))-1 # 0 = Control, 1 = manipulated
)

# control=0 and treatment=1 with a hyperprior for the differences across the food types
m0u_binary_hyper <- ulam(
    alist(
        # Y > 0
        Y|Y>0 ~ custom( log(p) + poisson_log_lpmf(Y|log_lambda1) ),
        # Y = 0
        Y|Y==0 ~ custom( log_sum_exp( 
            log(p) + poisson_log_lpmf(0|log_lambda1) , 
            log1m(p)
         ) ),
        # models for rate of behavior and prob possess behavior
        log_lambda1 <- log(L[BID]) + log(D[J]),
        save> logit(p) <- 
            # vocialization intercepts for each group
            a_mean[BID] + a[BID]*group[ID] + 
            # association of vocalization length with intercept
            bvl*vlen[BID],
        # priors
        bvl ~ normal(0,1),
        vector[M]:L ~ exponential(1),
        vector[M]:a_mean ~ normal(0,1),
        vector[M]:a ~ normal(a_bar,a_sigma),
        a_bar~normal(0,1),
        a_sigma~exponential(1)
    ), data=dat_list_binary , chains=4 , cores=4 , sample=TRUE , iter=2500 )

precis(m0u_binary_hyper,3,pars=c("a_bar"))



### repeat for foraging techniques

#Load the foraging data
f1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
f1 <- data.frame(f1)

#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
c1 <- f1[f1$Population=="AZ",]

#Count per bird the number of times it took a food type for all food types
f_tech <- c1 %>% group_by(BirdID,How) %>% summarise (Count=n())
f2_tech <- pivot_wider(f_tech,names_from=How,values_from=Count)

# AZ population: How many different food types? 20 (from R code chunk p2manipunregistered)
#length(unique(ft1$What)) #20
#unique(ft1$What) #fry, lizard, unknown, grains, insect, rock, cat food, worm, seed, food crumbs, vegetation, fruit, bird poop, candy, vomit, misc. trash, soil, condiment, carcass, chicken

# AZ population: How many different foraging techniques? 9 (from R code chunk p2manipunregistered)
#length(unique(ft1$How)) # 11 - 1 (eat) - 1 (tolerated theft) = 9
#unique(ft1$How) #eat, gape, lift or nudge, stalk catch, flip, food share, break into pieces, dunk in water, tolerated theft, theft, dig

# link with general datasheet to identify which birds were manipulated and their sum focal time
g <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
g <- data.frame(g)
#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
g <- g[g$Population=="AZ",]
ca<- g %>% group_by(BirdID) %>% summarise (Treatment=unique(FlexibilityManipulated), obstime=unique(SumFocalTime))

ty_tech <- left_join(f2_tech,ca,by="BirdID")
ty_tech <- subset(ty_tech, is.na(ty_tech$Treatment) == FALSE)
ty_tech <- as.data.frame(ty_tech)
#nrow(ty) #NOTE: n=13 (6=manipulated, 7=control) birds because some dropped out due to not having any foraging events in their focals or not having any focals

# Remove "eat" and "tolerated theft" from the techniques
ty_tech<-ty_tech[,-c(2,9)]

#replace NAs with zeros
ty_tech[is.na(ty_tech)] <- 0

# remove food types that neither the manipulated nor the control birds ate: we cannot say whether they are more or less likely to be part of their repertoire
for(i in 2:10){
  if(sum(ty_tech[,i])==0){print(i)}
}

ty_tech_minus<-ty_tech[,-c(9)]


# Convert the table into long form: take the values from the matrix and put them one behind the other, starting with the first row (all counts for bird 1 for all food types) followed by the second row (all counts for bird 2 for all food types), etc.

# Make a matrix that only has the food types and their counts
dat_tech<-ty_tech_minus[,2:9]

YY <- rep(NA,length(dat_tech))
MM <- YY
ID <- YY
JJ <- YY
k <- 1
for ( j in 1:nrow(dat_tech) ) for ( m in 1:ncol(dat_tech) ) {
    YY[k] <- dat_tech[j,m]
    MM[k] <- m
    ID[k] <- ty_tech_minus$BirdID[j]
    JJ[k] <- j
    k <- k + 1
}


### Richard's model: the probability for each bird for each food type that this food type is in their repertoire
dat_list_tech <- list(
    Y = YY,    # behavior counts
    ID = as.integer(as.factor(ID)),   # individual ID
    BID = MM,  # behavior ID
    J = JJ,    # recording ID
    D = ty_tech_minus$obstime, # duration of recording
    M = max(MM), # total number of different food types
    vlen=rep(1,max(MM)), # each of the different food types takes 1 second to process
    group=as.integer(as.factor(ty_tech_minus$Treatment)) # 1 = Control, 2 = manipulated
)

m0u_tech <- ulam(
    alist(
        # Y > 0
        Y|Y>0 ~ custom( log(p) + poisson_log_lpmf(Y|log_lambda1) ),
        # Y = 0
        Y|Y==0 ~ custom( log_sum_exp( 
            log(p) + poisson_log_lpmf(0|log_lambda1) , 
            log1m(p)
         ) ),
        # models for rate of behavior and prob possess behavior
        log_lambda1 <- log(L[BID]) + log(D[J]),
        save> logit(p) <- 
            # vocialization intercepts for each group
            a_mean[BID] + a[BID,group[ID]]*sigma + 
            # association of vocalization length with intercept
            bvl*vlen[BID],
        # priors
        bvl ~ normal(0,1),
        vector[M]:L ~ exponential(1),
        vector[M]:a_mean ~ normal(0,1),
        matrix[M,2]:a ~ normal(0,1),
        sigma ~ exponential(1)
    ), data=dat_list_tech , chains=4 , cores=4 , sample=TRUE , iter=500 )

precis(m0u_tech,3,pars=c("a_mean","sigma","bvl"))

# Calculate contrast for each food type between control and manipulated birds
posterior_m0u_tech<-extract.samples(m0u_tech)
pairwisecontrast_byforagingtechnique<-as.data.frame(matrix(ncol=dat_list_tech$M,nrow=nrow(posterior_m0u_tech$a)))
for(i in 1:dat_list_tech$M){
  pairwisecontrast_byforagingtechnique[,i]<-posterior_m0u_tech$a[,i,2]-posterior_m0u_tech$a[,i,1]
}
colnames(pairwisecontrast_byforagingtechnique)<-colnames(dat_tech)
precis(pairwisecontrast_byforagingtechnique)



### group as treatment yes versus no rather than group as id 1 or 2
dat_list_binary_tech <- list(
    Y = YY,    # behavior counts
    ID = as.integer(as.factor(ID)),   # individual ID
    BID = MM,  # behavior ID
    J = JJ,    # recording ID
    D = ty_tech_minus$obstime, # duration of recording
    M = max(MM), # total number of different food types
    vlen=rep(1,max(MM)), # each of the different food types takes 1 second to process
    group=as.integer(as.factor(ty_tech_minus$Treatment))-1 # 0 = Control, 1 = manipulated
)

# control=0 and treatment=1 with a hyperprior for the differences across the food types
m0u_binary_hyper_tech <- ulam(
    alist(
        # Y > 0
        Y|Y>0 ~ custom( log(p) + poisson_log_lpmf(Y|log_lambda1) ),
        # Y = 0
        Y|Y==0 ~ custom( log_sum_exp( 
            log(p) + poisson_log_lpmf(0|log_lambda1) , 
            log1m(p)
         ) ),
        # models for rate of behavior and prob possess behavior
        log_lambda1 <- log(L[BID]) + log(D[J]),
        save> logit(p) <- 
            # vocialization intercepts for each group
            a_mean[BID] + a[BID]*group[ID] + 
            # association of vocalization length with intercept
            bvl*vlen[BID],
        # priors
        bvl ~ normal(0,1),
        vector[M]:L ~ exponential(1),
        vector[M]:a_mean ~ normal(0,1),
        vector[M]:a ~ normal(a_bar,a_sigma),
        a_bar~normal(0,1),
        a_sigma~exponential(1)
    ), data=dat_list_binary_tech , chains=4 , cores=4 , sample=TRUE , iter=2500 )

precis(m0u_binary_hyper_tech,3,pars=c("a_bar"))

# number of foraging techniques control birds
inv_logit(mean(precis(m0u_binary_hyper_tech,3,pars=c("a_mean"))[,1]))
#> 0.4900608*8
# 3.920486

# number of foraging techniques manipulated birds
inv_logit(mean(precis(m0u_binary_hyper_tech,3,pars=c("a_mean"))[,1])+precis(m0u_binary_hyper_tech,3,pars=c("a_bar"))[1,1])
#> 0.6314007*8
# 5.051206

inv_logit(mean(precis(m0u_binary_hyper_tech,3,pars=c("a_mean"))[,1])+precis(m0u_binary_hyper_tech,3,pars=c("a_bar"))[1,1])*8-inv_logit(mean(precis(m0u_binary_hyper_tech,3,pars=c("a_mean"))[,1]))*8
# 1.130719
```

## 2.2 Did the manipulated birds use more food types than control birds because they ate more often?

Unregistered analysis: we explored whether it was also likely that the manipulated birds used more food types in part because they ate more often than control birds. We found that manipulated birds ate more frequently per minute than control birds (mean=0.18, sd=0.03, 89%CI=0.13-0.24).

```{r p2manipvsctrlsuppfeedingrate, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(dplyr)
library(tidyr)
### NUMBER OF FEEDING EVENTS for flexibility manipulated vs control birds 

# Does the rate at which individuals feed (number of feeding events per minute) differ between the manipulated vs control birds?

#Load the foraging data
f1 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
f1 <- data.frame(f1)

#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
c1 <- f1[f1$Population=="AZ",]

#Count per bird the number of times it took a food type for all food types
f <- c1 %>% group_by(BirdID,What) %>% summarise (Count=n())
f2 <- pivot_wider(f,names_from=What,values_from=Count)
f2<-as.data.frame(f2)
f2[is.na(f2)] <- 0
f2<-mutate(f2,sum=rowSums(f2[2:21]))

# link with general datasheet to identify which birds were manipulated and their sum focal time
g <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
g <- data.frame(g)
#select only the AZ birds who were manipulated or control individuals in the flexibility experiment
g <- g[g$Population=="AZ",]
ca<- g %>% group_by(BirdID) %>% summarise (Treatment=unique(FlexibilityManipulated), obstime=unique(SumFocalTime))

ty <- left_join(f2,ca,by="BirdID")
ty <- subset(ty, is.na(ty$Treatment) == FALSE)
ty <- as.data.frame(ty)
#nrow(ty) #NOTE: n=13 (6=manipulated, 7=control) birds because some dropped out due to not having any foraging events in their focals or not having any focals

dat_list_rate<- list(events = ty$sum,
                     treatment=as.integer(as.factor(ty$Treatment)),
                     obstime=standardize(ty$obstime)
              )
# POISSON model: want to know whether the slope (rate) between observation time and the number of feeding events is different for treatment versus control
set.seed(19)
events_poi <- ulam( alist(
        events ~ dpois(lambda),
        log(lambda) <- a + b[treatment]*obstime, #include total observation time because this varied per focal (with a target max time of 10 min)
        a ~dnorm(0,1) , #expect 1 technique as soon as start collecting data (time can never be zero)
        b[treatment] ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=dat_list_rate , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
outputevents_poi <- precis(events_poi,depth=2)
#     mean   sd 5.5% 94.5% n_eff Rhat4
#a[1] 0.50 0.23 0.11  0.86  1062     1
#a[2] 1.14 0.20 0.81  1.43  1066     1
#b    0.71 0.15 0.48  0.96  1086     1

#contrast to see if treatment groups differ
posteventspoi <- extract.samples(events_poi)
diffeventspoi <- exp( posteventspoi$b[,1]) - exp( posteventspoi$b[,2])
contrasteventspoi <- precis( diffeventspoi )
#         mean   sd  5.5% 94.5%  histogram
               mean   sd 5.5% 94.5%      histogram
# diffeventspoi -1.67 0.38 -2.3 -1.09 ▁▁▁▁▂▃▇▇▇▅▂▁▁▁
#manipulated birds eat more frequently than control birds
  

## BINOMIAL model - USE THIS ONE because the output is easier to interpret because already on the right scale 
dat_list_rate_binom<- list(events = ty$sum,
                     treatment=as.integer(as.factor(ty$Treatment)),
                     obstime=ty$obstime
              )               
                            
     events_binom <- ulam( alist(
        events ~ dbinom(obstime,p),
        logit(p) <- a + b[treatment], #include total observation time because this varied per focal (with a target max time of 10 min)
        a ~dnorm(0,1) , #expect 1 technique as soon as start collecting data (time can never be zero)
        b[treatment] ~ dnorm(0,1) #our prior expectation for b is that it is around 0, can be negative or positive, and should not be larger than 1
    ) , data=dat_list_rate_binom , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))
outputevents_binom <- precis(events_binom,depth=2)          
posteventsbinom <- extract.samples(events_binom)
diffeventsbinom <- inv_logit( posteventsbinom$b[,1]+posteventsbinom$a[,1]) - inv_logit( posteventsbinom$b[,2]+posteventsbinom$a[,1])
contrasteventsbinom <- precis( diffeventsbinom *60 )    
#                       mean   sd  5.5% 94.5%      histogram
# diffeventsbinom...60 -0.18 0.03 -0.24 -0.13 ▁▁▁▁▁▃▅▇▇▅▂▁▁▁
# control birds have 0.18 fewer feeding events per minute.


# Visualize
#generate the lines from the model
predevents_control<-link(events_binom,data=data.frame(treatment=rep(1,1),obstime=3500))
predevents_control_mean<-apply(predevents_control,2,mean)
predevents_control_seq<-predevents_control_mean*seq(from=0,to=9000,length=10)

predevents_manipulated<-link(events_binom,data=data.frame(treatment=rep(2,1),obstime=3500))
predevents_manipulated_mean<-apply(predevents_manipulated,2,mean)
predevents_manipulated_seq<-predevents_manipulated_mean*seq(from=0,to=9000,length=10)

#plot
plot(dat_list_rate_binom$events ~ dat_list_rate_binom$obstime,col=dat_list_rate_binom$treatment)
lines(predevents_control_seq ~  seq(from=0,to=9000,length=10),col=1)
lines(predevents_manipulated_seq ~  seq(from=0,to=9000,length=10),col=2)
```

# REFERENCES
