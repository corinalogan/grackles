---
title: Behavioral flexibility is (un)related to foraging and social behavior in a rapidly expanding species
author: 
- '[Logan CJ](http://CorinaLogan.com)^1^*'
- '[Lukas D](http://dieterlukas.mystrikingly.com)^1^*'
- 'LeGrande-Rolls C^1^'
- 'Bergeron L^2^'
- 'Folsom M^1^'
- 'Marfori Z^1^'
- '[McCune KB](https://www.kelseymccune.com)^2^'
date: '`r Sys.Date()`'
always_allow_html: yes
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
    code_folding: hide 
  github_document: 
    toc: true
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
  md_document: 
    toc: true
bibliography: MyLibrary.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
urlcolor: blue
header-includes:
  - \usepackage[left]{lineno}
  - \linenumbers
  - \usepackage{fancyhdr}
  - \usepackage{pdflscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
---

Open... ![](logoOpenAccess.png){width=5%} access ![](logoOpenCode.png){width=5%} [code](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforaging.Rmd) ![](logoOpenPeerReview.png){width=5%} peer review ![](logoOpenData.png){width=5%} [data]()

&nbsp;

**Affiliations:** 1) Max Planck Institute for Evolutionary Anthropology, Leipzig, Germany, 2) University of California Santa Barbara, USA. *Corresponding author: corina_logan@eva.mpg.de

```{r setup, include=FALSE}
library(knitr)
library(formatR)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=70),tidy=TRUE) 
#Make code chunks wrap text so it doesn't go off the page when knitting to PDF

knitr::opts_chunk$set(echo=T, include=T, results='asis', warning=F, message=F) 
#sets global options to display code along with the results https://exeter-data-analytics.github.io/LitProg/r-markdown.html
#set echo=F for knitting to PDF (hide code), and echo=T for knitting to HTML (show code)
```

&nbsp;

**This is the post-study manuscript of the preregistration that was pre-study peer reviewed and received an In Principle Recommendation on 6 Aug 2019 by:**

Julia Astegiano and Esther Sebastián Gonzalez (2019) Understanding geographic range expansions in human-dominated landscapes: does behavioral flexibility modulate flexibility in foraging and social behavior? *Peer Community in Ecology*, 100026. [10.24072/pci.ecology.100026](https://doi.org/10.24072/pci.ecology.100026). Reviewers: Pizza Ka Yee Chow and Esther Sebastián González

**Preregistration:** [html](http://corinalogan.com/Preregistrations/g_flexforaging.html), [pdf](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforagingPassedPreStudyPeerReviewOn6Aug2019.pdf), [rmd](https://github.com/corinalogan/grackles/blob/d17a75c24df4b90aa607eda452f4fcc496ae9409/Files/Preregistrations/g_flexforaging.Rmd)

**Post-study manuscript** (submitted to PCI Ecology for post-study peer review on ?): preprint [pdf]() at EcoEvoRxiv, [html](http://corinalogan.com/Preregistrations/g_flexforaging2.html), [rmd](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforaging.Rmd)


# ABSTRACT

This is one of the first studies planned for our long-term research on the role of behavioral flexibility in rapid geographic range expansions. **Project background:** Behavioral flexibility, the ability to change behavior when circumstances change based on learning from previous experience (@mikhalevich_is_2017), is thought to play an important role in a species' ability to successfully adapt to new environments and expand its geographic range (e.g., @lefebvre1997feeding, @griffin2014innovation, @chow2016practice, @sol2000behavioural, @sol2002behavioural, @sol2005big). However, behavioral flexibility is rarely directly tested at the individual level, thus limiting our ability to determine how it relates to other traits (e.g., behavior, invasion success, diet generalism, foraging techniques, foraging innovations, mortality, brain size), which limits the power of predictions about a species' ability to adapt behavior to new environments. We use great-tailed grackles (a bird species) as a model to investigate this question because they have rapidly expanded their range into North America over the past 140 years (i.e., they increased their nesting range by over 5500% between 1880 and 2000 [@wehtje2003range], [@peer2011invasion]) (Fig. 1). Foraging behavior is considered central to the rapid geographic range expansion of this species and it is thought that they have been so successful by following human urban and agricultural corridors (@wehtje2003range, @peer2011invasion). Therefore, as humans continue to modify landscapes, this increases the amount of suitable grackle habitat. We expect this species to be behaviorally flexible because they are fast at reversal learning (@logan2016behavioral), they often encounter human-made "puzzle boxes" in the wild as they attempt to open packaging to access food when digging through garbage cans and eating at outdoor cafes, and they may track resources across time and space. Results will allow us to determine whether, as predicted by hypotheses and cross-species correlational data, in this expanding species, individual-level variation in flexibility is linked with diet breadth, foraging proficiency, social interactions, habitat use, and movement into new geographic areas. **This investigation**: In this piece of the long-term project, we will assess whether individual performance in experiments that assess behavioral flexibility relates to individual variation in ecological and social behavior in the natural environment. In particular, we aim to determine whether the more behaviorally flexible (measured by reversal learning and solution switching on a multi-access box in a separate [preregistration](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md)) grackles have more flexible foraging behavior (eat a larger number of different foods, use a wider variety of foraging techniques), are more flexible in their habitat use (are found in more diverse habitat types, disperse farther from their natal area), and are more flexible in their social relationships (have more or stronger social bonds particularly with less related individuals). We will be able to compare the grackle's ability to adapt behavior according to social context with data from other species, as well as determine whether it is linked with measures of flexibility in asocial contexts.  


# INTRODUCTION



## HYPOTHESES

### H1: [Behavioral flexibility](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md) [see @mikhalevich_is_2017 for a detailed definition] is related to foraging behavior (measured with focal follows using this [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing)) in wild individuals (after their release from the aviaries). We measure flexibility in aviaries using two paradigms: reversal learning [where grackles must learn to prefer one of two options that contain food and then reverse this preference] and switching between options on a multi-access box (where grackles must learn to switch to a new option, out of four available options, when an option becomes non-functional). We expect this species to be behaviorally flexible because they are fast at reversal learning [@logan2016behavioral], they often encounter human-made "puzzle boxes" in the wild as they attempt to open packaging to access food when digging through garbage cans and eating at outdoor cafes, and they may track resources across time and space. Foraging behavior is considered central to the rapid geographic range expansion of this species and it is thought that they have been so successful by following human urban and agricultural corridors [@wehtje2003range; @peer2011invasion]. Therefore, as humans continue to modify landscapes, this increases the amount of suitable grackle habitat.

**Prediction 1:** Individuals that are faster to reverse preferences on a reversal learning task and who also have lower latencies to switch to solving new loci after previously solved loci become unavailable (multi-access box) will eat a larger number of different foods and use a wider variety of foraging techniques in the wild, validating the cross-species correlational finding that technique breadth [@overington2009technical] and diet breadth [@ducatez2015ecological] is associated with flexibility.

**P1 alternative 1:** If there is no correlation, this suggests that flexibility as we measured it represents a trait that is not related to the number of foods eaten and foraging techniques used. Flexibility may not necessarily be associated with diet and foraging technique breadth because flexibility could be constrained in a foraging context due to social competition (e.g., subordinates are outcompeted while foraging and thus try new foods and techniques) or ecological limitations (e.g., constrained by what is available). Additional research would be required to determine the factors that might constrain foraging behavior.

**P1 alternative 2:** If there is a negative correlation between flexibility and the number of different foods eaten, this might indicate that the more flexible individuals target particular food items. If this prediction is supported, we will conduct an additional analysis to examine what food types the more flexible grackles eat and whether these food types are potentially more valuable (measured as having more calories).

**P1 alternative 3:** If there is a negative correlation between flexibility and the number of foraging techniques, this could indicate that the more flexible individuals use particular (potentially more effective) techniques.

**P2:** Individuals whose [flexibility](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md) has been increased experimentally will consume a larger number of foods and use more foraging techniques (measured with focal follows) than individuals whose flexibility has not been manipulated. This would further validate that flexibility is related to diet breadth and foraging techniques. 

**P2 alternative 1:** If the flexibility manipulation does not work in that those individuals in the experimental condition do not decrease their reversal learning speeds more than control individuals, then we will rely on the general individual variation in flexibility and how it relates to foraging in the wild (as in P1).

**P3:** The proportion of a grackle's diet that is human foods and the proportion of their foraging techniques involving human foods is higher for the more flexible individuals, who will consistently occur in locations closer to known outdoor human food locations like picnic areas and outdoor cafe seating (measured as the repeatability of the individual's distance from cafes across multiple separate focal follows) OR who will occupy a home range that contains more outdoor human food locations. For the diet, this is potentially due to A) having stayed in their parent's home range (i.e., they eat human food because it happens to be more prevalent in their home range than in other home ranges; local specialization) or B) because these individuals move around to seek out such opportunities (potentially seeking out habitat edges within their population). For the foraging techniques, this is potentially due to human foods and their packaging changing at a faster rate than natural foods and prey items and their accessibility. Foods  eaten and foraging techniques used will be recorded during focal follows. Because this species is highly associated with human-modified landscapes, it is likely that consuming human foods is part of the reason for this association, and that flexible individuals are better at solving these human-made "puzzle boxes" to access food.

**P3 alternative 1:** There is no correlation between an individual's flexibility and the proportion of human foods in their diet, potentially because A) their daily range sizes encompass many different food resources, including human foods (though they are likely not specialized on human foods), and B) some less flexible individuals might specialize on human foods.

**P3 alternative 2:** There is a negative correlation between an individual's flexibility and the proportion of human foods in their diet, potentially because some of the less flexible individuals might specialize on human foods, thus increasing their consumption above that of the more flexible individuals.

### H2: [Behavioral flexibility](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md) [see @mikhalevich_is_2017 for a detailed definition] is related to social behavior (measured year-round with focal follows using this [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing)) in wild individuals. Flexibility is measured in aviaries using two paradigms: reversal learning and switching between options on a multi-access box. To give an example of the types of social relationships this sexually dimorphic species engages in, they forage and roost socially [@selander1961analysis] and they have a non-faithful-male frank polygynous mating system [@johnson2000male]. In terms of male social relationships, @johnson2000male found during the breeding season in a population in Texas that one or more territorial males defend a territory with several nests from females, that non-territory holding resident males will queue to gain access to a territory, and that transient males move from colony to colony. There could be varying needs for males to manage their relationships with each other in breeding and non-breeding seasons, and flexibility could potentially play a role in such management.

**P4** Flexible individuals are more likely to have a greater number of bonds OR stronger bonds with others, in particular with individuals who are less related, potentially because they are better able to adjust their behavior to that of an affiliate. Social bonds are measured using the focal follow method to sample affiliative and aggressive behaviors.

**P4 alternative 1:** Individual flexibility is not related to the number or strength of social bonds, potentially because all individuals are able to form bonds with like individuals, including the less flexible individuals.

**P4 alternative 2:** Flexible individuals may have fewer affiliates or be less likely to regularly affiliate with the same individuals, potentially because they frequently change their behavior and are difficult to associate with. We are not able to test this alternative in this study, but could propose experimental designs for future research if this alternative is supported by the data.


# METHODS

Please see our preregistration that received in principle acceptance at PCI Ecology [PDF](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_flexforagingPassedPreStudyPeerReviewOn6Aug2019.pdf) for the preregistered methods. We include here a summary of the methods and describe the deviations from the preregistration. 

## Planned sample and data collection stopping rule

Great-tailed grackles (n > 200) were caught in the wild at three field sites across their geographic range: the center of their original range (at a site to be determined in Central America), the middle of the northward expanding edge (Tempe, Arizona USA), and on the northern expanding edge (Sacramento, California USA). Individuals were identified using colored leg bands in unique combinations, their data collected (blood, feathers, and biometrics), and then they were released back to the wild. Some individuals (64-100, minimum 60) were brought temporarily into aviaries for behavioral testing, and then released back to the wild where the data for this study were collected. We will stop collecting data in April 2023 when the current funding ends, or after data have been collected at all three field sites, whichever date comes first.

 - **Deviation from the plan:** We originally planned to collect data from three field sites: the middle of the northward expanding edge (Tempe, Arizona), on the northern expanding edge (this ended up being in Sacramento, California), and at a site in the center of their original range (Central America). We ended up not being able to run the Central American site because the research station we were planning on using as the base for the site was exposed for having decades of sexual abuse toward women. We did not feel comfortable being at that station or bringing our business there, and it was too late to find another site because they take years to set up. Therefore, we have data only from two field sites and not three. This also means our sample size was not >200 grackles as originally planned. Our sample size ended up being 66 grackles with focal follow data in Arizona and 32 grackles in California, for a total of 98. We had also planned on bringing at least 60 of these grackles into the aviaries for behavioral choice tests. Of the grackles we brought into the aviaries, 49 (20 in Arizona and 19 in California) ended up completing their reversal learning experiment. We stopped collecting data in December 2022 when the California field site's data collection was complete.

## Open materials

 - [Ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing) for Prim8

 - [Individuals](https://docs.google.com/spreadsheets/d/1Lr0pwsmdnpVM8X2Fyoj9EIGa3zOY1WCZlntW7e0Ui_Y/edit?usp=sharing) for Prim8

 - [Protocol](https://docs.google.com/document/d/1SMUy43qRd52BBTZM5Oe2hpSExBLRAC6iUVyGvrAlgqs/edit?usp=sharing) for cleaning the focal follow data

## Open data

The data, scripts, and code are available at the Knowledge Network for Biocomplexity's data repository [@logan2023flexforagingdata].


## Dependent variables

***P1-P2***

1) Number of different foods eaten in the first X minutes (X=the sum of the total observation time per individual, using the individual who had the lowest sum to equalize observation time across individuals)

2) Number of foraging techniques used (based on Table 1 in @overington2009technical) in the first X minutes (X=the sum of the total observation time per individual, using the individual who had the lowest sum to equalize observation time across individuals)

One model will be run per dependent variable.

***P1 alternative 2 additional analysis: flexible = more valuable food types***

Food type (listed under the What modifier in the Eat behavior in the [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing))

***P3: flexible = more human foods***

1) Proportion of diet per individual that is human food

2) Distance to outdoor human food areas during focal follows

3) Number of outdoor human food areas within the home range

***P4: flexible = a greater number of bonds or stronger bonds***

1) Strength of the maximum bond (calculated as the half-weight index based on association behavior during focal follows. See Analysis Plan > P4 for a complete description). 

2) Individual strength (the sum of all bonds an individual has; @wey2008social)

3) Individual degree (maximum number of other individuals that the focal subject associated with; @wey2008social).

4) Male shares territory with another male: yes, no

5) Relatedness for the strongest bond (measured following the protocol in @thrasher2018double to estimate pairwise relatedness between all individuals based on the extent of sharing of genetic variants as determined by ddRADseq)

## Independent variables

***P1-P4***

1) Flexibility 1: **Number of trials to reverse** a preference in the last reversal (in the reversal learning experiment) an individual experienced (individuals in the flexibility control group only experience 1 reversal so this data will come from their first and only reversal; individuals in the flexibility manipulation group experience serial reversals until they pass a certain criterion, therefore we will only use data from their most recent reversal). An individual is considered to have a preference if it chose the rewarded option at least 17 out of the most recent 20 trials, with a minimum of 8 or 9 correct choices out of 10 on the two most recent sets of 10 trials). See behavioral flexibility [preregistration](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md).

2) Flexibility 3: If the number of trials to reverse a preference does not positively correlate with the number of trials to attempt or solve (meet criterion) new loci on the multi-access box (an additional measure of behavioral flexibility), then the **number of trials to solve** and the **number of trials to attempt** a new option on the multi-access box will be additional dependent variables. See behavioral flexibility [preregistration](https://github.com/corinalogan/grackles/blob/master/EasyToReadFiles/g_flexmanip.md).

3) Flexibility 4: This measure is currently being developed and is intended be a more accurate representation of all of the choices an individual made, as well as accounting for the degree of uncertainty exhibited by individuals as preferences change. It will be based on a Bayesian estimate of the reduction in error across trials estimated from the number of correct choices from the beginning of each reversal. If this measure more effectively represents flexibility (determined using a modeled dataset and not the actual data), we may decide to solely rely on this measure and not use flexibility measures 1 through 3. If this ends up being the case, we will modify the code in the analysis plan below to reflect this change.

4) Flexibility manipulation: control, manipulated

5) Dominance rank: measured as the number of wins minus the number of losses, divided by the sum of wins + losses. This calculation will give each individual a dominance rank number, and we will order individuals by rank from lowest to highest to create a dominance hierarchy.

6) Condition: aviary-tested, not-aviary-tested

7) ID (random effect because multiple measures per individual)

8) Population: center (Central America), middle (Arizona), edge (northern US) (random effect because each population might have a different slope)

***P1 alternative 2 additional analysis: flexible = more valuable food types***

Flexibility 1 (as above)



## ANALYSIS PLAN

We did not exclude any data. When missing data occurred, the existing data for that individual was included in the analyses for the tests they completed. Analyses were conducted in R [current version `r getRversion()`; @rcoreteam], using several R packages: @kableextra, @stargazer, @hadfield2010mcmcglmm, @mumin, @rethinking2020, @rstan, @formatr, @rstudioapi, @rcpp, @ggplot2, knitr [@xie2018knitr; @xie2017dynamic; @xie2013knitr], @dplyr, @cmdstanr, posterior [@burkner2020posterior], cowplot [@wilkecowplot], bayesplot [@gabry2019visualization], irr [@gamer2012package], psych [@revelle2014psych; @psych], @reactable, DHARMa [@hartig2019dharma], lme4 [@lme4; @bates2012lme4]. When there was more than one experimenter within a test, experimenter was added as a random effect to account for potential differences between experimenters in conducting the tests. When there are no differences between models including or excluding experimenter as a random effect, then we use the model without this random effect for simplicity. We analyzed data for ffales and males separately because each sex has a distinct natural history.

 - **Deviation from the plan:** We removed experimenter (random variable) from all analyses because the interobserver reliability scores were so high, indicating there was no difference between experimenters, therefore we could keep our models simpler by leaving this variable out.

### Calculating the independent variable Flexibility 4 (phis and lambdas)

We used the phis and lambdas from each bird's initial discrimination plus first reversal (for the CA birds and AZ control birds) or the last two reversals (for the AZ manipulated birds). We calculated the phis and lambdas using the model and code from @lukas2022flexmanip, and entered these into the data sheets used for the analyses in the results section.

```{r phislambdas, eval=FALSE}
### Code below copied from Lukas et al. 2022. Using OBSERVED (not simulated) data from GTGR in Woodland/Sacramento and Tempe

# These are the phis and lambas for the AZ birds using their LAST 2 switches
eachbirdslearningparameters<-read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexmanip_ArizonaBirds_EstimatedPhiLambdaReversalLearning.csv"), header=T, sep=",", stringsAsFactors=F)


# The code below gets the phis and lambdas for the first 2 switches, so only use it to calculate the CA data
# We want to estimate lambda and phi differently. For the initial values, we combine the data from the first association learning with the first reversal.
dflex <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/gxpopbehavhabitat_data_reversegtgr.csv"), header=T, sep=",", stringsAsFactors=F) 

library(rstan)
library(rethinking)
library(cmdstanr)
library(posterior)

# If you have cmdstan installed, use the following:
# set_ulam_cmdstan(TRUE)

# PREPARE reversal learning data
#exclude birds that did not finish the reversal experiment
dflex <- dflex[!dflex$ID=="Chocolate" & !dflex$ID=="Xango" & !dflex$ID=="Wachil" & !dflex$ID=="Talingo" & !dflex$ID=="Quiscalus" & !dflex$ID=="Churro" & !dflex$ID=="Sopapilla" & !dflex$ID=="Tres Leches" & !dflex$ID=="Merengue" & !dflex$ID=="Carlota" & !dflex$ID=="Changa" & !dflex$ID=="Urraca" & !dflex$ID=="Bacmut bacni" & !dflex$ID=="Zanate",] 

#include only those trials where the bird made a choice (0 or 1)
dflex <- subset(dflex, dflex$CorrectChoice != -1) #reverse number. 0=initial discrimination
dflex$Reversal <- as.integer(dflex$Reversal)

dflex$Correct <- as.integer(dflex$CorrectChoice)
dflex$Trial <- as.integer(dflex$Trial)
#exclude NAs from the CorrectChoice column
dflex <- subset(dflex, is.na(dflex$Correct) == FALSE)

# Want data ONLY from initial learning and first reversal to determine phi and lambda at the beginning. This is for all birds, including those that did not experience the reversal manipulation experiment
reduceddata <- matrix(ncol=ncol(dflex),nrow=0)
reduceddata <- data.frame(reduceddata)
for (i in 1:length(unique(dflex$ID))) {
  thisbird <- unique(dflex$ID)[i]
  thisbirddata <- dflex[dflex$ID==thisbird,]
  thisbirdslastreversal <- thisbirddata[thisbirddata$Reversal %in% c(0,1),]
  reduceddata <- rbind(reduceddata,thisbirdslastreversal)
}
dflex_beginning <- reduceddata

# We want to remove the birds who did not complete at least the first reversal
birdscompletedreversal<-unique(dflex_beginning[dflex_beginning$Reversal==1,]$ID)

dflex_beginning<-dflex_beginning[dflex_beginning$ID %in% birdscompletedreversal,]

length(unique(dflex_beginning$ID)) #39 birds

#Construct Choice variable to match with how the STAN model is set up.
dflex_beginning$Choice <- NA
for (i in 1: nrow(dflex_beginning)) {
  if (dflex_beginning$Reversal[i] %in% seq(0, max(unique(dflex_beginning$Reversal)), by = 2)){
    
    if (dflex_beginning$Correct[i] == 1){
      dflex_beginning$Choice[i] <- 1
    } else {
      dflex_beginning$Choice[i] <- 2
    } 
  } else {
    if (dflex_beginning$Correct[i] == 1){
      dflex_beginning$Choice[i] <- 2
    } else {
      dflex_beginning$Choice[i] <- 1
    } 
  }
}
dflex_beginning <- dflex_beginning[with(dflex_beginning, order(dflex_beginning$ID)), ]

#enter the column name for the individual's name here (ID) and then we will change it to small "id" to match the stan code below
colnames(dflex_beginning)[colnames(dflex_beginning)=="ID"]<-"id"

# Sort birds alphabetically; we do this so we can later on rematch the names to the numerical ids.
dflex_beginning <- dflex_beginning[with(dflex_beginning, order(dflex_beginning$id)), ]

# Store the bird names
birdnames<-unique(dflex_beginning$id)

# Convert bird names into numeric ids
dflex_beginning$id <- as.numeric(as.factor(dflex_beginning$id))

# Select only the columns that are of relevance. In particular, remove any additional columns that contain missing values.
dflex_beginning<-dflex_beginning[,c("id","Reversal","Trial","CorrectChoice","Correct","Choice")]

# Prepare the data in the setup for the STAN model, as a list
datinitialandfirstreversal <- as.list(dflex_beginning)
datinitialandfirstreversal$N <- nrow(dflex_beginning)
datinitialandfirstreversal$N_id <- length(unique(dflex_beginning$id))

datinitialandfirstreversal$Reversal<-as.numeric(as.factor(datinitialandfirstreversal$Reversal))
datinitialandfirstreversal$CorrectChoice<-as.numeric(as.factor(datinitialandfirstreversal$CorrectChoice))


# The STAN model is set up to have the initial attraction for each option set to 0.1, and that individuals only learn the reward of the option they chose in a given trial.
reinforcement_model_nonzeroattraction_alternativepriors <- "

data{
   int N;
   int N_id;
   int id[N];
   int Trial[N];
   int Choice[N];
   int Correct[N];
}

parameters{
  real logit_phi;
  real log_L;

  // Varying effects clustered on individual
  matrix[N_id,2] v_ID;
}

model{
matrix[N_id,2] A; // attraction matrix

logit_phi ~  normal(0,1);
log_L ~  normal(0,1);

// varying effects
to_vector(v_ID) ~ normal(0,1);

// initialize attraction scores

for ( i in 1:N_id ) {
A[i,1] = 0.1; A[i,2] = 0.1;
}

// loop over Choices

for ( i in 1:N ) {
vector[2] pay;
vector[2] p;
real L;
real phi;

// first, what is log-prob of observed choice

L =  exp(log_L + v_ID[id[i],1]);
p = softmax(L*A[id[i],1:2]' );
Choice[i] ~ categorical( p );

// second, update attractions conditional on observed choice

phi =  inv_logit(logit_phi + v_ID[id[i],2]);
pay[1:2] = rep_vector(0,2);
pay[ Choice[i] ] = Correct[i];
A[ id[i] , Choice[i] ] = ( (1-phi)*(A[ id[i] , Choice[i] ]) + phi*pay[Choice[i]]);

}//i
}
"

# RUN MODEL OPTION 1: The first way to run the model is directly through rstan. This does not work on some computers because of the way the interfacing runs. If it doesn't work on your computer, use Option 2 below, which uses cmdstan
m_initialandreversal <- stan( model_code =  reinforcement_model_nonzeroattraction_alternativepriors, data=datinitialandfirstreversal ,iter = 5000, cores = 4, chains=4, control = list(adapt_delta=0.9, max_treedepth = 12))

sinitialandreversal <- extract.samples(m_initialandreversal)
initialandreversal_lambda <- sapply(1 : datinitialandfirstreversal$N_id, function(x) exp( mean(sinitialandreversal$log_L) + mean(sinitialandreversal$v_ID[ ,x, 1])))
initialandreversal_phi <- sapply(1 : datinitialandfirstreversal$N_id, function(x) inv_logit( mean(sinitialandreversal$logit_phi) + mean(sinitialandreversal$v_ID[ ,x, 2])))

plot(initialandreversal_phi~initialandreversal_lambda)

# Combine the extracted values in a dataframe, and link them back to the id of the individuals
birds_phi_lambda<-matrix(ncol=3,nrow=length(birdnames))
birds_phi_lambda<-as.data.frame(birds_phi_lambda)
colnames(birds_phi_lambda)<-c("id","phi","lambda")
birds_phi_lambda$id<-birdnames
birds_phi_lambda$phi<-initialandreversal_phi
birds_phi_lambda$lambda<-initialandreversal_lambda
#here is the table with the phis and lambdas!
birds_phi_lambda 
#DONE with Option 1


# RUN MODEL OPTION 2: This alternative setup uses cmdstanr to run the model. It first needs to create an executable on your computer for the model for which you need to specify the path to where it can find the relevant compilers.
currentlocation<-getwd()
cmdstanlocation <- cmdstan_path()
setwd(cmdstanlocation)

# access the output file created by the model running the reinforcement model / reinforcement_model_nonzeroattraction_alternativepriors
write(reinforcement_model_nonzeroattraction_alternativepriors,file="myowntrial.stan")
file <- file.path(cmdstan_path(), "myowntrial.stan")
mod <- cmdstan_model(file)
options(mc.cores=4)

# RUN the model
fit_initialandfirstreversal <- mod$sample(
  data = datinitialandfirstreversal,
  chains = 4,
  parallel_chains = 4,
  refresh = 500
)

# Show the 90% compatibility intervals for the association between latency to switch loci on the plastic multi-access box and lambda and phi, and the interaction between lambda and phi from the reinforcement learning model
drawsarray<-fit_initialandfirstreversal$draws()
drawsdataframe<-as_draws_df(drawsarray)
drawsdataframe<-data.frame(drawsdataframe)
initialandreversal_lambda <- sapply(1 : datinitialandfirstreversal$N_id, function(x) exp( mean(drawsdataframe$log_L) + mean(drawsdataframe[,x+3]))) 
initialandreversal_phi <- sapply(1 : datinitialandfirstreversal$N_id, function(x) inv_logit( mean(drawsdataframe$logit_phi) + mean(drawsdataframe[,x+3+length(unique(datinitialandfirstreversal$id))])))

# Remove the stan command line file we created for this particular model from your computer
fn<-"myowntrial"
file.remove(fn)

# Reset your working directory to what it was before we ran the model
setwd(currentlocation)

# Combine the extracted values in a dataframe, and link them back to the id of the individuals
birds_phi_lambda<-matrix(ncol=3,nrow=length(birdnames))
birds_phi_lambda<-as.data.frame(birds_phi_lambda)
colnames(birds_phi_lambda)<-c("id","phi","lambda")
birds_phi_lambda$id<-birdnames
birds_phi_lambda$phi<-initialandreversal_phi
birds_phi_lambda$lambda<-initialandreversal_lambda
#here is the table with the phis and lambdas!
birds_phi_lambda 
#DONE with Option 2
```

### Data checking

The data will be checked for overdispersion, underdispersion, zero-inflation, and heteroscedasticity with the DHARMa R package [@hartig2019dharma] following methods by [Hartig](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html). Note: DHARMa doesn't support MCMCglmm, therefore we will use the closest supported model: glmer from the R package lme4 [@lme4].

### Ability to detect actual effects

To begin to understand what kinds of effect sizes we will be able to detect given our sample size limitations and our interest in decreasing noise by attempting to measure it, which increases the number of explanatory variables, we will revise the Analysis Plan after reading @statrethinkingbook. We currently don’t have any estimates for any of our measured variables because these tests have never been done in grackles and we have not encountered previous research that has manipulated flexibility in this way. We will use Bayesian analyses to estimate our likely confidence in the results given simulated data. We will revise this preregistration to include these new analyses before conducting the planned analyses on our actual data. Based on the simulations, we might adapt the number of focal follows per individual or decide to collect much more data just with the aviary-tested birds to increase the amount of information per individual.

## Deviations from the prepregistration

**In the middle of data collection**

 - Because all models only include aviary-tested birds for our analyses, Condition (IV6), which indicates whether a bird is aviary-tested or not-aviary-tested, does not need to be included as an independent variable as we originally indicated. (13 July 2022)
 - The Flexibility 4 independent variable calculates the phi and lambda of aviary-tested birds, and as such, it is redundant to include IV4: Flexibility manipulation as an independent variable in the analysis. (13 July 2022)
 - Initially, the dependent variables for P1 and P2 calculated the number of different foods eaten and the number of foraging techniques used in the first X minutes of a focal follow. To equalize observation time across individuals, X minutes was the total observation time using the individual with the lowest sum across all individuals. As we started to clean the data and prepare it for analysis, we noticed three individuals had no focal follows (sum focal time = 0) and the next lowest sum focal time was 497 seconds. The average sum focal time across all 38 individuals was 3024 seconds, leaving an excess of data that would be excluded given the originally prescribed calculation of the dependent variables. Therefore, we changed this to a proportion and divided the number of different foods eaten and the number of foraging techniques used by an individual with the sum observation time across that individual’s focal follows. The analysis for the P1 and P2 dependent variables accommodated this change by adjusting from a poisson to a binomial distribution. (3 August 2022)

## P1:


## P2:


## P3:


## P4: Flexibility and social bonds

**Analysis:** A GLMM was conducted as in P1-P2.

To quantify social relationships, we will conduct at least four 10-minute focal follows on each subject spaced equally across breeding and non-breeding seasons. We will find subjects in the wild because we will attach radio transmitter tags to all grackles that are released from the aviaries upon completion of their test battery. To ensure we fully sample social and foraging behavior, we will prioritize conducting focal follows on these tagged grackles for which we have a much larger amount of individualized data, including multiple measures of flexibility. We will also sample many other color marked grackles that were never tested in the aviaries, and thus do not have measures of flexibility. By conducting focal follows on grackles that were not in captivity, we can verify that the time in captivity had no effect on grackle social behavior after release because aviary-tested birds should be indistinguishable from non-aviary-tested birds in these analyses.

To measure affiliative bonds, during each focal follow we will record when another grackle comes within one body length of the focal bird (and does not engage in aggressive interactions). In case we do not observe enough of these close associations, we will also record when another grackle comes within 3m of the focal subject (and does not engage in aggressive interactions). Finally, we will conduct a scan sample at the end of the follow to determine group size as the number of other grackles within 10m of the focal individual. Unmarked grackles that are seen in proximity of the focal individual will be recorded and included in the count of group size and individual degree (the number of unique associates), but because we cannot distinguish unmarked individuals from each other, we will exclude unmarked bird data from calculations of an individual’s summed bond strengths (see details in the next paragraph).  

We will also measure aggressive behavioral interactions, as indicated in our ethogram. The outcome of these dyadic interactions will be used to create our index of dominance (wins - losses / wins + losses). 

We will conduct subsequent follows on the same individual only when 3 or more weeks have passed since the previous focal follow to prevent temporal autocorrelation in behavior (@whitehead2008analyzing). From the data sheet of dyadic associations during focal follows, we will create a matrix of association strengths between all marked grackles by calculating the Half-Weight association index. This index determines association strength based on the proportion of observations in which two individuals are seen together versus separately, and accounts for bias arising from subjects that are more likely to be observed separately rather than together in the same group (@cairns1987comparison). From the matrix of association values, we will use the R package igraph (@csardi2006igraph) to create a social network, and calculate each individual’s strength (sum of all association values) and degree (maximum number of unique associates) values (@croft2008exploring).

Before analyzing degree and strength, we will determine if these values differ between breeding (Apr - Aug) and non-breeding seasons (Sept - Mar) because social associations could change as a result of breeding behaviors. If there is no difference, we will combine all data for the analyses described below. Neither of the social network metrics (strength or degree) varied by season (sexes combined), so we proceed with the analysis of the breeding and non-breeding season data combined (INSERT STATS THAT SHOW THIS).

```{r p4pt2season, eval = F}
### Social network values differ by season? ###
#Load social data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

#Exclude unbanded birds
ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 

ff1 <- subset(ff1, is.na(ff1$FocalBirdID) == FALSE) #257 banded-banded bird associations
ff1aff <- subset(ff1, ff1$BehavType == "affiliative") #171 affiliative (86 aggressive for use in dominance calculations)

# Recreate social network graphs with association data separated by season (breeding or non-breeding)
unique(ff1aff$Date) #Dates from our raw data of banded-banded bird affiliative associations from above

# separate Sites because breeding started earlier in AZ
ff_AZ = ff1aff[which(ff1aff$Site == "AZ"),]
ff_AZ$Date = as.Date(ff_AZ$Date, format = "%Y-%m-%d")
ffAZ_bs19 = ff_AZ[which(ff_AZ$Date > "2019-03-08" & ff_AZ$Date < "2019-09-01"),] #2019 breeding season = 9 Mar to 31 Aug
ffAZ_bs19$Season = "BS"
ffAZ_bs20 = ff_AZ[which(ff_AZ$Date > "2020-03-08" & ff_AZ$Date < "2020-09-01"),] #2020 breeding season
ffAZ_bs20$Season = "BS"
ffAZ_nbs = ff_AZ[which(ff_AZ$Date < "2019-03-08" | c(ff_AZ$Date > "2019-08-31" & ff_AZ$Date < "2020-03-08")),] # nonbreeding season = 1 Sept 2019 - 8 Mar 2020
ffAZ_nbs$Season = "NBS"

ffsAZ = rbind(ffAZ_nbs,ffAZ_bs19,ffAZ_bs20)

#now repeat in CA
ff_CA = ff1aff[which(ff1aff$Site == "CA"),]
ff_CA$Date = as.Date(ff_CA$Date, format = "%Y-%m-%d")
ffCA_bs21 = ff_CA[which(ff_CA$Date > "2021-03-31" & ff_CA$Date < "2021-09-01"),] #2021 breeding season = 1 Apr to 31 Aug
ffCA_bs21$Season = "BS"
ffCA_bs22 = ff_CA[which(ff_CA$Date > "2022-03-29" & ff_CA$Date < "2022-09-01"),] #2022 breeding season = 30 Mar to 31 Aug
ffCA_bs22$Season = "BS"
ffCA_nbs = ff_CA[which(ff_CA$Date > "2021-08-31" & ff_CA$Date < "2022-03-30"),] # nonbreeding season = 1 Sept 2021 - 29 Mar 2022
ffCA_nbs$Season = "NBS"

ffsCA = rbind(ffCA_nbs,ffCA_bs21,ffCA_bs22)

#combine sites together again
ffs = rbind(ffsAZ,ffsCA)
#make new network graphs and re-calculate sna metrics by season
ffs2 = aggregate(TimeStamp ~ Date + FocalBirdID + NonFocalBirdID + Site + Season, data = ffs, FUN = "max") #only one observation of banded-banded pair per sampling period is allowed, for 111 banded-banded associations

#but only the following grackles (n = 15) had at least 2 follows per season: Burrito, Chalupa, Chilaquile, Diablo, Fideo, Taco, Taquito, Yuca, Polvorones, Dulce de Leche, Zapote Negro, Galandra, Cuervo, Kel, Cutuy
ffs3 = ffs2[which(ffs2$FocalBirdID == "Burrito" | ffs2$FocalBirdID == "Chilaquile" | ffs2$FocalBirdID == "Diablo" | 
                             ffs2$FocalBirdID == "Fideo" |  ffs2$FocalBirdID == "Taco" | ffs2$FocalBirdID == "Taquito" | 
                             ffs2$FocalBirdID == "Yuca" | ffs2$FocalBirdID == "Chalupa" | 
                             ffs2$FocalBirdID == "Polvorones" | ffs2$FocalBirdID == "Dulce de Leche" | ffs2$FocalBirdID == "Zapote Negro" | 
                             ffs2$FocalBirdID == "Cuervo" | ffs2$FocalBirdID == "Galandra" | ffs2$FocalBirdID == "Cutuy" | 
                             ffs2$FocalBirdID == "Kel"),]
#this decreases the sample size from 111 banded-banded associations to 27. And, the majority of these are in the non-breeding season (only 5 breeding season)

#Create an edgelist - a two column matrix of birds seen together
els.nb = ffs3[which(ffs3$Season == "NBS"),c(2:3)] #FocalBirdID and NonFocalBirdID in non-breeding season only (because 5 breeding season associations do not need to be symmetrized)
#since these are undirected associations, symmetrize the associations so all are in the same order and repeat pairs can be identified
colnames(els.nb)[c(1,2)]=c("ID.1","ID.2")
els.nb$ID.1 = as.character(els.nb$ID.1)
els.nb$ID.2 = as.character(els.nb$ID.2)
for (i in 1:nrow(els.nb)) {
  tmp = els.nb[i, c("ID.1", "ID.2")]
  tmp = tmp[,sort.list(tmp)] #produces warning messages, but works
  els.nb[i, "ID.1"] = tmp[,1]
  els.nb[i, "ID.2"] = tmp[,2]
}

#calculate edge weights using the half-weight index by quantifying the number of times two birds are seen together (x), the number of times bird 1 is seen without bird 2 (Y.1), and the number of times bird 2 is seen without bird 1 (Y.2)
els.nb$count = 1
x = aggregate(count ~ ID.1 + ID.2, data = els.nb, FUN = "sum") #how many times are bird 1 and bird 2 observed together in each season
colnames(x)[3]="x"
#add back in season and site variables
x$Season = "NBS"
x$Site = ifelse(x$ID.1 == "Camote" | x$ID.1 == "Cuervo" | x$ID.1 == "Cutuy" | x$ID.1 == "Galandra", "CA", "AZ")
x2 = ffs3[which(ffs3$Season == "BS"),-c(1,6)]
colnames(x2)[c(1:2)] = c("ID.1","ID.2")
x2$x = 1 #no repeated observations of the same two birds together across follows
x = rbind(x, x2) #combine with breeding season association data

tmp = ffs3[,c(2,4:5)] #FocalBirdID, Site, Season
colnames(tmp)[1] = "ID"
tmp2 = ffs3[,c(3:5)] #NonFocalBirdID, Site, Season
colnames(tmp2)[1] = "ID"
y = rbind(tmp, tmp2)
y$count = 1
y = aggregate(count ~ ID + Site + Season, data = y, FUN = "sum") #how many times each bird is seen individually each season
colnames(y)[4] = "y"

colnames(y)[1] = "ID.1" 
hwis = merge(x,y, by = c("ID.1","Site","Season"), all = T)
hwis$Y.1 = hwis$y - hwis$x #the number of times bird 1 was seen without bird 2 by season
hwis = hwis[,-6]
colnames(y)[1] = "ID.2"
hwis = merge(hwis,y, by = c("ID.2","Site","Season"), all = T)
hwis$Y.2 = hwis$y - hwis$x #the number of times bird 2 was seen without bird 1 by season
hwis = hwis[-which(is.na(hwis$x)),-7] #data frame ready for half-weight index equation
hwis$hwi = hwis$x/(0.5*(hwis$Y.1 + hwis$Y.2)+hwis$x)

library(igraph)
### Breeding season network
Y2bs = as.matrix(hwis[which(hwis$Season == "BS"),])
labels <- unique( c(Y2bs[,1], Y2bs[,4]) )
A2bs <- matrix(0, length(labels), length(labels))
rownames(A2bs) <- colnames(A2bs) <- labels
A2bs[ Y2bs[,c(1,4)] ] <- as.numeric( Y2bs[,8] )
Ya2bs = graph.adjacency(A2bs, weighted = T, mode = "max", diag = F)
### Nonbreeding season network
Y2nbs = as.matrix(hwis[which(hwis$Season == "NBS"),])
labels <- unique( c(Y2nbs[,1], Y2nbs[,4]) )
A2nbs <- matrix(0, length(labels), length(labels))
rownames(A2nbs) <- colnames(A2nbs) <- labels
A2nbs[ Y2nbs[,c(1,4)] ] <- as.numeric( Y2nbs[,8] )
Ya2nbs = graph.adjacency(A2nbs, weighted = T, mode = "max", diag = F)



### Now we can quantify social network metrics by season ###
### Calculate MaxBondStrength
bonds1 = hwis[,c(1,3,8)] #ID.2, Season, hwi
colnames(bonds1)[1] = "ID"
bonds2 = hwis[,c(3,4,8)] #ID.1, Season, hwi
colnames(bonds2)[2] = "ID"
bonds = rbind(bonds1, bonds2)
maxBond2 = aggregate(hwi ~ ID + Season, data = bonds, FUN = "max")

#include only grackles that had the minimum number of focal follows
maxBond2 = maxBond2[which(maxBond2$ID == "Burrito" | maxBond2$ID == "Chilaquile" | maxBond2$ID == "Diablo" | 
                             maxBond2$ID == "Fideo" |  maxBond2$ID == "Taco" | maxBond2$ID == "Taquito" | 
                             maxBond2$ID == "Yuca" | maxBond2$ID == "Chalupa" | 
                             maxBond2$ID == "Polvorones" | maxBond2$ID == "Dulce de Leche" | maxBond2$ID == "Zapote Negro" | 
                             maxBond2$ID == "Cuervo" | maxBond2$ID == "Galandra" | maxBond2$ID == "Cutuy" | 
                             maxBond2$ID == "Kel"),]


### Calculate IndividualStrength
strength.bs = strength(Ya2bs, V(Ya2bs))
strength.bs = data.frame(names(strength.bs),strength.bs)
colnames(strength.bs) = c("ID","strength")
strength.bs$Season = "BS"
strength.nbs = strength(Ya2nbs, V(Ya2nbs))
strength.nbs = data.frame(names(strength.nbs),strength.nbs)
colnames(strength.nbs) = c("ID","strength")
strength.nbs$Season = "NBS"
strength2 = rbind(strength.bs,strength.nbs)

#include grackles that had the minimum number of focal follows: 
strength2 = strength2[which(strength2$ID == "Burrito" | strength2$ID == "Chilaquile" | strength2$ID == "Diablo" | 
                             strength2$ID == "Fideo" |  strength2$ID == "Taco" | strength2$ID == "Taquito" | 
                             strength2$ID == "Yuca" | strength2$ID == "Chalupa" | 
                             strength2$ID == "Polvorones" | strength2$ID == "Dulce de Leche" | strength2$ID == "Zapote Negro" | 
                             strength2$ID == "Cuervo" | strength2$ID == "Galandra" | strength2$ID == "Cutuy" | 
                             strength2$ID == "Kel"),]

### Calculate Degree
degree.bs <- igraph::degree(Ya2bs,V(Ya2bs))
degree.bs = data.frame(names(degree.bs),degree.bs)
colnames(degree.bs) = c("ID","degree")
degree.bs$Season = "BS"
degree.nbs <- igraph::degree(Ya2nbs,V(Ya2nbs))
degree.nbs = data.frame(names(degree.nbs),degree.nbs)
colnames(degree.nbs) = c("ID","degree")
degree.nbs$Season = "NBS"
degree2 = rbind(degree.bs,degree.nbs)

#include grackles that had the minimum number of focal follows: 
degree2 = degree2[which(degree2$ID == "Burrito" | degree2$ID == "Chilaquile" | degree2$ID == "Diablo" | 
                             degree2$ID == "Fideo" |  degree2$ID == "Taco" | degree2$ID == "Taquito" | 
                             degree2$ID == "Yuca" | degree2$ID == "Chalupa" | 
                             degree2$ID == "Polvorones" | degree2$ID == "Dulce de Leche" | degree2$ID == "Zapote Negro" | 
                             degree2$ID == "Cuervo" | degree2$ID == "Galandra" | degree2$ID == "Cutuy" | 
                             degree2$ID == "Kel"),]

### Analyze sna metrics as a function of season
### We only have 7 data points from the breeding season with no variability in the social network metrics. Therefore, we do not think we have an adequate breeding season sample to be able to compare social network metrics across season. 
### There could be a season difference that we are unable to detect with our sample size and as preregistered, we will proceed using only the non-breeding season data.



# library(MCMCglmm)
# prior = list(R=list(R1=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0)))
# 
# # hwi = half-weight index, the social association indices that we said we would use to weight the edges in the social network analysis
# hist(log(maxBond2$hwi))
# seasonmb = MCMCglmm(log(hwi) ~ Season, random=~ID, family="gaussian", data=maxBond2, verbose=F, prior=prior, nitt=300000, thin=200, burnin=30000)
# autocorr(seasonmb$Sol) #Did fixed effects converge?
# autocorr(seasonmb$VCV) #Did random effects converge?
# summary(seasonmb) 
# boxplot(hwi~Season,data = maxBond2)
# 
# hist(log(strength2$strength))
# seasons = MCMCglmm(log(strength) ~ Season, random=~ID, family="gaussian", data=strength2, verbose=F, prior=prior, nitt=200000, thin=200, burnin=30000)
# autocorr(seasons$Sol) #Did fixed effects converge?
# autocorr(seasons$VCV) #Did random effects converge?
# summary(seasons) 
# boxplot(strength~Season,data = strength2)
# 
# prior = list(R=list(R1=list(V=1,nu=0)))
# hist(degree2$degree)
# degree2$Season <- as.factor(degree2$Season) #factor to see if it makes the fixed effects converge. It helped
# seasond = MCMCglmm(degree ~ Season, family="poisson", data=degree2, verbose=F, prior=prior, nitt=300000, thin=1000, burnin=50000)
# autocorr(seasond$Sol) #Did fixed effects converge? No so factored season, increased nitt/burnin, decreased thin and it worked
# autocorr(seasond$VCV) #Did random effects converge?
# summary(seasond) 
# boxplot(degree~Season,data = degree2)
```

Social network data are not independent (@croft2011hypothesis), therefore, to determine whether individuals are associating non-randomly based on flexibility (i.e., association strength between two grackles is larger than would be expected by random chance), we will compare our model results to those obtained from random networks. To make a random network, we will use the R package sna (@butts2016sna) and the function “rperm” to randomly rearrange the association strengths (edges) of grackles in our network. We will conduct this edge randomization (called permutation) 10,000 times to create our sample of random networks. We will then re-calculate our dependent variables from the random networks and re-run the same models (as in @croft2011hypothesis and @whitehead2005testing). We will conclude that social bonds are significantly related to flexibility if the coefficients describing the relationship in our observed data are in the top 2.5% and bottom 2.5% of the coefficients resulting from models run on the random networks.


## P5: Flexibility and immigration

The model takes the form of:

$pimmigrant_{i}$ ~ Binomial(1, $p$) *[likelihood]*,

logit($p$) ~ $\alpha_{i}$[habitat] + $\beta_{i}$$\phi$ *[model]*,

where $pimmigrant_{i}$ is the probability of being an immigrant for each individual i, $p$ is the probability of being an immigrant, $\alpha_{i}$ is the intercept (one per observation), and $\beta_{i}$ is the slope for the interaction with $\phi$. Note that the model is the same when analyzing $\lambda$, which replaces $\phi$ in the above model. We determine that $\phi$ and $\lambda$ are strongly related to the probability of being an immigrant if the compatibility interval for the slope does not cross zero.


## P6: Flexibility and habitat diversity

The model takes the form of:

$div_{i}$ ~ Normal($\mu_{i}$, $\sigma_{i}$) *[likelihood]*,

log($\mu_{i}$) ~ $\alpha$ + $\beta_{p}$$\phi$ + $\beta_{r}$$rank$ *[model]*,

where $div_{i}$ is the Shannon Diversity Index [see @vegan for mathematical definition] for each individual i, $\mu_{i}$ is the mean and $\sigma_{i}$ is the standard deviation, $\alpha$ is the intercept, $\beta_{p}$ is the slope for the interaction with $\phi$, and $\beta_{r}$ is the slope for the interaction with dominance $rank$. Note that the model is the same when analyzing $\lambda$, which replaces $\phi$ in the above model. We determine that $\phi$ and $\lambda$ are strongly related to the diversity index if the compatibility interval for the slope does not cross zero.


## P7: human population density across sites

Human population density (population per square mile) is obtained from the U.S. Census Bureau for Tempe, Arizona (https://www.census.gov/quickfacts/fact/table/tempecityarizona,US/POP060220), Woodland, California (https://www.census.gov/quickfacts/fact/table/woodlandcitycalifornia/POP060220), and Sacramento, California (https://www.census.gov/quickfacts/fact/table/sacramentocitycalifornia,tempecityarizona,US/POP060220) for 2010 and 2020 (the Census data), and from the U.S. Census American Community Survey (https://www.opendatanetwork.com/entity/1600000US0664000-1600000US0686328-1600000US0473000/Sacramento_CA-Woodland_CA-Tempe_AZ/geographic.population.density?year=2018&ref=compare-entity) for the rest of the years from 2009 to 2018 (note that there is no data for 2019). The Woodland population consists of two trapping locations: one in Woodland and the other in Sacramento. The two locations represent the same population because some of the same individuals are found at both locations. We design a bespoke Bayesian model to determine whether there are differences between populations and we conduct a simulation to determine how much of a difference between the means (at least 250 people per square mile) would result in there being a difference between the cities.

The model takes the form of:

$p_{i}$ ~ Normal($\mu_{i}$, $\sigma_{i}$) *[likelihood]*,

log($\mu_{i}$) ~ $\alpha$[city]  *[model]*,

where $p_{i}$ is the human population density (total population divided by the land area per square mile) for each observation i, $\mu_{i}$ is the mean and $\sigma_{i}$ is the standard deviation, and $\alpha$[city] is the intercept for each city.

## P8: flexibility and microhabitat types

The model takes the form of:

$follows_{i}$ ~ Binomial(1, $p$) *[likelihood]*,

logit($p$) ~ $\alpha_{i}$[habitat] + $\beta_{i}$$\phi$ *[model]*,

where $follows_{i}$ is the proportion of focal follows that were recorded in a particular microhabitat for each individual i, $p$ is the probability of being in a given microhabitat, $\alpha_{i}$ is the intercept (one per observation), and $\beta_{i}$ is the slope for the interaction with $\phi$. Note that the model is the same when analyzing $\lambda$, which replaces $\phi$ in the above model. We determine that $\phi$ and $\lambda$ are strongly related to the proportion of focal follows in a given habitat if the compatibility interval for the slope does not cross zero.


# RESULTS



## P1: FLexibility and foraging behavior 

### Analysis plan: P1-P2

**Analysis:** Because the independent variables could influence each other, we will analyze them in a single model: Generalized Linear Mixed Model (GLMM; MCMCglmm function, MCMCglmm package; [@hadfield2010mcmc]) with a Poisson distribution and log link using 130,000 iterations with a thinning interval of 10, a burnin of 30,000, and minimal priors (V=1, nu=0) [@hadfield2014coursenotes]. We will ensure the GLMM shows acceptable convergence (lag time autocorrelation values <0.01; [@hadfield2010mcmc]), and adjust parameters if necessary to meet this criterion. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

 - **Deviation from the plan:** we added the independent variable, total seconds of observation time, to account for the different amounts of observation time with regard to the number of foods eaten and foraging techniques used per individual.

```{r p1p2, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)

ff <- data.frame(ff)

#exclude NAs from the DomRank column
ff <- subset(ff, is.na(ff$DomRank) == FALSE)

#Separate the sexes
ff <- ff[ff$Sex=="F",]
mal <- ff[ff$Sex=="M",]

#Factor the random effect variables
ff$ID <- as.factor(ff$BirdID)
ff$Population <- as.factor(ff$Population)
mal$ID <- as.factor(mal$BirdID)
mal$Population <- as.factor(mal$Population)

#sample sizes
length(unique(ff$ID)) #9 ffales
length(unique(mal$ID)) #26 males

## figuring out how to treat the differences in observation time (SumFocalTime)
plot(ff$NumFoodTypes ~ ff$SumFocalTime)
plot(mal$NumFoodTypes ~ mal$SumFocalTime)
plot(ff$NumForageTechs ~ ff$SumFocalTime)
plot(mal$NumForageTechs ~ mal$SumFocalTime)

#male data are significantly correlated - need to include observation time; female data are not significantly correlated - don't need to include observation time. However, there is a larger sample size for the males so perhaps this would be a pattern found in the females too if we had data on more individuals
cor.test(ff$NumFoodTypes, ff$SumFocalTime, conf.level = 0.95, method = "pearson", alternative = "two.sided") #t = 1.6156, df = 7, p-value = 0.1502, 95 percent confidence interval:  -0.2186279  0.8805227, cor 0.5211645 
cor.test(mal$NumFoodTypes, mal$SumFocalTime, conf.level = 0.95, method = "pearson", alternative = "two.sided") #t = 3.1879, df = 24, p-value = 0.003954, 95 percent confidence interval: 0.2004097 0.7700786, cor 0.5454211 
cor.test(ff$NumForageTechs, ff$SumFocalTime, conf.level = 0.95, method = "pearson", alternative = "two.sided") #t = 0.88938, df = 7, p-value = 0.4033, 95 percent confidence interval: -0.4382205  0.8111143, cor 0.3186338 
cor.test(mal$NumForageTechs, mal$SumFocalTime, conf.level = 0.95, method = "pearson", alternative = "two.sided") #t = 2.4232, df = 24, p-value = 0.0233, 95 percent confidence interval:0.06761479 0.70895493, cor 0.3186338 


# DATA CHECKING
library(DHARMa)
library(lme4)

#Data checking for GLMM 1 ffales
simulationOutput <- simulateResiduals(fittedModel = glmer(NumFoodTypes ~ Phi + Lambda + FlexibilityManipulated + DomRank + (1|ID) + (1|Population) + (1|SumFocalTime), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation. p=0.88 so it is fine
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p=0.05. p<0.99 so not zero inflated
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. p=0.72 so it is fine. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel. Says combined adjusted quantile test significant
plotResiduals(ff$Phi, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect). Says combined adjusted quantile test significant, but not sure what it means in this context

#Data checking for GLMM 1 males
simulationOutput <- simulateResiduals(fittedModel = glmer(NumFoodTypes ~ Phi + Lambda + FlexibilityManipulated + DomRank + (1|ID) + (1|Population) + (1|SumFocalTime), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation. p=0.88 so it is fine
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05. p=0.86 so it is fine
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. p=0.76 so it is fine. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(mal$Phi, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect). Says combined adjusted quantile test significant, but not sure what it means in this context

#Data checking for GLMM 2 ffales
simulationOutput <- simulateResiduals(fittedModel = glmer(NumForageTechs ~ Phi + Lambda + FlexibilityManipulated + DomRank + (1|ID) + (1|Population) + (1|SumFocalTime), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation. p=0.336 so it is fine
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05. p=1 so it is fine
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. p=0.49 so it is fine. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(ff$Phi, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect). Says combined adjusted quantile test significant, but not sure what it means in this context

#Data checking for GLMM 2 males
simulationOutput <- simulateResiduals(fittedModel = glmer(NumForageTechs ~ Phi + Lambda + FlexibilityManipulated + DomRank + (1|ID) + (1|Population) + (1|SumFocalTime), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
plot(simulationOutput$scaledResiduals) #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation. p=0.94 so it is fine
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05. p=0.77 so it is fine
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. p=0.84 so it is fine. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(mal$Phi, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect). Says combined adjusted quantile test significant, but not sure what it means in this context


#GLMM 
library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0),R2=list(V=1,nu=0),R3=list(V=1,nu=0),R4=list(V=1,nu=0),R5=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0),G2=list(V=1,nu=0)))

#GLMM 1 with response variable = NumberFoodsEaten
#ffales
f1 <- MCMCglmm(NumFoodTypes ~ Phi + Lambda + FlexibilityManipulated + DomRank, random=~Population+ID+SumFocalTime, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
f2 <- MCMCglmm(NumFoodTypes ~ Phi + Lambda + FlexibilityManipulated + DomRank, random=~Population+ID+SumFocalTime, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?

#GLMM 2 with response variable = NumberForagingTechniques
#female
f3 <- MCMCglmm(NumForageTechs ~ Phi + Lambda + FlexibilityManipulated + DomRank, random=~Population+ID+SumFocalTime, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f3)
#autocorr(f3$Sol) #Did fixed effects converge?
#autocorr(f3$VCV) #Did random effects converge?

#male
f4 <- MCMCglmm(NumForageTechs ~ Phi + Lambda + FlexibilityManipulated + DomRank, random=~Population+ID+SumFocalTime, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f4)
#autocorr(f4$Sol) #Did fixed effects converge?
#autocorr(f4$VCV) #Did random effects converge?
```

We will quantify the number of different food types and foraging techniques during focal follows according to the [ethogram](https://docs.google.com/spreadsheets/d/1N8wsA3geaRGlMjRxYTRpdG2i5oCXNGq9zBlTnj02Gho/edit?usp=sharing). If a grackle forages during a focal follow we record WHAT it eats, as well as HOW the bird is searching for food. Foraging techniques include: Flipping over objects (flip), digging in ground with bill or feet (dig), sweeping head back and forth [i.e., actually sweeping the bill across the substrate; (sw)], extracting from a substrate (ex), lowers body posture to be parallel to ground to stalk/catch prey from air, from ground, from tree, etc (sc), using gaping bill to search through substrate (ga), lifting or nudging objects with bill (ln). 

## P1 alternative 2: flexible = more valuable food types

Prediction: If there is a negative correlation between flexibility and the number of different foods eaten, this might indicate that the more flexible individuals target particular food items. If this prediction is supported, we will conduct an additional analysis to examine what food types the more flexible grackles eat and whether these food types are potentially more valuable (measured as having more calories).

**Analysis:** We will rank all food types eaten by the grackles by their caloric value, examine the food types eaten per individual and relate this to their flexibility scores on their most recent reversal learning color tube experiment. This will allow us to see whether the more flexible individuals (faster to reverse) eat more valuable (i.e., higher calorie) food types than the less flexible individuals.

## P2: Flexibility manipulation and foraging behavior 



## P3: flexible = more human foods

**Analysis:** A GLMM was conducted as in P1-P2, except this GLMM used a binomial distribution (called "categorical" in MCMCglmm) due to the response variable being a proportion.

```{r p3, eval=FALSE}
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)

ff <- data.frame(ff)

#exclude NAs from the DomRank column
ff <- subset(ff, is.na(ff$DomRank) == FALSE)

#Separate the sexes
ff <- ff[ff$Sex=="F",]
mal <- ff[ff$Sex=="M",]

#Factor the random effect variables
ff$ID <- as.factor(ff$BirdID)
ff$Population <- as.factor(ff$Population)
mal$ID <- as.factor(mal$BirdID)
mal$Population <- as.factor(mal$Population)

#sample sizes
length(unique(ff$ID)) #9 ffales
length(unique(mal$ID)) #26 males

# DATA CHECKING
library(DHARMa)
library(lme4)

#Data checking for ffale GLMM
simulationOutput <- simulateResiduals(fittedModel = glmer(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime + (1|ID) + (1|Population), family=binomial, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(ProportionFoodsEatenHumanFood, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM
simulationOutput <- simulateResiduals(fittedModel = glmer(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime + (1|ID) + (1|Population), family=binomial, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(ProportionFoodsEatenHumanFood, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet


#GLMM
library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0),R2=list(V=1,nu=0),R3=list(V=1,nu=0),R4=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0),G2=list(V=1,nu=0)))

#GLMM with response variable = NumberFoodsEaten
#ffales
f1 <- MCMCglmm(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime, random=~Population+ID, family="categorical", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
f2 <- MCMCglmm(PropHumanFood ~ Phi + Lambda + FlexibilityManipulated + DomRank + SumFocalTime, random=~Population+ID, family="categorical", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?

#Is distance from outdoor cafes a repeatable trait within individuals, as measured with a GPS point of individual locations during several separate focal follows
d1 <- rpt(dist ~ Sex + (1 | ID), grname = "ID", data = ff, datatype = "poisson", nboot = 1000, npermut = 300)
summary(d1)
#If repeatable, take average distance across focal follows to model relationship with flexibility
tmp = aggregate(dist ~ ID, FUN = "mean", data = ff)
colnames(tmp) = c("avg_dist","ID")
ff = merge(ff, tmp, by = "ID", all = T)
d2 <- MCMCglmm(avg_dist ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="categorical", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(d2)

# Number of outdoor cafes within the home range of each individual, measured by calculating home range size and then summing the number of cafes.
distance <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_foraging.csv"), header=T, sep=",", stringsAsFactors=F)
distance <- data.frame(distance)

#Load packages
library(adehabitatHR)
library(sf)
#Point to the correct data file and load it
setwd("~/Documents/Grackle project/Space use")
pts<-read.csv("gtgr_points.csv", header = T)
#Set variables to ensure the models read the data properly
pts$Latitude = as.numeric(as.character(pts$Latitude))
pts$Longitude = as.numeric(as.character(pts$Longitude))
pts$Date = as.character(pts$Date)
pts$Time = as.character(pts$Time)
pts$da.ti = as.POSIXct(paste(pts$Date, pts$Time), format="%Y-%m-%d %H:%M:%S")
#Home range size can only be calculated when a bird has more than 5 relocations
#Count the number of relocations for each bird, then exclude individuals with less than 6
tmp = pts
tmp$count = 1
tmp = aggregate(count ~ Bird.Name, FUN = "sum", data = tmp)
pts.min = merge(pts, tmp, by = "Bird.Name", all = T)
pts.min = pts.min[-which(pts.min$count<6),]
pts.min$Bird.Name = as.factor(as.character(pts.min$Bird.Name))
#Convert dataframe to Spatial file type
p.sf <- st_as_sf(pts.min, coords = c("Longitude", "Latitude"), crs = 4326) 
class(p.sf) 
p.spatial <- as(p.sf, "Spatial")
class(p.spatial)
#Calculate home range in square meters for each individual, excluding outliers
hr = mcp(p.spatial[1], percent = 100, unout = "m2")
plot(hr)
#Read in dataframe with cafe locations
cafs<-read.csv("cafe_points.csv", header = T)
#Convert to spatial points dataframe
c <- SpatialPointsDataFrame(cafs)
#Count the number of cafes in each home range polygon
cafes <- over(c, hr)
cafe_data <- table(cafes$NAME_1)
cafe_data <- merge(cafe_data, ff, by = "ID")

c1 <- MCMCglmm(NumberCafesInTerritory ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="categorical", data=cafe_data, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(c1)
```

## P4: Flexibility and social bonds

The social network is... (say something general about Figure) (Figure).

```{r p4pt1socialnetwork, eval=T}
### Create social network graph figure from associations between banded birds ###
#Load social data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

#Exclude unbanded birds
ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 

ff1 <- subset(ff1, is.na(ff1$FocalBirdID) == FALSE) #257 banded-banded bird associations
ff1aff <- subset(ff1, ff1$BehavType == "affiliative")
ff2 = aggregate(TimeStamp ~ Date + FocalBirdID + NonFocalBirdID + Site, data = ff1aff, FUN = "max") #only one observation of banded-banded pair per sampling period is allowed, for 111 banded-banded associations

library(igraph)
library(sna)
#Create an edgelist - a two column matrix of birds seen together
el = ff2
#since these are undirected associations, symmetrize the associations so all are in the same order and repeat pairs can be identified
colnames(el)[c(2,3)]=c("ID.1","ID.2")
el$ID.1 = as.character(el$ID.1)
el$ID.2 = as.character(el$ID.2)
for (i in 1:nrow(el)) {
  tmp = el[i, c("ID.1", "ID.2")]
  tmp = tmp[,sort.list(tmp)] 
  el[i, "ID.1"] = tmp[,1]
  el[i, "ID.2"] = tmp[,2]
}

#calculate edge weights using the half-weight index by quantifying the number of times two birds are seen together (x), the number of times bird 1 is seen without bird 2 (Y.1), and the number of times bird 2 is seen without bird 1 (Y.2)
el$count = 1
x = aggregate(count ~ ID.1 + ID.2, data = el, FUN = "sum") #how many times are bird 1 and bird 2 observed together
colnames(x)[3]="x"

tmp = el[,c(2,4)]
colnames(tmp)[1] = "ID"
tmp2 = el[,c(3,4)]
colnames(tmp2)[1] = "ID"
y = rbind(tmp, tmp2)
y$count = 1
y = aggregate(count ~ ID + Site, data = y, FUN = "sum") #how many times each bird is seen individually
colnames(y)[3] = "y"

colnames(y)[1] = "ID.1" 
hwi = merge(x,y, by = "ID.1", all = T)
hwi$Y.1 = hwi$y - hwi$x #the number of times bird 1 was seen without bird 2
hwi = hwi[,-5]
colnames(y)[1] = "ID.2"
hwi = merge(hwi,y, by = c("ID.2","Site"), all = T)
hwi$Y.2 = hwi$y - hwi$x #the number of times bird 2 was seen without bird 1
hwi = hwi[-which(is.na(hwi$x)),-6] #data frame ready for half-weight index equation
hwi$hwi = hwi$x/(0.5*(hwi$Y.1 + hwi$Y.2)+hwi$x)

#convert data to adjacency graph for calculating social network metrics
Y = as.matrix(hwi)
labels <- unique( c(Y[,1], Y[,3]) ) #make sure the matrix indices labels match hwi columns for ID.1 and ID.2
A <- matrix(0, length(labels), length(labels))
rownames(A) <- colnames(A) <- labels
A[ Y[,c(1,3)] ] <- as.numeric( Y[,7] ) #make sure the matrix numeric index is matched with the hwi column for hwi.
Ya = graph.adjacency(A, weighted = T, mode = "max", diag = F)

#graphical representation of the data, including all individuals seen from both sites (ie. we did not exclude grackles who did not meet the minimum focal follow sample size for the plot)
l <- layout_with_fr(Ya)
l <- norm_coords(l, ymin=-8, ymax=8, xmin=-8, xmax=8)
E(Ya)$weight <- hwi$hwi #link hwi to graph for edge weights
V(Ya)$Site=as.character(y$Site[match(V(Ya)$name,y$ID.2)])#link Site info to graph vertices (bird IDs)
V(Ya)$color=V(Ya)$Site 
V(Ya)$color=gsub("AZ","gray",V(Ya)$color) 
V(Ya)$color=gsub("CA","lightblue",V(Ya)$color)
deg <- igraph::degree(Ya)
V(Ya)$size <- deg*2

plot(Ya, layout = l*8.0, 
     edge.width =E(Ya)$weight*10,
     vertex.color = V(Ya)$color,
     size = V(Ya)$size*10,
     vertex.label.cex=1,
     vertex.label.color = "black")
```

**Figure.** Social network of the Arizona (red) and California (blue) grackles.


```{r p4pt2socnetmetrics, eval = F}
### Now we can quantify social network metrics on individuals with the minimum number of focal follows ###
### We do not have enough breeding season data, so we are only using nonbreeding season data. Which birds meet the minimum requirement of 4 total follows?

#load attribute data
g <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
g <- data.frame(g)
g = g[,c(1:2,21:27)] #data frame with attribute data for analyses (BirdID, Sex, ShannonDI, behavioral flexibility [Phi & Lambda], DomRank, Population, NumFollows)
g1 <- g[g$NumFollows>3,] #n=24
g1 = g1[!is.na(g1$BirdID),]
#Also, we only want birds with data from the non-breeding season
g1 = g1[-which(g1$BirdID == "Marisco" | g1$BirdID == "Mofongo" | g1$BirdID == "Queso" | g1$BirdID == "Tapa" | g1$BirdID == "Tomatillo" | g1$BirdID == "Helado"),]
#Males=13: Burrito, Chilaquile, Diablo, Fideo, Taco, Taquito, Tembleque, Polvorones, Camote, Dulce de Leche, Zapote Negro, Cuervo, Xunub
#females=5: Chalupa, Yuca, Galandra, Kel, Cutuy

#load social association data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

## Data filtering
#Exclude unbanded birds
ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 

ff1 <- subset(ff1, is.na(ff1$FocalBirdID) == FALSE) #257 banded-banded bird associations
#Exlude aggressive assocations
ff1aff <- subset(ff1, ff1$BehavType == "affiliative")
colnames(ff1aff)[2] = "ID"
#Exlude birds that don't meet minimum focal follow sample size
ff2 = ff1aff[which(ff1aff$ID == "Burrito" | ff1aff$ID == "Chilaquile" | ff1aff$ID == "Chalupa" | 
                             ff1aff$ID == "Diablo" | ff1aff$ID == "Fideo" | 
                             ff1aff$ID == "Taco" | ff1aff$ID == "Taquito" |  ff1aff$ID == "Yuca" | 
                             ff1aff$ID == "Tembleque" | ff1aff$ID == "Polvorones" | ff1aff$ID == "Camote" |
                             ff1aff$ID == "Dulce de Leche" | ff1aff$ID == "Zapote Negro" | 
                             ff1aff$ID == "Cuervo" | ff1aff$ID == "Xunub" | 
                             ff1aff$ID == "Galandra" | ff1aff$ID == "Kel" | ff1aff$ID == "Cutuy"),]

### Calculate MaxBondStrength - the strength of the strongest association value (half weight index) for each individual
bonds1 = hwi[,c(1,7)] #select only ID.2/ID.1 and hwi
colnames(bonds1)[1] = "ID"
bonds2 = hwi[,c(3,7)] #select only ID.2/ID.1 and hwi
colnames(bonds2)[1] = "ID"
bonds = rbind(bonds1, bonds2)
maxBond = aggregate(hwi ~ ID, data = bonds, FUN = "max")
# only interested in data from grackles that were in the aviaries and for which we have the minimum number of focal follows (2 per season): n = 24


#maxbond #this shows the hwi per bird. ADD THIS DATA TO THE GENERAL DATA SHEET

### Calculate IndividualStrength - the sum of the association values for each individual
strength = strength(Ya, V(Ya))
strength = data.frame(names(strength),strength)
colnames(strength)[1] = "ID"
# only interested in data from grackles that were in the aviaries and for which we have the minimum number of focal follows (2 per season): n = 24
strength = strength[which(strength$ID == "Burrito" | strength$ID == "Chilaquile" | strength$ID == "Diablo" | 
                             strength$ID == "Fideo" | strength$ID == "Marisco" | strength$ID == "Mofongo" | 
                             strength$ID == "Queso" | strength$ID == "Taco" | strength$ID == "Taquito" | 
                             strength$ID == "Tembleque" | strength$ID == "Polvorones" | strength$ID == "Camote" |
                             strength$ID == "Helado" | strength$ID == "Dulce de Leche" | strength$ID == "Zapote Negro" | 
                             strength$ID == "Cuervo" | strength$ID == "Xunub" | strength$ID == "Chalupa" | 
                             strength$ID == "Tapa" | strength$ID == "Yuca" | strength$ID == "Galandra" | 
                             strength$ID == "Kel"),]

strength  #this shows the strength per bird. ADD THIS DATA TO THE GENERAL DATA SHEET

### Calculate Degree
degree <- igraph::degree(Ya,V(Ya))
degree = data.frame(names(degree),degree)
colnames(degree)[1] = "ID"
# only interested in data from grackles that were in the aviaries and for which we have the minimum number of focal follows (2 per season): n = 24
degree = degree[which(degree$ID == "Burrito" | degree$ID == "Chilaquile" | degree$ID == "Diablo" | 
                             degree$ID == "Fideo" | degree$ID == "Marisco" | degree$ID == "Mofongo" | 
                             degree$ID == "Queso" | degree$ID == "Taco" | degree$ID == "Taquito" | 
                             degree$ID == "Tembleque" | degree$ID == "Polvorones" | degree$ID == "Camote" |
                             degree$ID == "Helado" | degree$ID == "Dulce de Leche" | degree$ID == "Zapote Negro" | 
                             degree$ID == "Cuervo" | degree$ID == "Xunub" | degree$ID == "Chalupa" | 
                             degree$ID == "Tapa" | degree$ID == "Yuca" | degree$ID == "Galandra" | 
                             degree$ID == "Kel"),]

#degree #this shows the degree per bird. ADD THIS DATA TO THE GENERAL DATA SHEET


### TO DO: Add to data sheet Relatedness of strongest bonds - dyadic data? Have to wait for DNA data to be available (Sep 2023) 

```


```{r p4pt4results, eval = F}
#Load social data
ff <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_social.csv"), header=T, sep=",", stringsAsFactors=F)
ff <- data.frame(ff)

#Exclude unbanded birds
ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 

ff1 <- subset(ff1, is.na(ff1$FocalBirdID) == FALSE) #257 banded-banded bird associations

### Analyses ###
#Separate the sexes
sex = ff1[,c(2,9)]
colnames(sex)[1] = "ID"
data = merge(sna, sex, by = "ID")

ff <- ff[ff$Sex=="F",]
mal <- ff[ff$Sex=="M",]

# ### Were there enough affiliative events between two banded birds to have a sample size to analyze bond strength?
# 
# ## females
# #remove NAs and unbanded birds. Use the ff data frame to get all of the categories
# ff$NonFocalBirdID <- factor(ff$NonFocalBirdID) #first, factor non focal bird ID to see what the other categories are called
# levels(ff$NonFocalBirdID)
# 
# ff1 <- ff[!ff$FocalBirdID=="NA" & !ff$NonFocalBirdID=="NA" & !ff$NonFocalBirdID=="unbanded adult female" & !ff$NonFocalBirdID=="unbanded adult male" & !ff$NonFocalBirdID=="unbanded juvenile" & !ff$NonFocalBirdID=="unbanded juvenile female" & !ff$NonFocalBirdID=="unbanded juvenile male" & !ff$NonFocalBirdID=="unbanded unknown female" & !ff$NonFocalBirdID=="unbanded unknown male"  & !ff$NonFocalBirdID=="unknown adult female" & !ff$NonFocalBirdID=="unknown adult male" & !ff$NonFocalBirdID=="unknown adult male " & !ff$NonFocalBirdID=="unknown banded female" & !ff$NonFocalBirdID=="unknown female" & !ff$NonFocalBirdID=="unknown grackle"  & !ff$NonFocalBirdID=="unknown individual" & !ff$NonFocalBirdID=="unknown juvenile" & !ff$NonFocalBirdID=="unknown juvenile female"  & !ff$NonFocalBirdID=="unknown juvenile male" & !ff$NonFocalBirdID=="unknown male" & !ff$NonFocalBirdID=="unknown unbanded male",] 
# 
# #select only affiliative interactions
# ff1 <- ff1[ff1$BehavType=="affiliative",]
# ff1 #how many affiliative events were there in total? have a look at the data sheet to get a general sense
# length(ff1$BehavType) #how many affiliative events were there in total across all females? 167 events
# 
# #how many females had affiliative events?
# ff1$FocalBirdID <- factor(ff1$FocalBirdID)
# length(levels(ff1$FocalBirdID)) #29 females have affiliative data
# 
# ## Males
# 
# #remove NAs and unbanded birds. Use the ff data frame to get all of the categories
# ff$NonFocalBirdID <- factor(ff$NonFocalBirdID) #first, factor non focal bird ID to see what the other categories are called
# levels(ff$NonFocalBirdID)
# 
# mal1 <- mal[!mal$NonFocalBirdID=="NA" & !mal$NonFocalBirdID=="unbanded adult ffale" & !mal$NonFocalBirdID=="unbanded adult male" & !mal$NonFocalBirdID=="unbanded juvenile" & !mal$NonFocalBirdID=="unbanded juvenile ffale" & !mal$NonFocalBirdID=="unbanded juvenile male" & !mal$NonFocalBirdID=="unbanded unknown ffale" & !mal$NonFocalBirdID=="unbanded unknown male"  & !mal$NonFocalBirdID=="unknown adult ffale" & !mal$NonFocalBirdID=="unknown adult male" & !mal$NonFocalBirdID=="unknown adult male " & !mal$NonFocalBirdID=="unknown banded ffale" & !mal$NonFocalBirdID=="unknown ffale" & !mal$NonFocalBirdID=="unknown grackle"  & !mal$NonFocalBirdID=="unknown individual" & !mal$NonFocalBirdID=="unknown juvenile" & !mal$NonFocalBirdID=="unknown juvenile ffale"  & !mal$NonFocalBirdID=="unknown juvenile male" & !mal$NonFocalBirdID=="unknown male" & !mal$NonFocalBirdID=="unknown unbanded male",] 
# 
# #select only affiliative interactions
# mal <- mal1[mal1$BehavType=="affiliative",]
# mal1 #how many affiliative events were there in total? have a look at the data sheet to get a general sense
# length(mal1$BehavType) #how many affiliative events were there in total across all males? 1689 events
# 
# #how many males had affiliative events?
# mal1$FocalBirdID <- factor(mal1$FocalBirdID)
# length(levels(mal1$FocalBirdID)) #24 males have affiliative data






### OLD

#Factor the random effect variables
ID <- as.factor(ff$ID)
Population <- as.factor(ff$Site)
ID <- as.factor(mal$ID)
Population <- as.factor(mal$Site)

# DATA CHECKING
library(DHARMa)
library(lme4)


### MAX BOND STRENGTH ###
#Data checking for female GLMM 1
simulationOutput <- simulateResiduals(fittedModel = glmer(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(MaxBondStrength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 1
simulationOutput <- simulateResiduals(fittedModel = glmer(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(MaxBondStrength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet


library(MCMCglmm)
prior = list(R=list(R1=list(V=1,nu=0),R2=list(V=1,nu=0),R3=list(V=1,nu=0),R4=list(V=1,nu=0)), G=list(G1=list(V=1,nu=0),G2=list(V=1,nu=0)))

#GLMM 1 with response variable = MaxBondStrength#
#females
f1 <- MCMCglmm(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
f2 <- MCMCglmm(MaxBondStrength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?



### STRENGTH ###
#Data checking for female GLMM 2
simulationOutput <- simulateResiduals(fittedModel = glmer(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Strength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 2
simulationOutput <- simulateResiduals(fittedModel = glmer(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Strength, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#GLMM 2 with response variable = AvgBondStrength
#female
f3 <- MCMCglmm(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f3)
#autocorr(f3$Sol) #Did fixed effects converge?
#autocorr(f3$VCV) #Did random effects converge?

#male
f4 <- MCMCglmm(Strength ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f4)
#autocorr(f4$Sol) #Did fixed effects converge?
#autocorr(f4$VCV) #Did random effects converge?


### DEGREE ###
#Data checking for female GLMM 3
simulationOutput <- simulateResiduals(fittedModel = glmer(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Degree, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 3
simulationOutput <- simulateResiduals(fittedModel = glmer(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(Degree, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#GLMM 3 with response variable = Degree
#female
f5 <- MCMCglmm(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f5)
#autocorr(f5$Sol) #Did fixed effects converge?
#autocorr(f5$VCV) #Did random effects converge?

#male
f6 <- MCMCglmm(Degree ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f6)
#autocorr(f6$Sol) #Did fixed effects converge?
#autocorr(f6$VCV) #Did random effects converge?



### MALE TERRITORY OVERLAP ###
#Data checking for male GLMM 4
simulationOutput <- simulateResiduals(fittedModel = glmer(MaleSharesTerritory ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(MaleSharesTerritory, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#GLMM 4 with response variable = MaleSharesTerritory
#male
f8 <- MCMCglmm(MaleSharesTerritory ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f8)
#autocorr(f8$Sol) #Did fixed effects converge?
#autocorr(f8$VCV) #Did random effects converge?



### RELATEDNESS FOR MAX BOND ### TO DO
#Data checking for female GLMM 5
simulationOutput <- simulateResiduals(fittedModel = glmer(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=ff), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(RelatednessForMaxBond, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet

#Data checking for male GLMM 5
simulationOutput <- simulateResiduals(fittedModel = glmer(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition + (1|ID) + (1|Population), family=poisson, data=mal), n=250) #250 simulations, but if want higher precision change n>1000
simulationOutput$scaledResiduals #Expect a flat distribution of the overall residuals, and uniformity in y direction if plotted against any predictor
testDispersion(simulationOutput) #if under- or over-dispersed, then p-value<0.05, but then check the dispersion parameter and try to determine what in the model could be the cause and address it there, also check for zero inflation
testZeroInflation(simulationOutput) #compare expected vs observed zeros, not zero-inflated if p<0.05
testUniformity(simulationOutput) #check for heteroscedasticity ("a systematic dependency of the dispersion / variance on another variable in the model" Hartig, https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html), which is indicated if dots aren't on the red line and p<0.05. Also...
plot(simulationOutput) #...there should be no pattern in the data points in the right panel
plotResiduals(RelatednessForMaxBond, simulationOutput$scaledResiduals) #plot the residuals against other predictors (in cases when there is more than 1 fixed effect) - can't get this code to work yet


#GLMM 5 with response variable = RelatednessForMaxBond
#female
f9 <- MCMCglmm(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=ff, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f9)
#autocorr(f9$Sol) #Did fixed effects converge?
#autocorr(f9$VCV) #Did random effects converge?

#male
f10 <- MCMCglmm(RelatednessForMaxBond ~ TrialsToReverseLast + ExperimentalGroup + DominanceRank + Condition, random=~Population+ID, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f4)
#autocorr(f10$Sol) #Did fixed effects converge?
#autocorr(f10$VCV) #Did random effects converge?
```


```{r p4results, eval=F}
### RUN THE MODELS
library(rethinking)

### MAX BOND - strength of the strongest bond (calculated as the half-weight index based on association behavior during focal follows)


### STRENGTH - the sum of all bonds an individual has


### DEGREE - maximum number of other individuals that the focal subject associated with


### PERCENT TERRITORY SHARED WITH ANOTHER MALE
te <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
te <- data.frame(te)

# remove NAs
te <- subset(te,!(is.na(te["PercentTerritoryShared"])))
te <- subset(te,!(is.na(te["Phi"])))
te <- subset(te,!(is.na(te["Lambda"])))
te <- subset(te,!(is.na(te["DomRank"])))

#Summary
te$BirdID <- as.factor(te$BirdID)
#length(levels(te$BirdID)) #26 males
#range(te$NumFollows) #1-8 focals per male
#mean(te$NumFollows) #avg 4.6 focals for males

# SIMULATE
n = 100
p = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
d = rnorm(n,mean=0,sd=0.3) #rank can range from -1 to 1, but standardize it
terr = rnorm(n,mean=(-1*p + -1*d),sd=0.5) #territory is a proportion. Now change the slope (b) - tried 0, 1, and -1
#plot(p,terr)
#plot(d,terr)
#plots look good - any relationship is possible, but all values are within the feasible range

# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# PHI
dat <- list(ter = te$PercentTerritoryShared, #range=0-1.54 so standardizing centers on 0
            phi = standardize(te$Phi),
            lambda = standardize(te$Lambda),
            rank = standardize(te$DomRank)
              )

# Run the model: normal distribution bc the index is a variable that has already been modified to account for presence in habitats, therefore it is more similar to a sum (McElreath 2nd edition, Fig 10.6)
tephi <- ulam(
    alist(
        ter ~ dnorm(mu,sigma),
        log(mu) <- a + bp*phi + br*rank ,
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bp ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputp <- precis( tephi , depth=2 ) #look at the bp mean and whether the interval crosses zero to determine whether phi is strongly related to the percent shared territory (does not cross 0) or not (does cross 0)
#        mean   sd  5.5% 94.5% n_eff Rhat4
#a      4.24 0.06  4.14  4.33  2096     1
#bp     0.05 0.06 -0.04  0.14  1490     1
#br    -0.01 0.06 -0.10  0.08  1978     1
#sigma 19.90 2.00 16.90 23.23  1868     1
# bp interval crosses zero so not much relationship between phi and the percent shared territory


# LAMBDA
telam <- ulam(
    alist(
        ter ~ dnorm(mu,sigma),
        log(mu) <- a + bl*lambda + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputl <- precis( telam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#a      4.24 0.06  4.14  4.33  1875     1
#bl    -0.02 0.06 -0.12  0.07  1960     1
#br    -0.02 0.06 -0.11  0.08  1639     1
#sigma 20.11 1.96 17.24 23.39  2256     1
# bl interval crosses zero so not much relationship between phi and the percent shared territory
```

```{r p4figterritory, eval=T}
library(rethinking)
te <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
te <- data.frame(te)

# remove NAs
te <- subset(te,!(is.na(te["PercentTerritoryShared"])))
te <- subset(te,!(is.na(te["Phi"])))
te <- subset(te,!(is.na(te["Lambda"])))
te <- subset(te,!(is.na(te["DomRank"])))

# set up the data sheet
dat <- list(ter = te$PercentTerritoryShared, #range=0-1.54 so standardizing centers on 0
            phi = standardize(te$Phi),
            lambda = standardize(te$Lambda),
            rank = standardize(te$DomRank)
              )

# the figure
op <- par(mfrow=c(2,1), mar=c(5.9,4.9,2,0.9))
plot(dat$ter ~ dat$phi , pch=1 , col="black" , xlab="Phi (std)" , ylab="Percent territory shared" , xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
plot(dat$ter ~ dat$lambda , pch=1 , col="black" , xlab="Lambda (std)" , ylab="Percent territory shared", xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
par(op)
```

**Figure.** Scatterplots showing the lack of relationship between the Shannon Diversity Index with $\phi$ and $\lambda$ for both sexes.


## P5: Flexibility and immigration

**Analysis:** Because the independent variables could influence each other, we will analyze them in a single model: Generalized Linear Mixed Model (GLMM; MCMCglmm function, MCMCglmm package; [@hadfield2010mcmc]) with a Poisson distribution and log link using 130,000 iterations with a thinning interval of 10, a burnin of 30,000, and minimal priors (V=1, nu=0) [@hadfield2014coursenotes]. We will ensure the GLMM shows acceptable convergence (lag time autocorrelation values <0.01; [@hadfield2010mcmc]), and adjust parameters if necessary to meet this criterion. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

```{r p5, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(rethinking)
p5 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
p% <- data.frame(p5)

# remove NAs
p5 <- subset(p5,!(is.na(p5["ProbImmigrant"])))
p5 <- subset(p5,!(is.na(p5["Phi"])))
p5 <- subset(p5,!(is.na(p5["Lambda"])))

#Separate the sexes
f5 <- p5[p5$Sex=="F",]
m5 <- p5[p5$Sex=="M",]

#Summary
f5$BirdID <- as.factor(f5$BirdID)
#length(levels(f8$BirdID)) # females
m5$BirdID <- as.factor(m5$BirdID)
#length(levels(m8$BirdID)) # males

# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# MALES, phi. Set up data sheet for model
datm5 <- list(follows = m5$Probimmigrant, 
            phi = standardize(m5$Phi),
            lambda = standardize(m5$Lambda)
              )

# Run the model
m5phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*phi , #microhabitat=random variable
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=datm5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm5p <- precis( m5phi , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 

m5lambda <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*lambda , 
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=datm5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm5l <- precis( m5lambda , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 


# FEMALES, phi. Set up data sheet for model
datf5 <- list(follows = f5$Probimmigrant, 
            phi = standardize(f5$Phi),
            lambda = standardize(f5$Lambda)
              )

f5phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*phi , #microhabitat=random variable
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=dat5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm5p <- precis( f5phi , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 

f5lambda <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a + b*lambda , 
        a ~ dnorm(0,1) #mean=0 bc response variable is standardized
    ) , data=dat5 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputf5l <- precis( f5lambda , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to 


#GLMM 
#females
f1 <- MCMCglmm(ImmigrantProbability ~ Phi + Lambda, random=~Population, family="poisson", data=fem, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f1)
#autocorr(f1$Sol) #Did fixed effects converge?
#autocorr(f1$VCV) #Did random effects converge?

#males
f2 <- MCMCglmm(ImmigrantProbability ~ Phi + Lambda, random=~Population, family="poisson", data=mal, verbose=F, prior=prior, nitt=130000, thin=10, burnin=30000)
summary(f2)
#autocorr(f2$Sol) #Did fixed effects converge?
#autocorr(f2$VCV) #Did random effects converge?
```


## P6: flexible = wider range of habitats

The Shannon Diversity Index does not have a strong relationship with either flexibility component, phi or lambda, for either sex as indicated by the low means and the compatibility interval crossing zero (Table X). As such, prediction 6 (the more flexible individuals have a higher diversity index) and prediction 6 alternative (the more flexible individuals have a low diversity index indicating that they are specialists) are not supported.

**Table.** Model output showing that phi and lambda did not have a strong relationship with the Shannon Diversity Index for either sex as indicated by the slopes. n_eff is the effective sample size and Rhat4 is an indicator of model convergence (1.00 is ideal).

```{r resltsp6table, eval=T}
library(kableExtra)
t6 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_tablep6.csv"), header=F, sep=",", stringsAsFactors=F)
t6 <- data.frame(t6)
colnames(t6) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)","n_eff","Rhat4")

knitr::kable(t6) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 11)
```

```{r p6, eval=F}
### Calculate the Shannon diversity index (SDI) per bird
sdi <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_proportionmicrohabitats.csv"), header=T, sep=",", stringsAsFactors=F)
sdi <- data.frame(sdi)
library(vegan)

#factor ID and make a data frame for each individual so each can get their own SDI
sdi$BirdID <- factor(sdi$BirdID)
#levels(unique(sdi$BirdID))
ado <- sdi[sdi$BirdID=="Adobo",]
#diversity(ado$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
akx <- sdi[sdi$BirdID=="Ak'xi",]
#diversity(akx$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
bun <- sdi[sdi$BirdID=="Buñuelo",]
#diversity(bun$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
bur <- sdi[sdi$BirdID=="Burrito",]
#diversity(bur$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.748781
cam <- sdi[sdi$BirdID=="Camote",]
#diversity(cam$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.386294
cha <- sdi[sdi$BirdID=="Chalupa",]
#diversity(cha$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.332179
chi <- sdi[sdi$BirdID=="Chilaquile",]
#diversity(chi$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6341786
cue <- sdi[sdi$BirdID=="Cuervo",]
#diversity(cue$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.013665
cut <- sdi[sdi$BirdID=="Cutuy",]
#diversity(cut$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.4558862
dia <- sdi[sdi$BirdID=="Diablo",]
#diversity(dia$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.9502705
ddl <- sdi[sdi$BirdID=="Dulce de Leche",]
#diversity(ddl$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #= 1.085262
fid <- sdi[sdi$BirdID=="Fideo",]
#diversity(fid$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.260804
fla <- sdi[sdi$BirdID=="Flan",]
#diversity(fla$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
gal <- sdi[sdi$BirdID=="Galandra",]
#diversity(gal$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.872114
hab <- sdi[sdi$BirdID=="Habanero",]
#diversity(hab$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
hel <- sdi[sdi$BirdID=="Helado",]
#diversity(hel$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6931472
kau <- sdi[sdi$BirdID=="Kau",]
#diversity(kau$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
kel <- sdi[sdi$BirdID=="Kel",]
#diversity(kel$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
mar <- sdi[sdi$BirdID=="Marisco",]
#diversity(mar$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
mof <- sdi[sdi$BirdID=="Mofongo",]
#diversity(mof$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.386294
mol <- sdi[sdi$BirdID=="Mole",]
#diversity(mol$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6931472
pin <- sdi[sdi$BirdID=="Piña",]
#diversity(pin$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.098612
piz <- sdi[sdi$BirdID=="Pizza",]
#diversity(piz$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #= 0.6341786
pol <- sdi[sdi$BirdID=="Pollito",]
#diversity(pol$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
pov <- sdi[sdi$BirdID=="Polvorones",]
#diversity(pov$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.334183
que <- sdi[sdi$BirdID=="Queso",]
#diversity(que$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6730117
tac <- sdi[sdi$BirdID=="Taco",]
#diversity(tac$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.748781
tap <- sdi[sdi$BirdID=="Tapa",]
#diversity(tap$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
taq <- sdi[sdi$BirdID=="Taquito",]
#diversity(taq$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
tem <- sdi[sdi$BirdID=="Tembleque",]
#diversity(tem$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.332179
tom <- sdi[sdi$BirdID=="Tomatillo",]
#diversity(tom$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.039721
tza <- sdi[sdi$BirdID=="Tzanatl preciosa",]
#diversity(tza$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.6931472
xun <- sdi[sdi$BirdID=="Xunub",]
#diversity(xun$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0.5623351
yuc <- sdi[sdi$BirdID=="Yuca",]
#diversity(yuc$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=0
zan <- sdi[sdi$BirdID=="Zapote Negro",]
#diversity(zan$ProportionFollows, index = "shannon", equalize.groups = FALSE, MARGIN = 1, base = exp(1)) #=1.322879
#entered this data into the main data sheet used below

### RUN THE MODELS
library(rethinking)
p8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
p8 <- data.frame(p8)

# remove NAs
p8 <- subset(p8,!(is.na(p8["ShannonDiversityIndex"])))
p8 <- subset(p8,!(is.na(p8["Phi"])))
p8 <- subset(p8,!(is.na(p8["Lambda"])))
p8 <- subset(p8,!(is.na(p8["DomRank"])))

#Separate the sexes
f8 <- p8[p8$Sex=="F",]
m8 <- p8[p8$Sex=="M",]

#Summary
f8$BirdID <- as.factor(f8$BirdID)
#length(levels(f8$BirdID)) #9 females
#range(f8$NumFollows) #1-6 focals per female
#mean(f8$NumFollows) #avg 4.2 focals for males
m8$BirdID <- as.factor(m8$BirdID)
#length(levels(m8$BirdID)) #26 males
#range(m8$NumFollows) #1-8 focals per male
#mean(m8$NumFollows) #avg 4.6 focals for males

# SIMULATE
n = 100
p = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
d = rnorm(n,mean=0,sd=0.2) #rank can range from 0 to 1, but standardize it
sdi = rnorm(n,mean=(-1*p + 1*d),sd=0.5) #shannon diversity index, standardize it. Now change the slope (b) - tried 0, 1, and -1
#plot(p,sdi)
#plot(d,sdi)
#plots look good - any relationship is possible, but all values are within the feasible range

#Just to check: unstandardize for plotting to interpret: standardized value * sd of original data + mean of original data
pu = sd(m8$Phi)*p+mean(m8$Phi)
sdiu = sd(m8$ShannonDiversityIndex)*sdi+mean(m8$ShannonDiversityIndex)
#plot(pu,sdiu)


# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# MALES, phi. Set up data sheet for model
dat <- list(div = standardize(m8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(m8$Phi),
            lambda = standardize(m8$Lambda),
            rank = standardize(m8$DomRank)
              )

# Run the model: normal distribution bc the index is a variable that has already been modified to account for presence in habitats, therefore it is more similar to a sum (McElreath 2nd edition, Fig 10.6)
m8phi <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bp*phi + br*rank ,
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bp ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm8p <- precis( m8phi , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether phi is strongly related to the diversity index (does not cross 0) or not (does cross 0). Look at the direction of the relationship to determine whether higher phi (more flexible bc associated with reversing in fewer trials, see Lukas et al. 2023 figs 2 & 3) have lower SDIs, which would indicate that they are specializing in particular microhabitats
#        mean   sd  5.5% 94.5% n_eff Rhat4
#a     -1.87 0.57 -2.82 -1.03  1225  1.00
#bp     0.05 0.55 -0.81  0.92  1127  1.00
#br     0.27 0.51 -0.46  1.11   932  1.01
#sigma  1.04 0.15  0.82  1.30  1474  1.00
# The result here and for all of the below models is the same: bp interval crosses zero and the slope is negative (-0.02 to -0.33) so not much relationship between phi and the shannon diversity index, indicating that the more flexible individuals do not specialize or generalize in microhabitat types, but are somewhere in the middle. This means that P6 and P6 alt are not supported and do not need to be analyzed. Do need to analyze P8 though because can't tell from this analysis whether different birds preferred different habitats. We can only see how they split their time among the habitats, not what the habitats are.


# MALES, lambda
m8lam <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bl*lambda + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputm8l <- precis( m8lam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#a     -1.86 0.58 -2.89 -1.00  1081     1
#bl    -0.02 0.47 -0.83  0.66  1071     1
#br     0.31 0.54 -0.48  1.23  1114     1
#sigma  1.05 0.15  0.83  1.32  1467     1


# FEMALES, phi
daf <- list(div = standardize(f8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(f8$Phi),
            lambda = standardize(f8$Lambda),
            rank = standardize(f8$DomRank)
              )

f8phi <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bp*phi + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bp ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=daf , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputfp <- precis( f8phi , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#a     -1.50 0.62 -2.54 -0.61   904     1
#bp    -0.14 0.58 -1.17  0.65   905     1
#br     0.44 0.70 -0.66  1.57  1005     1
#sigma  1.08 0.29  0.71  1.59  1180     1

f8lam <- ulam(
    alist(
        div ~ dnorm(mu,sigma),
        log(mu) <- a + bl*lambda + br*rank , #bird=random variable
        a ~ dnorm(0,1), #mean=0 bc response variable is standardized
        bl ~ dnorm(0,1),
        br ~ dnorm(0,1),
        sigma~dexp(1)
    ) , data=daf , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputfl <- precis( f8lam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#a     -1.50 0.60 -2.53 -0.60   975     1
#bl    -0.33 0.59 -1.30  0.59   943     1
#br     0.39 0.65 -0.56  1.47   805     1
#sigma  1.05 0.29  0.69  1.58  1153     1
```

```{r p6fig, eval=T}
library(rethinking)
p8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_general.csv"), header=T, sep=",", stringsAsFactors=F)
p8 <- data.frame(p8)

# remove NAs
p8 <- subset(p8,!(is.na(p8["ShannonDiversityIndex"])))
p8 <- subset(p8,!(is.na(p8["Phi"])))
p8 <- subset(p8,!(is.na(p8["Lambda"])))
p8 <- subset(p8,!(is.na(p8["DomRank"])))

#Separate the sexes
f8 <- p8[p8$Sex=="F",]
m8 <- p8[p8$Sex=="M",]

#set up the data sheets
dat <- list(div = standardize(m8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(m8$Phi),
            lambda = standardize(m8$Lambda),
            rank = standardize(m8$DomRank)
              )
daf <- list(div = standardize(f8$ShannonDiversityIndex), #range=0-1.54 so standardizing centers on 0
            phi = standardize(f8$Phi),
            lambda = standardize(f8$Lambda),
            rank = standardize(f8$DomRank)
              )

# the figure
op <- par(mfrow=c(2,2), mar=c(5.9,4.9,2,0.9))
plot(daf$div ~ daf$phi , pch=1 , col="black" , xlab="Female: Phi (std)" , ylab="Shannon Diversity Index (std)" , xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
plot(daf$div ~ daf$lambda , pch=1 , col="black" , xlab="Female: Lambda (std)" , ylab="", xlim=c(-2,2), cex.lab=2, cex.axis=2, cex=2 )
plot(dat$div ~ dat$phi , pch=1 , col="black" , xlab="Male: Phi (std)" , ylab="Shannon Diversity Index (std)", xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
plot(dat$div ~ dat$lambda , pch=1 , col="black" , xlab="Male: Lambda (std)" , ylab="", xlim=c(-2.5,2.5), cex.lab=2, cex.axis=2, cex=2 )
par(op)
```

**Figure.** Scatterplots showing the lack of relationship between the Shannon Diversity Index with $\phi$ and $\lambda$ for both sexes.

This species is primarily found within urbanized environments, however there are many different substrates within urban habitats that could provide a variety of food items. Since we are interested in the flexibility of grackle foraging behaviors within the urban habitat, we have focused our habitat diversity measures on the different substrates on which we are mostly likely to see individual variability in foraging behaviors and food types, if present.  For example, cement, cafe, and dumpster substrates are all likely to contain human-provided food (either because people leave food out for wild animals or wild animals are able to scrounge human foods), whereas grass, gravel, or other natural substrates such as trees likely contain non-human provided prey items including insects and small vertebrates. Using the Shannon diversity index to understand the evenness of substrate use within urban habitats has been recommended by others in the field of urban ecology [@alberti2001quantifying; @tews2004animal].

## P7: no difference in human population density across sites

Human population density (population per square mile) is higher in Sacramento, California (mean=4,895, standard deviation=185), which is higher than Tempe, Arizona (mean=4,283, standard deviation=187), which is higher than Woodland, California (mean=3,710, standard deviation=140) (contrast: mean=572.84 sd=32.21 89% compatibility interval=520.78-622.69).

**Table.** Contrasts showing that the human population density at each trap site is different from the others.

```{r resltsp7table, eval=T}
library(kableExtra)
exptable <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_tablep7.csv"), header=F, sep=",", stringsAsFactors=F)
exptable <- data.frame(exptable)
colnames(exptable) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)")

knitr::kable(exptable) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 11)
```

```{r p7, eval=FALSE}
library(rethinking)

# Human population density 2009-2020 (but no data for 2019 so n=10 data points per city) from the Open Data Network, which used data from the U.S. Census American Community Survey ("Population Density is computed by dividing the total population by Land Area Per Square Mile"), except for the data points from 2010 and 2020, which were from the census.
pd <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_datap7.csv"), header=T, sep=",", stringsAsFactors=F)
pd <- data.frame(pd)

# look at the data: each city's pop is generally increasing every year
f <- plot(pd$HumanPopDensity~pd$Year)

# SIMULATE data to figure out the model boundaries
n=10 #sample size
offset=250 #expect no difference between the cities when offset=0 (bc they have the same means)
city1_mean=5000 #avg pop density of city 1
city2_mean=city1_mean+offset #avg pop density of city 2
act1=rnorm(n/2, mean=city1_mean, sd=100) #alpha simulation for city 1
act2=rnorm(n/2, mean=city2_mean, sd=100) #alpha simulation for city 2

#boxplot(c(act1,act2)~c(rep("City1",n/2),rep("City2",n/2))) #look at the sim
plotsim <- plot(c(act1,act2)~c(rep(1,n/2),rep(2,n/2))) #look at the sim
for (j in 1:(n/2) ) {
  lines(x=c(1,2),y=c(act1[j],act2[j]),lwd=2,col=2)
}

# will run a contrast on the actual data to determine whether the cities differ, so run simulated contrasts and look at the histogram to see if any values cross zero. Centered on the offset and the spread reflects the SD. Ran the contrasts with varying offsets and found the values stop crossing zero when the difference between the city means is at least 250 (at n=50 and n=10, SD always=100).
contrast <- act2-act1
hist(contrast)

# USING ACTUAL DATA: Set up the data sheet for the model
dat <- list(
  city = as.factor(pd$City),
  p = as.numeric(pd$HumanPopDensity)
)

# Run the model: normal distribution bc pop density is a sum with a large mean (McElreath 2nd edition, Fig 10.6)
pop <- ulam(
    alist(
        p ~ dnorm(mu,sigma),
        log(mu) <- a[city],
        a[city] ~ dnorm(8,2), #mean of 8 because the actual mean across the cities is around 3000 so log(3000)=8. Set the sd of expected values at 2 because pop densities could range from 100 (log=5) to 10,000 (log=9)
        sigma~dexp(1)
    ) , data=dat , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

output <- precis( pop , depth=2 ) #level 1=Sacramento, 2=Tempe, 3=Woodland
#        mean   sd  5.5% 94.5% n_eff Rhat4
#a[1]     8.50 0.01  8.49  8.50  3111     1
#a[2]     8.36 0.01  8.35  8.37  2850     1
#a[3]     8.22 0.01  8.21  8.23  3295     1
#a_bar    0.99 1.05 -0.64  2.67  1581     1
#sigma_a  5.11 1.37  3.33  7.47  1775     1
#sigma   87.91 5.11 80.00 96.21  1882     1

# run a CONTRAST to determine whether there is a difference between cities
post <- extract.samples(pop)
diff_a <- post$a[,1] - post$a[,2]
diff_p12 <- exp(post$a[,1]) - exp(post$a[,2]) #convert the log link to the probability scale p.341
diff_p13 <- exp(post$a[,1]) - exp(post$a[,3]) #convert the log link to the probability scale p.341
diff_p32 <- exp(post$a[,2]) - exp(post$a[,3]) #convert the log link to the probability scale p.341
precis( list( diff_p12=diff_p12 , diff_p13=diff_p13 , diff_p32=diff_p32 ) )
#        mean   sd  5.5% 94.5%     histogram
#diff_p12  612.15 36.01  556.47  670.68  ▁▁▁▂▃▇▇▇▅▂▁▁▁
#diff_p13 1184.74 36.10 1129.14 1241.31 ▁▁▁▁▂▃▇▇▅▃▁▁▁▁
#diff_p32  572.59 36.15  515.65  630.09  ▁▁▁▂▃▇▇▇▅▂▁▁▁
#there is a difference between all cities because diff interval crosses zero and there is a difference larger than 250 between the means

# summary
#mean(pd[pd$City=="Tempe",]$HumanPopDensity) #4282.755
#mean(pd[pd$City=="Woodland",]$HumanPopDensity) #3710.073
#mean(pd[pd$City=="Sacramento",]$HumanPopDensity) #4895.055
#sd(pd[pd$City=="Tempe",]$HumanPopDensity) #187.4377
#sd(pd[pd$City=="Woodland",]$HumanPopDensity) #140.2587
#sd(pd[pd$City=="Sacramento",]$HumanPopDensity) #185.2717

### land cover classifications (https://www.usgs.gov/media/images/land-cover-conterminous-us-shown-16-thematic-classes)
## Tempe and Sacramento = Developed, medium intensity
## Woodland = Cultivated crops
```

## P8: flexible = particular habitats

**Analysis:** We examine the proportion of focal follows associated with each microhabitat per individual and relate this to their flexibility scores on their most recent reversal in the tube experiment. This allows us to see whether the more flexible individuals (faster to reverse) are associated with particular microhabitats more than the less flexible individuals.

There is not a strong relationship between phi or lambda and the proportion of focal follows in a given micro habitat type: the compatibility intervals for the slopes cross zero in all microhabitat types (Table, Figure).

**Table.** Model output showing that phi and lambda did not have a strong relationship with the proportion of focal follows in a given microhabitat type for either sex as indicated by the slopes. n_eff is the effective sample size and Rhat4 is an indicator of model convergence (1.00 is ideal).

```{r resltsp8table, eval=T}
library(kableExtra)
t8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_tablep8.csv"), header=F, sep=",", stringsAsFactors=F)
t8 <- data.frame(t8)
colnames(t8) <- c("","Mean","Standard deviation","Lower 89 percentile compatibility interval (5.5%)","Upper 89 percentile compatibility interval (94.5%)","n_eff","Rhat4")

knitr::kable(t8) %>%
kable_styling(full_width = T, position = "left",  bootstrap_options = "condensed", font_size = 11)
```


```{r p8, eval=F}
library(rethinking)
d8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_proportionmicrohabitats.csv"), header=T, sep=",", stringsAsFactors=F)
d8 <- data.frame(d8)

# remove NAs
d8 <- subset(d8,!(is.na(d8["ProportionFollows"])))
d8 <- subset(d8,!(is.na(d8["Phi"])))
d8 <- subset(d8,!(is.na(d8["Lambda"])))
d8 <- subset(d8,!(is.na(d8["Microhabitat"])))

#Separate the sexes
ff8 <- d8[d8$Sex=="F",]
mm8 <- d8[d8$Sex=="M",]

#Summary
ff8$BirdID <- as.factor(ff8$BirdID)
#length(levels(ff8$BirdID)) #9 females
mm8$BirdID <- as.factor(mm8$BirdID)
#length(levels(mm8$BirdID)) #26 males

# SIMULATE
n = 99 #99 rows / 9 microhabitat types = 11 individuals
ph = rnorm(n,mean=0,sd=1) #phi can range from 0 to 1, but standardize it by making mean=0 and SD=1. FYI avg phi for AZ grackles is about 0.06 and only goes up to 0.12 so this is a small number, hence the small sd to keep it in this low range. 
ha = rep(c(1:9),11) #go through all individuals 1 time (microhabitat is a categorical variable) 
slopes0 = rep(c(0,0,0,0,0,0,0,0,0),11) #repeat 0 nine times (one time per habitat) for 11 inds. Use zeros for no relationship. 
slopes1 = rep(c(-1,-1,-1,0,0,0,1,1,1),11) #use a mixture of slopes to simulate what happens at different values
pf = rnorm(n,mean=(0*ha + slopes1*ph),sd=0.5) #proportion follows
#plot(ha,pf,cex=ph*2) #Multiply by 2 so the tiny dots show up better
#plots look good - any relationship is possible, but all values are within the feasible range

# RUN THE MODEL on the actual data (similar to J.Q4 in ManyIndividuals: line 1024)
# MALES, phi. Set up data sheet for model
dat8 <- list(follows = mm8$ProportionFollows, 
            phi = standardize(mm8$Phi),
            lambda = standardize(mm8$Lambda),
            hab = as.factor(mm8$Microhabitat)
              )

# Run the model
d8phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*phi , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=dat8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputd8p <- precis( d8phi , depth=2 ) #look at the b values (the slopes) and whether the interval crosses zero to determine whether phi is strongly related to the proportion of follows (does not cross 0) or not (does cross 0). b1=building, b2=dumpster, b3=grass, b4=human surface, b5=misc human, b6=natural ground, b7=rock, b8=shrub, b9=tree
#        mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.02 0.58 -0.96  0.90  2345     1
#b[2]  0.23 0.54 -0.62  1.10  3214     1
#b[3] -0.02 0.61 -1.00  0.93  2660     1
#b[4] -0.27 0.55 -1.16  0.57  2854     1
#b[5] -0.01 0.59 -0.97  0.92  2987     1
#b[6] -0.02 0.57 -0.92  0.89  2601     1
#b[7] -0.03 0.57 -0.94  0.90  2815     1
#b[8] -0.02 0.58 -0.96  0.88  2693     1
#b[9] -0.33 0.47 -1.07  0.42  2810     1
# The result here and for all of the below models is the same: the b intervals cross zero in all microhabitat types and the slope is negative, so not much relationship between phi and the proportion of follows, indicating that the more flexible individuals do not specialize in a particular microhabitat type

# MALES, lambda
d8lam <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*lambda , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=dat8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputd8l <- precis( d8lam , depth=2 )
#       mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.08 0.59 -1.04  0.84  2610     1
#b[2] -0.26 0.56 -1.18  0.59  2123     1
#b[3] -0.08 0.58 -1.09  0.80  2531     1
#b[4] -0.11 0.56 -1.01  0.75  3014     1
#b[5] -0.07 0.58 -1.03  0.81  1705     1
#b[6] -0.08 0.58 -1.10  0.81  2744     1
#b[7] -0.07 0.57 -0.99  0.83  3115     1
#b[8] -0.09 0.59 -1.06  0.77  2644     1
#b[9]  0.42 0.45 -0.28  1.12  2415     1
#look at b9 Tree because it has a large mean relative to the others
#plot(mm8[mm8$Microhabitat=="Tree",]$ProportionFollows ~ mm8[mm8$Microhabitat=="Tree",]$Lambda)
#this relationship is pretty randomly scattered, with the zero proportions having lower lambdas

# FEMALES, phi
daf8 <- list(follows = ff8$ProportionFollows, 
            phi = standardize(ff8$Phi),
            lambda = standardize(ff8$Lambda),
            hab = as.factor(ff8$Microhabitat)
              )

df8phi <- ulam( alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*phi , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=daf8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputdfp <- precis( df8phi , depth=2 ) 
#      mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.12 0.73 -1.32  0.98  3283     1
#b[2] -0.11 0.72 -1.29  0.99  2439     1
#b[3] -0.13 0.71 -1.28  0.94  2915     1
#b[4] -0.11 0.70 -1.28  0.99  3604     1
#b[5] -0.26 0.71 -1.45  0.82  3307     1
#b[6] -0.11 0.67 -1.21  0.94  2994     1
#b[7] -0.09 0.71 -1.34  0.98  2787     1
#b[8] -0.11 0.71 -1.28  0.98  3012     1
#b[9] -0.29 0.72 -1.50  0.78  3101     1

df8lam <- ulam(alist(
        follows ~ dbinom(1,p),
        logit(p) <- a[hab] + b[hab]*lambda , #microhabitat=random variable
        a[hab] ~ dnorm(0,1), #mean=0 bc response variable is standardized
        b[hab] ~ dnorm(0,1)  #mean=0 bc response variable is standardized
    ) , data=daf8 , chains=4 , cores=4 , cmdstan = TRUE, control = list(adapt_delta = .95, force_recompile = TRUE))

outputdfl <- precis( df8lam , depth=2 ) #look at the bp effect size and whether the interval crosses zero to determine whether 
#       mean   sd  5.5% 94.5% n_eff Rhat4
#b[1] -0.03 0.67 -1.10  1.01  2861     1
#b[2] -0.01 0.67 -1.07  1.02  2932     1
#b[3] -0.06 0.71 -1.23  1.03  2212     1
#b[4] -0.04 0.69 -1.18  1.04  2739     1
#b[5]  0.56 0.66 -0.47  1.62  2977     1
#b[6] -0.02 0.69 -1.14  1.06  2949     1
#b[7]  0.00 0.67 -1.10  1.06  3289     1
#b[8] -0.02 0.67 -1.09  1.02  2355     1
#b[9] -0.09 0.66 -1.12  0.96  2884     1

#look at b5 MiscHuman because it has a large mean relative to the others
#plot(ff8[ff8$Microhabitat=="MiscHuman",]$ProportionFollows ~ ff8[ff8$Microhabitat=="MiscHuman",]$Lambda)
#this relationship is due to 1 female that spends 100% of her time in this habitat, while the others don't often visit it

# put all of the model outputs into a csv file
#write.csv(c(outputdfp,outputdfl,outputd8l,outputd8l),file="flexforaging_P8outputs.csv")
```

```{r p8figure, eval=T}
library(ggplot2)
library(cowplot)

d8 <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_flexforaging_data_proportionmicrohabitats.csv"), header=T, sep=",", stringsAsFactors=F)
d8 <- data.frame(d8)

# remove NAs
d8 <- subset(d8,!(is.na(d8["ProportionFollows"])))
d8 <- subset(d8,!(is.na(d8["Phi"])))
d8 <- subset(d8,!(is.na(d8["Lambda"])))
d8 <- subset(d8,!(is.na(d8["Microhabitat"])))

#Separate the sexes
ff8 <- d8[d8$Sex=="F",]
mm8 <- d8[d8$Sex=="M",]
ff8$BirdID <- as.factor(ff8$BirdID)
mm8$BirdID <- as.factor(mm8$BirdID)

# factor categorical variable
ff8$Microhabitat <- as.factor(ff8$Microhabitat)
mm8$Microhabitat <- as.factor(mm8$Microhabitat)

# visualize
mp <- ggplot() + geom_point(data=mm8,aes(x=Microhabitat, y=ProportionFollows, size=Phi), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "Proportion follows")
ml <- ggplot() + geom_point(data=mm8,aes(x=Microhabitat, y=ProportionFollows, size=Lambda), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "")
fp <- ggplot() + geom_point(data=ff8,aes(x=Microhabitat, y=ProportionFollows, size=Phi), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "Proportion follows")
fl <- ggplot() + geom_point(data=ff8,aes(x=Microhabitat, y=ProportionFollows, size=Lambda), shape=1) + geom_jitter(width=0.5, height=0.1) + theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + labs(x = "", y = "")

theme_set(theme_cowplot(font_size=12))
plot_grid(mp, ml, fp, fl, align='h', ncol=2, labels=c('A','B','C','D'), label_size=12)
```

**Figure.** Scatterplots for females (top row) and males (bottom row) showing the relationship between the proportion of follows in a particular microhabitat and phi (left column) or lambda (right column). Larger diameter circles indicate a larger phi or lambda.


# DISCUSSION

Human population density varies within and between the grackle populations: it is the highest and lowest at the Woodland trap sites, which are different from each other and from Tempe. This indicates that the environments that individuals on the edge experience do not differ systematically in human population density.

In conclusion,


# ETHICS

This research is carried out in accordance with permits from the:

1) US Fish and Wildlife Service (scientific collecting permit number MB76700A-0,1,2)
2) US Geological Survey Bird Banding Laboratory (federal bird banding permit number 23872)
3) Arizona Game and Fish Department (scientific collecting license number SP594338 [2017], SP606267 [2018], and SP639866 [2019])
4) California Department of Fish and Wildlife (scientific collecting permit number S‐192100001‐19210‐001)
5) Institutional Animal Care and Use Committee at Arizona State University (protocol number 17-1594R)
6) Institutional Animal Care and Use Committee at the University of California Santa Barbara (protocol number 958)
7) University of Cambridge ethical review process (non-regulated use of animals in scientific procedures: zoo4/17 [2017])
8) RegionalSan access permit (number AP 2021-01)

# AUTHOR CONTRIBUTIONS

**Logan:** Hypothesis development, study design, materials, data collection, data analysis and interpretation, write up, funding.

**Lukas:** Hypothesis development, study design, data analysis and interpretation, write up, revising/editing.

**LeGrande-Rolls:** Data collection, data analysis and interpretation, revising/editing

**Bergeron:** Data collection, data interpretation, revising/editing.

**Folsom:** Data collection, data interpretation, revising/editing.

**Marfori:** Data collection, revising/editing.

**McCune:** Hypothesis development, study design, data collection, data analysis, data interpretation, revising/editing.

# FUNDING

This research was funded by the Department of Human Behavior, Ecology and Culture at the Max Planck Institute for Evolutionary Anthropology, and by a Leverhulme Early Career Research Fellowship to Logan (2017-2018).

# CONFLICT OF INTEREST DISCLOSURE

We, the authors, declare that we have no financial conflicts of interest with the content of this article. Logan and Lukas are Recommenders at PCI Ecology, and Logan was on the Managing Board at PCI Ecology (2018-2022).

# ACKNOWLEDGEMENTS

We thank Ben Trumble for providing us with a wet lab at Arizona State University and Angela Bond for lab support; Melissa Wilson for sponsoring our affiliations at Arizona State University and lending lab equipment; Kevin Langergraber for serving as local PI on the ASU IACUC; Kristine Johnson for technical advice on great-tailed grackles; Arizona State University School of Life Sciences Department Animal Care and Technologies for providing space for our aviaries and for their excellent support of our daily activities; Julia Cissewski for tirelessly solving problems involving financial transactions and contracts; Richard McElreath for project support; Aaron Blackwell and Ken Kosik for being the UCSB sponsors of the Cooperation Agreement with the Max Planck Institute for Evolutionary Anthropology; Julia Astegiano, our Recommender at PCI Ecology, and reviewers Esther Sebastian-Gonzalez and Pizza Ka Yee Chow for their wonderful feedback; Sawyer Lung for field support; Alexis Breen for assistance with data cleaning; and our research assistants: Aelin Mayer, Nancy Rodriguez, Brianna Thomas, Aldora Messinger, Elysia Mamola, Michael Guillen, Rita Barakat, Adriana Boderash, Olateju Ojekunle, August Sevchik, Justin Huynh, Jennifer Berens, Amanda Overholt, Michael Pickett, Sam Munoz, Sam Bowser, Emily Blackwell, Kaylee Delcid, Sofija Savic, Brynna Hood, Sierra Planck, and Elise Lange.

\newpage

# SUPPLEMENTARY MATERIAL 1: interobserver reliability

To be able to conduct focal follows [methods as in @altmann1974observational], a coder must pass interobserver reliability before the data they collect is used in the data set. To pass, coders must have an intra-class correlation [ICC; @hutcheon2010random] of 0.90 or greater based on at least six 10-min focal follows where both coders recorded the behavior of the same focal individual at the same time.

Bergeron was the first person to conduct focal follows, therefore she trained McCune and Folsom until they passed interobserver reliability (on 10 June 2019) for each of the 6 variables listed in the preregistration. In March 2021, Rolls passed interobserver reliability (training with McCune) in the California population.

```{r ior, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
# Inter/intra-rater reliability using Cohen's kappa when the variable is categorical (scale=1+) or intra-class correlation coefficient when the variable is continuous (Mandrekar 2011 J Thoracic Oncology 6(1):6-7 https://doi.org/10.1097/JTO.0b013e318200f983)

# Intra-class correlation / reliability coefficient / the
# degree of bias in the regression slope (Hutcheon et al.
# 2010. Random measurement error and regression dilution bias
# www.bmj.com/content/340/bmj.c2289). 'The ratio of variation
# in error-free (true) X values to the variation in the
# observed error-prone (observed) values is known as the
# reliability coefficient, attenuation factor, or intra-class
# correlation.'

#Cohen's kappa = Good for nominal data (where distance doesn't mean anything; don't use the weighted Kappa bc it is like the ICC) https://www.rdocumentation.org/packages/psych/versions/1.9.12.31/topics/cohen.kappa 

# ICC / Cohen's Kappa must be 0.90 or greater to be considered reliable and pass training
### ICCs for agreement between the 2 coders (live coder and video coder)

library(irr) #ICC package
library(psych) #Cohen's kappa package

### ICCs & Cohen's unweighted kappas for agreement between the 2 coders for 6-7 variables
#Note: c(4,5) is telling R to look at columns 4 ("1NumberForagingTechniques") and 5 ("2NumberForagingTechniques") and compare them

#ICCs for KM=Kelsey McCune, MF=Melissa Folsom, CLR=Christa Rolls
km <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/IOR_flexforagingKM.csv"), header=T, sep=",", stringsAsFactors=F) 
km #Check to make sure it looks right
km[,2]
km[,3]

#ICC for number different foods eaten not working
icc(km[,c(2,3)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentFoodsEaten. See note in text for why this is 1.00 rather than 0.64

icc(km[,c(4,5)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentForagingTechniques
icc(km[,c(6,7)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAffiliativeInteractions
icc(km[,c(8,9)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAggressiveInteractions
icc(km[,c(10,11)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberTimesSubjectInitiatedAggression
cohen.kappa(km[,c(12,13)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Microhabitat


#ICCs for MF=Melissa Folsom
mf <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/IOR_flexforagingMF.csv"), header=T, sep=",", stringsAsFactors=F) 
mf #Check to make sure it looks right
mf[,2]
mf[,3]
mf[,12]
mf[,13]

icc(mf[,c(2,3)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentFoodsEaten. See note in text for why this is 1.00 rather than 0.63
icc(mf[,c(4,5)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentForagingTechniques
icc(mf[,c(6,7)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAffiliativeInteractions
icc(mf[,c(8,9)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAggressiveInteractions
icc(mf[,c(10,11)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberTimesSubjectInitiatedAggression
cohen.kappa(mf[,c(12,13)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Microhabitat


#ICCs for CLR=Christa Rolls
clr <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/IOR_flexforagingCLR.csv"), header=T, sep=",", stringsAsFactors=F) 
clr #Check to make sure it looks right
clr[,9]
clr[,10]

icc(clr[,c(3,4)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentFoodsEaten
icc(clr[,c(5,6)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberDifferentForagingTechniques
icc(clr[,c(7,8)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAffiliativeInteractions
icc(clr[,c(9,10)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberAggressiveInteractions
icc(clr[,c(11,12)], model="oneway", type="agreement", unit="single", conf.level=0.95) #NumberTimesSubjectInitiatedAggression
cohen.kappa(clr[,c(13,14)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Microhabitat. Unweighted kappa=1
icc(clr[,c(15,16)], model="oneway", type="agreement", unit="single", conf.level=0.95) #Group size
```

**Scores for McCune (n=6 focal follows, Bergeron=baseline):**

Different Foods Eaten: ICC = 1.00

Different Foraging Techniques: ICC = 0.97 (95% confidence interval=0.823-1.00)

Number of Affiliative Interactions: ICC = 0.96 (95% confidence interval=0.794-1.00)

Number of Aggressive Interactions: ICC = 1.00 (95% confidence interval=0.986-1.00)

Number of Initiated Aggressive Interactions: ICC = 1.00 (95% confidence interval=0.974-1.00)

Microhabitat: Cohen's unweighted kappa = 1.00

**Scores for Folsom (n=6 focal follows, Bergeron=baseline):**

Different Foods Eaten: ICC = 1.00

Different Foraging Techniques: ICC = 1.00

Number of Affiliative Interactions: ICC = 1.00

Number of Aggressive Interactions: ICC = 0.96 (95% confidence interval=0.779-0.994)

Number of Initiated Aggressive Interactions: ICC = 0.94 (95% confidence interval=0.696-0.991)

Microhabitat: Cohen's unweighted kappa = 1.00

NOTE: the ICCs for the variable Different Foods Eaten for these focal follows was originally 0.63 (Folsom) and 0.64 (McCune) because Folsom and McCune recorded a "bug" being eaten while Bergeron recorded no food type because she couldn't identify it to a more specific category. At this point, we decided that we would prefer to enter a general category for food type rather than having no information about what was eaten. Therefore, this data point was removed from the interobserver reliability analysis. This resulted in ICCs of 1.00 for both McCune and Folsom on the Different Foods Eaten variable because they matched Bergeron in the other food type data points.

**Scores for Rolls (n=17 focal follows, McCune=baseline):**

Different Foods Eaten: ICC = 0.92 (95% confidence interval=0.791-0.971)

Different Foraging Techniques: ICC = 0.91 (95% confidence interval=0.758-0.966)

Number of Affiliative Interactions: ICC = 0.90 (95% confidence interval=0.751-0.965)

Number of Aggressive Interactions: ICC = 0.94 (95% confidence interval=0.830-0.977)

Number of Initiated Aggressive Interactions: ICC = 0.95 (95% confidence interval=0.874-0.983)

Microhabitat: Cohen's unweighted kappa = 1.00

Group size = 1.00

```{r iorrolls, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
#Cohen's kappa for CLR=Christa Rolls' recoded data vs the original transcribed data
library(psych) #Cohen's kappa package

#whether one or more errors were found by CLR (1=yes, 0=no). The assumption is that when the coders initially transcribed the data the first time, they did not think they were making any errors (0)
clr = c(1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0)
orig = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)

#the cohen.kappa calculation can't calculate it properly when the data are in this format because one string is calculating the errors of the other string. So assign numbers 1 through 37 to orig and the same for clr, but make the 4 data points that were different in the two strings a number that is out of sequence so the difference will register
orig <- c(1:37)
clr <- c(1:37)
clr[1] <- 38
clr[22] <- 39
clr[30] <- 10
clr[36] <- 40

cohen.kappa(x=cbind(clr,orig), w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Unweighted kappa = 0.89, confidence boundary 0.79-0.99
```

**Unregistered reliability analysis for data entry (Jun 2022):** The focal follow data were transferred from the Prim8 auto-generated data sheets and transcribed (from focals that were recorded using audio files) to two analyzable data sheets (one for social behavior and one for foraging behavior) containing data for all variables in this preregistration. During the data cleaning process, several data entry/transcription errors were found, which prompted us to conduct a reliability analysis on the data. We did not record who the data entry person / transcriber was, so we could not conduct an interoberver analysis. Instead, we conducted an intraobserver reliability analysis. Ten percent (37) of the focal follows (total 367) were randomly selected (using RAND() in MS Excel) and recoded by Christa Rolls in 2022. Rolls recorded for each focal follow whether one or more errors in the original data set were made (1) or not (0), and this vector was compared with a vector from the original data set where the assumption wsa that no errors were made (all data points were 0). The Cohen's kappa between the recoded and the original data set was 0.89 (confidence boundary 0.79-0.99), indicating that the data cleaning process corrected enough errors such that the rest of the data did not need to be recoded.

# REFERENCES
