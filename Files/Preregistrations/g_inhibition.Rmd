---
title: "Are the more flexible great-tailed grackles also better at behavioral inhibition?"
author: 
 - '[Logan CJ](http://CorinaLogan.com)^1^'
 - '[McCune KB](https://www.kelseymccune.com)^2^'
 - '[MacPherson M](http://maggiepmacpherson.com)^2^'
 - 'Johnson-Ulrich Z^2^'
 - 'Bergeron L^2^'
 - 'Rowney C^1^'
 - '[Seitz B](https://benjaminseitz.wixsite.com/mysite)^3^'
 - '[Blaisdell A](http://pigeonrat.psych.ucla.edu)^3^'
 - 'Folsom M^1^'
 - 'Deffner D^1^'
 - '[Wascher C](https://www.claudiawascher.com)^4^'
date: '`r Sys.Date()`'
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
    code_folding: hide 
  md_document: 
    toc: true
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
  github_document: 
    toc: true
bibliography: /Users/corina/ownCloud/Documents/GitHub/grackles/Files/MyLibrary.bib
always_allow_html: true
header-includes:
  - \usepackage[left]{lineno}
  - \linenumbers
---

##### Affiliations: 
1) Max Planck Institute for Evolutionary Anthropology
2) University of California Santa Barbara
3) University of California Los Angeles
4) Anglia Ruskin University

*Corresponding author: corina_logan@eva.mpg.de

```{r setup, include=FALSE}
library(knitr)
#Make code wrap text so it doesn't go off the page when Knitting to PDF
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

knitr::opts_chunk$set(echo = TRUE)
```

<img width="50%" src="logoPCIecology.png">

**Cite as:** Logan CJ, McCune K, MacPherson M, Johnson-Ulrich Z, Bergeron L, Rowney C, Seitz B, Blaisdell A, Folsom M, Wascher CAF. 2019. **[Are the more flexible individuals also better at inhibition?](http://corinalogan.com/Preregistrations/g_inhibition.html)** (http://corinalogan.com/Preregistrations/g_inhibition.html) In principle acceptance by *PCI Ecology* of the version on 6 Mar 2019 [https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_inhibition.Rmd](https://github.com/corinalogan/grackles/blob/master/Files/Preregistrations/g_inhibition.Rmd).

<img width="5%" src="logoOpenAccess.png"> <img width="5%" src="logoOpenCode.png"> <img width="5%" src="logoOpenPeerReview.png">

**This preregistration has been pre-study peer reviewed and received an In Principle Recommendation by:**

Erin Vogel (2019) Adapting to a changing environment: advancing our understanding of the mechanisms that lead to behavioral flexibility. *Peer Community in Ecology*, 100016. [10.24072/pci.ecology.100016](https://ecology.peercommunityin.org/public/rec?id=32&reviews=True)

 - Reviewers: Simon Gingins and two anonymous reviewers

### ABSTRACT

It is thought that those individuals who are more behaviorally flexible (measured as reversal learning) must also be better at inhibiting because one should need to inhibit a previously learned behavior to change their behavior when the task changes [the flexibility component; @manrique_repeated_2013; @griffin2014innovation; @liu2016learning]. However, @homberg2007serotonin showed that rats with improved behavioral inhibition (due to gene knock outs) did not perform better in a reversal learning experiment (a measure of behavioral flexibility) than non-knock out rats. These results challenge the assumption that behavioral inhibition is involved in making flexible decisions. We test the hypothesis that behavioral flexibility requires behavioral inhibition by measuring both variables in the same individuals. We set out to measure grackle behavioral inhibition in three experiments (delay of gratification, go-no go, detour) to determine whether those individuals that are more flexible (measured as reversal learning and solution switching on a puzzlebox by @logan2019flexmanip) are also better at inhibiting. We were not able to run the delay of gratification experiment because the grackles never habituated to the apparatuses, therefore the behavioral inhibition results come from the go no-go and detour experiments. Touchscreen experiments had never been conducted in this species before, and it was one of our goals to validate whether this set up is viable for running a behavioral inhibition task on wild-caught adult grackles. We found that the grackles were able to learn to use the touchscreen and to complete the go no-go test on it, thus validating the use of this set up for future experiments. Results showed that neither behavioral inhibition test correlated with either measure of behavioral flexibility, indicating that inhibition and flexibility are two separate traits. However, a posthoc analysis of the go no-go data using a different passing criterion (number of trials to reach 85% correct, rather than needing to get 100% correct by trial 150 and 85% correct thereafter) showed a positive correlation with the number of trials to reverse a preference. We are reluctant to rely on this result because it was a posthoc analysis and the relationship appeared entirely due to one outlier. We would need a larger sample size to determine whether this is a reliable result. Performance on the two behavioral inhibition tests, go no-go and detour, did not correlate with each other, indicating that they do not measure the same trait. Performance on the detour test was not affected by extensive experience obtaining food from tubes in the reversal learning test because grackles who received detour before reversal did not perform differently from those who received detour after reversal. We consider the go no-go test a more accurate measure of behavioral inhibition because it requires an active decision to inhibit a motor behavior, rather than a passive form of motor inhibition as in the detour task. 

### [Video summary](https://youtu.be/TXFOYqZztf4)

### INTRODUCTION

It is thought that those individuals who are more behaviorally flexible (measured as reversal learning) must also be better at inhibiting because one should need to inhibit a previously learned behavior to change their behavior when the task changes [the flexibility component, see @mikhalevich_is_2017 for the theory behind the flexibility definition; @manrique_repeated_2013; @griffin2014innovation; @liu2016learning]. However, @homberg2007serotonin showed that rats with improved behavioral inhibition (due to gene knock outs) did not perform better in a reversal learning experiment (a measure of behavioral flexibility) than non-knock out rats. These results challenge the assumption that behavioral inhibition is involved in making flexible decisions. @logan2016flexibilityproblem posited that "behavioral flexibility may rely more on individuals continuing to sample their environment rather than simply inhibiting a response when a behavior is no longer rewarded".

Different forms of behavioral inhibition (active vs passive)...[Claudia]

We aimed to determine whether great-tailed grackles that are better at inhibiting in three experiments (delay of gratification, go-no go, detour) are also more behaviorally flexible (measured as reversal learning and solution switching on a puzzlebox by @logan2019flexmanip). Touchscreen experiments had never been conducted in this species before, and it was one of our goals to validate whether this set up is viable for running a behavioral inhibition task on wild-caught adult grackles. By measuring behavioral inhibition in three different ways, we aimed to determine whether these tests measure the same trait or separate traits. Results indicate whether flexibility and behavioral inhibition are related and whether behavioral inhibition tests measure the same trait.

### RESULTS

We were not able to conduct the delay of gratification experiment because the grackles never habituated to the apparatuses, therefore the behavioral inhibition results come from the go no-go and detour experiments. 

**Table 1.** Summarized results per bird in the go no-go, detour, reversal, and multiaccess box (MAB) experiments. Pizza completed only 4 of the 10 detour trials (with 0 correct choices), therefore this experiment was incomplete and his data were not included in the analyses.

```{r summary, eval=TRUE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)

d <- data.frame(d)

library(reactable)
reactable(d, highlight=TRUE, bordered=FALSE, compact=TRUE, wrap=TRUE, resizable=TRUE,
          columns = list(
            V1 = colDef(name="Bird name"),
            V2 = colDef(name="Bird ID"),
            V3 = colDef(name="Go no-go trials to 85% correct after 150 trials"),
            V4 = colDef(name="Go no-go trials to 85% correct"),
            V5 = colDef(name="Detour % correct"),
            V6 = colDef(name="Detour % correct modified"),
            V7 = colDef(name="Detour pre- or post-reversal"),
            V8 = colDef(name="Trials to reverse in first reversal"),
            V9 = colDef(name="Trials to reverse in last reversal"),
            V10 = colDef(name="Average latency to attempt new solution (MAB)")
          ))
```

#### Prediction 1: go no-go

**Model 2a: Number of trials**

There was no correlation between the number of trials to pass criterion in the go no-go experiment and the number of trials to reverse a preference in the colored tube reversal experiment (in their **last reversal**) when using our original go no-go passing criterion (if 100% correct is not reached by trial 150, then they pass when they reach 85% correct after trial 150, measured in the most recent 20 trial block; Table 2). Nine grackles participated in the go no-go experiment and they passed criterion in an average of 178 trials (standard deviation: 15, range: 160 trials to not passing before the experiment ended at 200 trials).

##### Unregistered analyses

We additionally analyzed the relationship between go no-go performance and the number of trials to reverse a color preference in the **first reversal** to make our results comparable across more species. This is because most studies do not conduct serial reversals, but only one reversal. The results remained the same regardless of whether the first or last reversal were analyzed: there was no relationship between go no-go and reversal learning performance (Table 2).

As we conducted this experiment, we realized that setting an **arbitrary threshold** of needing 100% correct in the first 150 trials to pass criterion was not ecologically relevant for grackles. In reversal learning tests, which are similar to the go no-go experimental design in that they learn to discriminate between two shapes, grackles almost always continue to explore their options regardless of whether they already have a color preference [e.g., @logan2016flexibilityproblem]. Therefore, we *posthoc* examined the number of trials required to reach 85% correct in the most recent 20 trial block, regardless of the 150 trial threshold. Using this criterion, grackles passed in an average of 149 trials (standard deviation: 71, range: 60-290 trials). We found that there was more individual variation using this variable. Results showed that the number of trials to reach 85% correct positively correlated with the number of trials to reverse a preference. This indicates that those individuals that are faster at inhibiting are also faster at changing their preferences when circumstances change. However, we are hesitant to rely on the result because 1) it was a posthoc analysis, and 2) the relationship appeared to occur because of the outlier (Taquito). We would need a larger sample size to determine whether this is a reliable result. 

**Table 2.** Results from the GLMs: **m1** and **m2** show GLM outputs for the last reversal, while **m3** and **m4** show GLM outputs for the first reversal. **m1** and **m3** show results from the GLM using the number of trials to reach 85% correct if 100% correct was not achieved within the first 150 trials in go no-go, while **m2** and **m4** use the number of trials to reach 85% correct without the 150 trial threshold.

```{r goResults, eval=T, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsFirst","TrialsLast","AvgLatency")

#GLM
m1 <- glm(Gonogo150 ~ TrialsLast, family="poisson", data=d)
#sm1 <- summary(m1) 
#there is no relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the last reversal)

m2 <- glm(Gonogo85 ~ TrialsLast, family="poisson", data=d)
#sm2 <- summary(m2) 
#there is a relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the last reversal) 

#have a look at the plot to see why m2, but not m1 is positively related
#plot(Gonogo85~TrialsLast, data=d) 
#Taquito is a huge outlier here and if I look at the rest of the data, I don't see a positive relationship. Need more data to know whether this relationship holds


#UNREGISTERED analyses: number of trials to reverse in the first reversal (which will make this data comparable with more species)
u1 <- glm(Gonogo150 ~ TrialsFirst, family="poisson", data=d)
#su1 <- summary(u1) 
#there is no relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the first reversal)

u2 <- glm(Gonogo85 ~ TrialsFirst, family="poisson", data=d)
#su2 <- summary(u2) 
#there is no relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the first reversal) (though the estimate 0.008 and the standard error is lower than the estimate so it doesn't cross zero, it is is significant: p<2e-16)


#load packages for the output table
library(jtools) 
base::suppressMessages(jtools::export_summs(m1, m2, u1, u2, model.names=c("m1: 150 last reversal","m2: 85 last reversal","m3: 150 first reversal","m4: 85 first reversal"), digits = getOption("jtools-digits", default = 2), model.info = getOption("summ-model.info", TRUE), model.fit = getOption("summ-model.fit", TRUE), pvals = getOption("summ-pvals", FALSE))) 
#suppressMessages gets rid of the text saying that the broom package overwrites something in jtools. Need to specify the package before the function to avoid a message popping up and preventing the PDF from rendering
knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)}) 
#this prevents an issue with xcolor package when rendering to PDF


#Note: this code also works for showing output tables, but don't know how to get it to show more than one model at a time
#library(xtable)
#sm1.table <- xtable(sm1)
#library(knitr)
#kable(sm1.table, caption="Table T: Model selection output.", format="html", digits=2)
```

**Model 2b: Latency to peck screen**

The model examining the latency of the first peck to the screen per trial (response variable) in association with whether the response was correct or not and the trial number did not converge. Therefore, we cannot include the analysis here or make conclusions based on it. Additionally, there was a problem matching the latency data across data sheets. Latency data was brought in from the PsychoPy data sheets, however the number of trials reported by the experimenter and by PsychoPy sometimes differed for reasons that are unclear. Therefore, the first latency to peck the screen is not completely accurately matched between the two data sheets.

```{r golatencyResults, eval=T, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_data_gonogoExperimenter.csv"), header=T, sep=",", stringsAsFactors=F)
d <- data.frame(d)

#Remove trials that grackles didn't participate in, & Queso who didn't complete this experiment
d1 <- d[!d$CorrectChoice==-1  & !d$ID=="Queso",] 

#Set numeric and factors so MCMCglmm will run
d1$LatencyFirstPeckToScreen <- as.numeric(d1$LatencyFirstPeckToScreen)
d1$Trial <- as.numeric(d1$Trial)
d1$CorrectChoice <- as.factor(d1$CorrectChoice)
d1$ID <- as.factor(d1$ID)

#Figure: x=trial number,  y=latency to peck screen, by choice (wrong, correct on go trial, correct on no go trial)
wrong <- d1[d1$CorrectChoice=="0",]
go <- d1[d1$CorrectChoice=="1",]
nogo <- d1[d1$CorrectChoice=="2",]

op <- par(mfrow=c(3,1), oma=c(0,0,0,0), mar=c(4.5,4.5,2,0.2), cex.lab=1.8, cex.axis=2)
plot(wrong$Trial,wrong$LatencyFirstPeckToScreen, ylab="Latency first peck/trial (s)", xlab="", xlim=c(0,300), cex=2)
mtext("Incorrect choice",side=3,line=0,cex=1.5)
plot(go$Trial,go$LatencyFirstPeckToScreen, ylab="Latency first peck/trial (s)", xlab="", xlim=c(0,300), cex=2)
mtext("Correct choice: Go trials",side=3,line=0,cex=1.5)
plot(nogo$Trial,nogo$LatencyFirstPeckToScreen, ylab="Latency first peck/trial (s)", xlab="Trial number", xlim=c(0,300), cex=2)
mtext("Correct choice: No Go trials",side=3,line=0,cex=1.5)
par(op)
```

**Figure 1.** The latency to the first peck on the screen per trial across trials according to whether they made the incorrect choice (top), the correct choice on the Go trials (middle), or the correct choice on the No Go trials (bottom).

#### Prediction 1: detour

There was no correlation between the number of trials to pass criterion in the go no-go experiment and the percent correct on the detour experiment (Table 3). 18 grackles completed this experiment and they averaged 71% correct (standard deviation: 25%, range: 20-100%). 

##### Unregistered analyses

We additionally analyzed the relationship between detour performance and the number of trials to reverse a color preference in the **first reversal** to make our results comparable across more species. This is because most studies do not conduct serial reversals, but only one reversal. The results remained the same regardless of whether the first or last reversal were analyzed: there was no relationship between detour and reversal learning performance (Table 3).

As we conducted this experiment, we discovered the scoring whether the grackle made a correct or incorrect first choice is more complicated than the scoring method used in @maclean2014evolution. In @maclean2014evolution, if the plastic is touched first, then it is an incorrect choice, whereas if the food is touched first, it is a correct choice. If the plastic is touched first, it is assumed that the individual touched the plastic on the long side of the tube and not on the rim side where the opening is because they were trying to reach the food through plastic (which is non-functional). We found that many grackles have a habit of standing at the tube opening attempting to reach their head in to obtain the food, but being hesitant to put their head inside the tube, at which point they bite the rim of the tube (what we have been calling a "frustration bite") just before reaching their head in to obtain the food. Because the grackle was clearly not attempting to reach the food through the plastic, we coded an additional variable, the "grackle-specific correct choice". In this variable, a frustration bite to the plastic rim does not count as an incorrect choice if they immediately afterward obtain the food. Instead, this counts as a correct choice. We therefore conducted *posthoc* analyses of the percent correct on the detour task in relation to their reversal performance (Table 3). The results were the same as above: there is no correlation between detour performance (using the grackle-specific correct choice) and the number of trials to reverse their last or first preference. With this scoring method, grackles averaged 87% correct (standard deviation: 25%, range: 60-100%).

**Table 3.** Results from the GLMs: **m1** and **m2** show GLM outputs using the  @maclean2014evolution method of scoring, while **m3** and **m4** show GLM outputs using the grackle-specific scoring method. **m1** and **m3** show results using the last reversal, while **m2** and **m4** use the first reversal.

```{r detourResults, eval=T, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsFirst","TrialsLast","AvgLatency")

#GLM
d$ID <- factor(d$ID)
m4 <- glm(Detour ~ TrialsLast, family="binomial", data=d)
sm4 <- summary(m4) 
#there is no relationship between the proportion of trials correct on the detour task and the number of trials to reverse in the last reversal

#UNREGISTERED ANALYSIS: first reversal (rather than last reversal)
m5 <- glm(Detour ~ TrialsFirst, family="binomial", data=d)
sm5 <- summary(m5) 
#there is no relationship between the proportion of trials correct on the detour task and the number of trials to reverse in the first reversal

m6 <- glm(DetourA ~ TrialsLast, family="binomial", data=d)
sm6 <- summary(m6) 
#there is no relationship between the proportion of trials correct on the detour task (grackle calculation) and the number of trials to reverse in the last reversal

m7 <- glm(Detour ~ TrialsFirst, family="binomial", data=d)
sm7 <- summary(m7) 
#there is no relationship between the proportion of trials correct on the detour task (grackle calculation) and the number of trials to reverse in the first reversal


#load packages for the output table
library(jtools) 
base::suppressMessages(jtools::export_summs(m4, m5, m6, m7, model.names=c("m1: MacLean calculation & last reversal","m2: MacLean calculation & first reversal","m3: Grackle calculation & last reversal","m4: Grackle calculation & first reversal"), digits = getOption("jtools-digits", default = 2), model.info = getOption("summ-model.info", TRUE), model.fit = getOption("summ-model.fit", TRUE), pvals = getOption("summ-pvals", FALSE))) 
#suppressMessages gets rid of the text saying that the broom package overwrites something in jtools. Need to specify the package before the function to avoid a message popping up and preventing the PDF from rendering
knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)}) 
#this prevents an issue with xcolor package when rendering to PDF
```

#### Prediction 1 alternative 2: are behavioral inhibition results reliable?



#### Prediction 2: correlation across behavioral inhibition tasks



#### Prediction 3: does training improve detour performance?

There was no difference in the percent correct on the detour task and whether the individual received the detour experiment before or after their reversal learning experiment (which also involved obtaining food from tubes; Table 5).

##### Unregistered analysis

We conducted a post-hoc analysis using the grackle-specific percent of correct responses (see full explanation in P1: detour > Unregistered analyses) and found that the result is the same as above: there is no difference in detour performance relative to their experience with reversal tubes.

**Table 5.** Results from the GLMs: **Detour standard** shows GLM outputs using the  @maclean2014evolution method of scoring, and **Detour grackle-specific** shows GLM outputs using the grackle-specific scoring method.

```{r detour2Results, eval=T, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsFirst","TrialsLast","AvgLatency")

#GLM - detour standard correct choice scoring
de <- glm(Detour ~ Detourprepost, family="binomial", data=d)
sde <- summary(de)
#no difference between detour percent correct and whether they received detour before or after reversal tubes

#GLM - detour grackle-specific correct choice scoring - UNREGISTERED ANALYSIS
de2 <- glm(DetourA ~ Detourprepost, family="binomial", data=d)
sde2 <- summary(de2)
#no difference between detour percent correct and whether they received detour before or after reversal tubes

#load packages for the output table
library(jtools) 
base::suppressMessages(jtools::export_summs(de, de2, model.names=c("Detour standard","Detour grackle-specific"), digits = getOption("jtools-digits", default = 2), model.info = getOption("summ-model.info", TRUE), model.fit = getOption("summ-model.fit", TRUE), pvals = getOption("summ-pvals", FALSE))) 
#suppressMessages gets rid of the text saying that the broom package overwrites something in jtools. Need to specify the package before the function to avoid a message popping up and preventing the PDF from rendering
knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)}) 
#this prevents an issue with xcolor package when rendering to PDF
```



### DISCUSSION



### A. STATE OF THE DATA

**Prior to collecting any data:** This preregistration was written. 

**After data collection had begun (and before any data analysis):** This preregistration was submitted to PCI Ecology (Oct 2018) for peer review after starting data collection on the detour task for the pre-reversal subcategory of subjects (for which there was data from one bird). Reviews were received, the preregistration was revised and resubmitted to PCI Ecology (Jan 2019) at which point there was detour data for six birds, data on a few training trials for the delay of gratification task for one bird, and no data from the go no-go experiment. This preregistration passed peer review and was recommended by PCI Ecology in March 2019 (see the [review history](https://ecology.peercommunityin.org/public/rec?id=32&reviews=True)).

**After data collection began and before data analysis: how the actual methods differed from the planned methods**

1) Jan 2020: we discovered that none of the grackles reached 100% accuracy within 150 trials (at least not at the level of 20 trial blocks), which is consistent with their reversal performance as well where they usually do not 100% prefer one option, but continue to occasionally explore the other option. The passing criterion of 100% correct within 150 trials or 85% correct between 150-200 trials could be the reason there was not much individual variation in this test (passing in 160-190 trials or they did not reach 85% accuracy within 200 trials). All grackles received 150+ trials, therefore we were only measuring variation after 150 trials, rather than variation across all trials. We decided to add a **post-hoc passing criterion** that might be more illustrative of individual differences in behavioral inhibition in grackles: 85% accuracy at the level of the most recent sliding 10 trial block (i.e., the most recent 10 trials, regardless of whether it is an even 20, 30, 40 trials). We added this modified response variable posthoc to the discussion. We predict this new passing criterion will show more individual variation, and that it will more accurately represent individual differences in grackle inhibitive abilities.

2) Jul 2020: Independent variables > P1 go no-go > Model 2b: removed the variable "flexibility condition" because, by definition, the birds in the manipulated condition were faster to reverse. 

### B. PARTITIONING THE RESULTS

We may decide to present the results from different tests in separate papers. NOTE: everything in the preregistration is included in this one manuscript.

### C. HYPOTHESIS

**If flexibility requires behavioral inhibition, then individuals that are more [behaviorally flexible](./g_flexmanip.Rmd) (indicated by individuals that are faster at functionally changing their behavior when circumstances change), as measured by reversal learning and switching between options on a multi-access box, will also be better at inhibiting their responses in three tasks: delayed gratification, go no-go, and detour.**

**P1:** Individuals that are faster to reverse preferences on a reversal learning task and who also have lower latencies to successfully solve new loci after previously solved loci become unavailable (multi-access box) (see [flexibility preregistration](./g_flexmanip.Rmd)) will perform better in the go no-go task (methods similar to @harding2004animal), in the detour task (methods as in @maclean2014evolution who call it the "cylinder task"), and they will wait longer for higher quality (more preferred) food, but not for higher quantities (methods as in @hillemann2014waiting). Waiting for higher quality food has been validated as a test of behavioral inhibition in birds, while waiting for a higher quantity of food does not appear to measure behavioral inhibition (@hillemann2014waiting).

**P1 alternative 1:** If there is no correlation between flexibility measures and performance on the behavioral inhibition tasks, this may indicate that the flexibility tasks may not require much behavioral inhibition (particularly if the behavioral inhibition results are reliable - see *P1 alternative 2*).

**P1 alternative 2:** If there is no correlation between flexibility measures and performance on the behavioral inhibition tasks, this may indicate that the behavioral inhibition tasks had low reliability and were therefore too noisy to correlate with flexibility.

**P2:** If there is no correlation in performance across behavioral inhibition tasks, it may indicate that that one or more of these tasks does not measure behavioral inhibition, or that they measure different types of behavioral inhibition (see @friedman2004relations).

**P2 alternative:** If go no-go task performance strongly correlates with performance on the delayed gratification task, this indicates these two tasks measure the same trait, which therefore validates a behavioral inhibition task using a touchscreen (the go no-go task).

**P3:** If individuals perform well on the detour task and with little individual variation, this is potentially because they will have had extensive experience looking into the sides of opaque tubes during reversal learning. To determine whether prior experience with opaque tubes in reversal learning contributed to their detour performance, a subset of individuals will experience the detour task before any reversal learning tests. If this subset performs the same as the others, then previous experience with tubes does not influence detour task performance. If the subset performs worse than the others, this indicates that detour task performance depends on the previous experiences of the indviduals tested.

![Figure 2. Experimental design.](g_inhibitionFig1.png)

***Figure 2.*** The experimental designs of the three tasks: delayed gratification, go no-go, and detour (see [protocol](https://docs.google.com/document/d/1oEQ66yLrkMFr4UJTXfPBRAEXqoUuOgRwcKOB_KcT7HE/edit?usp=sharing) for details). In the **delay of gratification** task, individuals learn that food items will be transferred by the experimenter from a storing lid (near the experimenter) to a serving lid (near the bird) one at a time, and that they have access to the food in the serving lid from which they can eat at any time: they will learn that they will have access to more food if they wait longer for the experimenter to transfer food items. Once they pass training (by waiting for more than one food item in three trials), they move on to the test where food items are transferred from the serving to the storing lid with delays ranging from 2-1280 seconds. Birds will be tested on whether they are willing to wait for food items that increase in quality (i.e., are more preferred) or increase in quantity (i.e., the same food type accumulates in the serving lid). In the **go no-go** task, after pecking a start key on the touchscreen to show they are interested in attending to a trial, they will see either a green circle or a purple circle (the rewarded circle color is counterbalanced across birds). Pecking the food key while the rewarded colored circle (green in the figure) is on the screen will result in the food hopper rising so the bird can eat food for 2 seconds, after which point the trial ends and the screen goes blank for 8 seconds before starting over again. If the non-rewarded colored circle (purple in the figure) appears on the screen after the start key is pecked, then the correct response is to refrain from pecking the food key for 10 seconds. If the bird succeeds in refraining, the next intertrial interval starts. If the bird fails and pecks the food key while the purple circle is on the screen, then it is given an aversive stimuli for 5 seconds (TV static screen). In the **detour** task, individuals first receive a warm up with an opaque tube where they learn that the experimenter will show them a piece of food and then move that piece of food into the tube. They then have the opportunity to approach the tube and eat the food. A correct response is when their first approach is to go to the side of the tube to the opening to obtain the food and an incorrect response is when they try to access the food by pecking at the front of the tube (which has no opening). Once they pass the warm up, they move on to the test, which is exactly the same except the tube is transparent. The idea is that being able to see the food through the tube wall might entice them to try to go through the wall rather than refrain from a direct approach to the food and instead go around the side through the tube opening.

### D. METHODS

#### Open materials

[Testing protocols](https://docs.google.com/document/d/1oEQ66yLrkMFr4UJTXfPBRAEXqoUuOgRwcKOB_KcT7HE/edit?usp=sharing) for all three experiments: color tube reversal learning, multi-access box, and touchscreen reversal learning

#### Open data

When the study is complete, the data will be published in the Knowledge Network for Biocomplexity's data repository.

#### Randomization and counterbalancing

**P3** 

Two individuals from each batch will experience the detour task before participating in the flexibility manipulation. These individuals will be randomly selected using the random number generator at https://www.random.org.

**P1-P2**

For the rest of the individuals (n=6 per batch), the order of the three behavioral inhibition tasks will be counterbalanced across birds (using https://www.random.org to randomly assign individuals to one of three experimental orders). 1/3 of the individuals will experience:

1. Delayed gratification task

2. Go no-go task

3. Detour

1/3 of the individuals will experience:

1. Go no-go task

2. Detour

3. Delayed gratification task

1/3 of the individuals will experience: 

1. Detour

2. Delayed gratification task

3. Go no-go task

**Delayed gratification** 

- Food preference test: food will be presented in random combinations over six sessions of 12-15 trials. 

- Training trials: The type of demonstration and training trials varied randomly (with more demo trials near the beginning of training), incorporating trials in which food of the same sort accumulated (quantity), food of ascending quality accumulated (quality), and trials in which we added increasingly larger food pieces throughout the trial (size)

- Test: we will test each food quality (low, mid, high) twice in randomized order in each session.

**Go no-go** 

Go and no-go trials will be presented randomly with the restriction that no more than four of the same type will occur in a row. The rewarded color will be counterbalanced across birds.

**Detour** 

The side from which the apparatus is baited will be consistent within subjects, but counterbalanced across subjects.

#### Blinding of conditions during analysis

No blinding is involved in this study.

#### Dependent variables

##### *P1: the more flexible individuals are better at behavioral inhibition*

1) **Delayed gratification:** Number of food pieces waited for (0-3). A successful wait is defined as waiting for at least one additional piece of food to be added to the serving lid of the three possible additional food items, and accepted at least one piece of the reward pieces.

2) **Go no-go:** 

    a) The number of trials to reach criterion (85% correct) where correct responses involve pecking when the rewarded stimulus is displayed and not pecking when the unrewarded stimulus is displayed, and incorrect responses involve pecking when the unrewarded stimulus is displayed, and not pecking when the rewarded stimulus is displayed

    b) The latency to respond (peck the target key)

3) **Detour:** First approach (physical contact): Correct (to the tube's side opening) or Incorrect (to the front unopen area of the tube) (methods as in @maclean2014evolution).

One model will be run per dependent variable.

##### *P3: does training improve detour performance?*

1) First approach (physical contact): Correct (to the tube's side opening) or Incorrect (to the front unopen area of the tube) (methods as in @maclean2014evolution).

#### Independent variables

##### *P1: delayed gratification*

1) Food quality or quantity (Quality: High, Med, Low; Quantity: Smaller, Medium, Larger)

2) Trial

3) Delay (2, 5, 10, 20, 40, 60, or 80 seconds)

4) Flexibility 1: **Number of trials to reverse** a preference in the last reversal an individual experienced (reversal learning; an individual is considered to have a preference if it chose the rewarded option at least 17 out of the most recent 20 trials, with a minimum of 8 or 9 correct choices out of 10 on the two most recent sets of 10 trials). See behavioral flexibility [preregistration](./g_flexmanip.Rmd).

5) Flexibility 3: If the number of trials to reverse a preference does not positively correlate with the latency to attempt or solve new loci on the multi-access box (an additional measure of behavioral flexibility), then the **average latency to solve** and the **average latency to attempt** a new option on the multi-access box will be additional dependent variables. See behavioral flexibility [preregistration](./g_flexmanip.Rmd).

7) Flexibility 4: This measure is currently being developed and is intended be a more accurate representation of all of the choices an individual made, as well as accounting for the degree of uncertainty exhibited by individuals as preferences change. If this measure more effectively represents flexibility (determined using a modeled dataset and not the actual data), we may decide to solely rely on this measure and not use flexibility measures 1 through 3. If this ends up being the case, we will modify the code in the analysis plan below to reflect this change.

##### *P1: go no-go*

Model 2a: number of trials to reach criterion

1) Flexibility 1: Number of trials to reverse a preference in the last reversal an individual experienced (reversal learning; as above)

2) Flexibility 3: If the number of trials to reverse a preference does not positively correlate with the latency to attempt or solve new loci on the multi-access box, then the **average latency to solve** and the **average latency to attempt** a new option on the multi-access box will be additional independent variables (as above).

4) Flexibility 4: This measure is currently being developed and is intended be a more accurate representation of all of the choices an individual made, as well as accounting for the degree of uncertainty exhibited by individuals as preferences change. If this measure more effectively represents flexibility (determined using a modeled dataset and not the actual data), we may decide to solely rely on this measure and not use flexibility measures 1 through 3. If this ends up being the case, we will modify the code in the analysis plan below to reflect this change.

Model 2b: latency to respond

1) Correct or incorrect response

2) Trial

3) [Flexibility Condition](./g_flexmanip.Rmd): control, flexibility manipulation

3) ID (random effect because multiple measures per bird)

NOTE Jul 2020: remove flexibility condition as a variable because, by definition, the birds in the manipulated group were faster to reverse their preferences.

##### *P1: detour*

1) Trial

NOTE (Aug 2020): Because the data are analyzed in a GLM, meaning that there is only one row per bird, trial number is not able to be included in such an analysis because it would need to be conducted on multiple rows per bird. Therefore, we removed this independent variable from this analysis.

2) Flexibility 1: Number of trials to reverse a preference in the last reversal an individual experienced (reversal learning; as above)

3) Flexibility 3: If the number of trials to reverse a preference does not positively correlate with the latency to attempt or solve new loci on the multi-access box, then the **average latency to solve** and the **average latency to attempt** a new option on the multi-access box will be additional independent variables (as above).

4) Flexibility 4: This measure is currently being developed and is intended be a more accurate representation of all of the choices an individual made, as well as accounting for the degree of uncertainty exhibited by individuals as preferences change. If this measure more effectively represents flexibility (determined using a modeled dataset and not the actual data), we may decide to solely rely on this measure and not use flexibility measures 1 through 3. If this ends up being the case, we will modify the code in the analysis plan below to reflect this change.

##### *P3: does training improve detour performance?*

1) Condition: pre- or post-reversal learning tests


##### Unregistered analysis: Interobserver reliability of dependent variables

To determine whether experimenters coded the dependent variables in a repeatable way, hypothesis-blind video coders, Sophie Kaube (detour) and Brynna Hood (go no-go), were first trained in video coding the dependent variables (detour and go no-go: whether the bird made the correct choice or not), requiring a Cohen's unweighted kappa of 0.90 or above to pass training (using the psych package in R @psych). This threshold indicates that the two coders (the experimenter and the video coder) agree with each other to a high degree (@landis1977measurement). After passing training, the video coders coded 24% (detour) and 33% (go no-go) of the videos for each experiment and the unweighted Cohen's kappa was calculated to determine how objective and repeatable scoring was for this variable, while noting that the experimenter had the advantage over the video coder because watching the videos was not as clear as watching the bird participate in the trial from the aisle of the aviaries. The unweighted kappa was used because this is a categorical variable where the distances between the numbers are meaningless (0=incorrect choice, 1=correct choice, -1=did not participate).

**Detour: correct choice**

We randomly chose four (Diablo, Queso, Chalupa, and Habanero) of the 11 birds that had participated in this experiment by Nov 2019 using random.org. First, Kaube analyzed all videos from Habanero and Diablo, and we analyzed the data using an intraclass correlation coefficient, which is not an appropriate test for categorical data. After learning this, we switched to using the Cohen's unweighted kappa and replaced Habanero and Diablo with two new randomly chosen grackles (Mole and Chilaquile). Kaube then analyzed all videos from Queso and Chalupa for training and passed (Cohen's unweighted kappa=0.91, confidence boundary=0.75-1.00, n=24 data points). After passing training, Kaube analyzed all videos from Queso, Chalupa, Mole, and Chilaquile, and highly agreed with the experimenter's data (Cohen's unweighted kappa=0.91, confidence boundary=0.78-1.00, n=44 data points).

**Go no-go: correct choice**

We randomly chose three (Diablo, Burrito, and Chilaquile) of the 12 birds that were estimated to complete this experiment using random.org. Hood then analyzed all videos from Diablo for training and passed (Cohen's unweighted kappa=0.91, confidence boundary=0.80-1.00, n=40 data points). Hood then coded the rest of the videos and had substantial amounts of agreement with the experimenters (Cohen's unweighted kappa = 0.82, confidence boundary = 0.78-0.85, n=611 data points).

We think the reason for the lower interobserver agreement for this variable is due to the fact that the correct choice data were not as objective to code as we had hoped due to the touchscreen malfunctioning (not registering touches to the screen), and to the subjective criterion that the bird had to be within a certain distance of the screen to be considered paying attention and thus be in position to make a choice or not. This indicates that our touchscreen set up could be greatly improved such that it is actually automated, rather than needing experimenter intervention for every trial.

**Go no-go: latency to respond (peck the screen)**

Interobserver reliability was not conducted on this variable because we obtained this data from the automatically generated PsychoPy data sheets. However, we must note that when entering the latency to first screen peck into the main data sheet that the experimenter used to determine whether they made a correct choice or not, the two data sheets did not always match. This is because: 1) if a session started or ended with the bird not participating such that a trial was not triggered, this receives a -1 in the experimenter's data sheet and is not recorded by the PsychoPy data sheet; and 2) the touchscreen regularly failed to register screen pecks, which could result in an NA for the PsychoPy data sheet whereas the experimenter's data sheet recorded a choice.

```{r ior, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
library(irr) #ICC package

#### DETOUR

# did Sophie Kaube pass interobserver reliability training? YES (0.91) on 10 Feb 2020

## 9 Jan 2020 = ICC = 0.4 because we differed on 2/21 data points. However, Sophie was correct (CL checked the video) because she followed the instructions in an unbiased way. I need to rethink the instructions and then give her another video or two to code
ld <- c(1,1,-1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,1,1,1) #live coder data from AdaptedFirstTouchCorrectChoice column for A036R- 2019-01-07 Detour S1 T1, A036R- 2019-01-08 Detour S2 T3, A064LR 2019-11-07 Detour S1 T1
vd <- c(1,1,-1,1,1,1,1,1,1,1,1,0,1,1,1,1,2,2,1,1,1) #video coder data for same videos
vdtest <- c(1,1,-1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1) #video coder data for same videos 
d <- data.frame(ld,vdtest)

icc(d, model = "oneway", type = "consistency", unit = "single", conf.level = 0.95) #=0.412 BUT WAIT!!!! The reason the ICC was so low is because it was looking at the distance between the measurements: 0-2 and 0-2 were the differences, but in reality, these are just categories that don't have a distance. So change the TYPE to CONSISTENCY rather than AGREEMENT (http://neoacademic.com/2011/11/16/computing-intraclass-correlations-icc-as-estimates-of-interrater-reliability-in-spss/). BUT the instructions for ICC say that if a oneway model is chosen, then consistency is the only option so it is implicitly already doing consistency.

## 10 Feb 2020: Did Sophie pass IOR for the second 2 birds she coded? YES 0.91
#NOTE: don't just add more videos to the above analysis to try to get her ICC up because it would take more than 4 extra videos to counteract the 2 disagreements. Instead, start from scratch on different videos and have her recode the above after she passes.
ld2 <- c(1,1,1,-1,1,2,-1,1,1,1,1,-1,2,1,1,1,0,1,1,1,1,1,-1,1) #live coder data from AdaptedFirstTouchCorrectChoice column for the same videos as vd2
vd2 <- c(0,1,1,-1,1,2,-1,1,1,1,1,-1,2,1,1,1,0,1,1,1,1,1,-1,1) #video coder data from AdaptedFirstTouchCorrectChoice for videos A025GO 2018-12-30 Detour Up S1 T1, A025GO 2018-12-31 Detour S2 T4, A025GO 2018-12-31 Detour S3 T6, A025GO 2018-12-31 Detour S4 T9, A025GO 2019-01-01 Detour S5 T10, A031-Y 2018-10-08 Detour S1 T1, A031-Y 2018-10-09 Detour S2 T10
d5 <- data.frame(ld2+2,vd2+2) 

cohen.kappa(d5, w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Sophie = unweighted kappa = 0.91, confidence boundary=0.75-1.00, n=24 data points
#Now have Sophie code 2 additional birds (don't need any more IOR because she already passed) and then 20% of the videos will be double coded

## 19 Feb 2020: Sophie IOR score for 20% of the videos (birds 25 Chalupa, 31 Queso, 35 Mole, 86 Chilaquile) = 0.91
ld3 <- c(1,1,1,-1,1,2,-1,1,1,1,1,-1,2,1,1,1,0,1,1,1,1,1,-1,1,  0,1,1,1,2,1,1,1,1,1,2,1,2,1,2,1,1,1,1,2) #live coder data from AdaptedFirstTouchCorrectChoice column for the same videos as vd2
vd3 <- c(0,1,1,-1,1,2,-1,1,1,1,1,-1,2,1,1,1,0,1,1,1,1,1,-1,1,  2,1,1,1,2,1,1,1,1,1,2,1,2,1,2,1,1,1,1,2) #video coder data from AdaptedFirstTouchCorrectChoice for videos A025GO 2018-12-30 Detour Up S1 T1, A025GO 2018-12-31 Detour S2 T4, A025GO 2018-12-31 Detour S3 T6, A025GO 2018-12-31 Detour S4 T9, A025GO 2019-01-01 Detour S5 T10, A031-Y 2018-10-08 Detour S1 T1, A031-Y 2018-10-09 Detour S2 T10, A035P- 2018-12-20 Detour S1 T1, A086GB 2020-01-01 Detour S1 T1
dfinal <- data.frame(ld3+2,vd3+2) 
cohen.kappa(dfinal, w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #Sophie = unweighted kappa = 0.91, confidence boundary=0.78-1.00, n=44 data points


#### GO NO GO

# did Brynna Hood pass interobserver reliability training? YES Cohen's unweighted kappa = 0.91
mm <- c(-1,0,1,0,1,0,1,0,1,0,0,1,1,-1,1,0,1,0,1,0,1,0,1,0,0,1,0,1,1,0,0,1,1,0,0,0,0,1,1,0) #live coder data (Maggie MacPherson) from CorectChoice column for the same trials as in videos for bh
bh <- c(-1,2,1,0,1,0,1,0,1,0,0,1,1,-1,1,0,1,0,1,0,1,2,1,0,0,1,0,1,1,0,0,1,1,0,0,0,0,1,1,0) #video coder data from CorrectChoice for videos A064LR 2019-12-06 Go:No-Go S1 T1.mp4, A064LR 2019-12-06 Go:No-Go S2 T19.mp4
dgng <- data.frame(mm,bh) 
cohen.kappa(dgng, w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #unweighted kappa = 0.91, confidence boundaries 0.80-1.00, n=40 data points

# interobserver reliability on 20% of the videos between Brynna Hood and the live coder (LC)
data <- read.csv("/Users/corina/ownCloud/Documents/Experiments/Interobserver Reliability/InterObsRelGoNoGoLCBrynna.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(data)  #Check to make sure it looks right
# Note: c(3,5) is telling R to look at columns 2 ('1CorrectChoice') and 3 ('2CorrectChoiceAdapted') and compare them. Double check this:
data[,3] #1CorrectChoice = live coder
data[,5] #2CorrectChoiceAdapted = re-aligned Coder2 data from Brynna
cohen.kappa(data[,c(3,5)], w=NULL,n.obs=NULL,alpha=.05,levels=NULL) #unweighted kappa = 0.82, confidence boundary = 0.78-0.85, n=611 data points
```



### E. ANALYSIS PLAN

We do not plan to **exclude** any data. When **missing data** occur, the existing data for that individual will be included in the analyses for the tests they completed. Analyses will be conducted in R (current version `r getRversion()`; @rcoreteam). When there is more than one experimenter within a test, experimenter will be added as a random effect to account for potential differences between experimenters in conducting the tests. If there are no differences between models including or excluding experimenter as a random effect, then we will use the model without this random effect for simplicity.

#### Ability to detect actual effects

To begin to understand what kinds of effect sizes we will be able to detect given our sample size limitations and our interest in decreasing noise by attempting to measure it, which increases the number of explanatory variables, we used G&ast;Power (v.3.1, @faul2007g, @faul2009statistical) to conduct power analyses based on confidence intervals. G&ast;Power uses pre-set drop down menus and we chose the options that were as close to our analysis methods as possible (listed in each analysis below). Note that there were no explicit options for GLMs (though the chosen test in G&ast;Power appears to align with GLMs) or GLMMs or for the inclusion of the number of trials per bird (which are generally large in our investigation), thus the power analyses are only an approximation of the kinds of effect sizes we can detect. We realize that these power analyses are not fully aligned with our study design and that these kinds of analyses are not appropriate for Bayesian statistics (e.g., our MCMCglmm below), however we are unaware of better options at this time. Additionally, it is difficult to run power analyses because it is unclear what kinds of effect sizes we should expect due to the lack of data on this species for these experiments. 

#### Data checking

The data will be visually checked to determine whether they are normally distributed via two methods: 1) normality is indicated when the histograms of actual data match those with simulated data (Figure 2), and 2) normality is indicated when the residuals closely fit the dotted line in the Normal Q-Q plot (Figure 3) [@zuur2009]. If the data do not appear normally distributed, visually check the residuals. If they are patternless, then assume a normal distribution [@zuur2009]. Detour data look normal, go no go data are questionable, and both have patternless residuals, therefore we presume normality for both variables.

```{r dist_checkHist, eval=FALSE, warning=FALSE, results='asis', echo=TRUE}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsLast","AvgLatency")

#Check the dependent variables for normality: Histograms
op <- par(mfrow=c(2,4), mar=c(4,4,2,0.2))
#This is what the distribution of actual data looks like
hist(d$Gonogo150, xlab="Go no-go 150: Trials to criterion", main="Actual Data") #not normally distributed
hist(d$Gonogo85, xlab="Go no-go 85 (unregistered): Trials to criterion", main="Actual Data") #much more normally distributed than Gonogo150
hist(d$Detour, xlab="Detour: First approach", main="Actual Data")

#Given the actual data, this is what a normal distribution would look like
Y2 <- rnorm(1281, mean=mean(d$Gonogo150), sd=sd(d$Gonogo150))
hist(Y2, xlab="Go/no-go 150: Trials to criterion", main="Simulated Data") #The NAs break this, but looking at the histogram, the data are not normally distributed

Z2 <- rnorm(1281, mean=mean(d$Detour), sd=sd(d$Detour))
hist(Z2, xlab="Detour: First approach", main="Simulated Data")


#Check the dependent variables for normality: Q-Q plots
op <- par(mfrow=c(3,4), mar=c(4,4,2,0.2))
plot(glm(d$Gonogo150~d$TrialsLast)) 
plot(glm(d$Gonogo85~d$TrialsLast)) 
plot(glm(d$Detour~d$TrialsLast)) 
#detour looks normally distributed, go no go 150 data are borderline, go no go 85 data are normally distributed. Analyze all three dependent variables.

##Check the dependent variables for normality: Residuals
op <- par(mfrow=c(1,3), mar=c(4,4,2,0.2))
plot(residuals(glm(d$Detour~d$TrialsLast)), ylab="Detour residuals: First approach ~ Trials to reverse")
plot(residuals(glm(d$Gonogo150~d$TrialsLast)), ylab="Go-no-go 150: Residuals Correct response ~ Trials to reverse")
plot(residuals(glm(d$Gonogo85~d$TrialsLast)), ylab="Go-no-go 85 (unregistered): Residuals Correct response ~ Trials to reverse")
#All look patternless. Analyze all three dependent variables.

#The distribution of the actual data versus what a normal distribution would look like with simulated data. Residuals vs fitted: checking for homogeneity, which is satisfied if residuals have an even spread across the x-axis; Normal Q-Q: residuals are normally distributed if they are on the diagonal line; Residuals vs leverage: Cook's distance <1 means no influential observations [@zuur2009].
```


#### P1: delayed gratification

**Assess food preferences:** Conduct preference tests between pairs of different foods. Rank food preferences into three categories (High, Medium, Low) in the order of the percentage of times a food was chosen.

**Analysis:** Generalized Linear Model (GLM; glm function, stats package) with a Poisson distribution and log link, unless the only choices made were 0 (they didn't wait for food) and 1 (they waited for 1 piece of food but not for 2 or 3), in which case we will use a binomial distribution with a logit link. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

To determine our ability to detect actual effects, we ran a power analysis in G&ast;Power with the following settings: test family=F tests, statistical test=linear multiple regression: Fixed model (R^2 deviation from zero), type of power analysis=a priori, alpha error probability=0.05. We reduced the power to 0.70 and increased the effect size until the total sample size in the output matched our projected sample size (n=32). The protocol of the power analysis is here:

*Input:*

Effect size f                	=	0,41
			
 err prob                    	=	0,05

Power (1- err prob)          	=	0,7

Number of predictors          	=	5

*Output:*

Noncentrality parameter      	=	13,1200000

Critical F                    	=	2,5867901

Numerator df                  	=	5

Denominator df                	=	26

Total sample size             	=	32

Actual power                  	=	0,7103096

This means that, with our sample size of 32, we have a 71% chance of detecting a large effect (approximated at f^2^=0.35 by @cohen1988statistical). 

```{r better, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
acc <- read.csv ("/Users/corina/GTGR/data/data_accumulation.csv", header=T, sep=",", stringsAsFactors=F) 

#GLM
better <- glm(NumberOfAccumulationsWaited ~ Delay + FoodQualityQuantity + Trial + TrialsToReverseLast, family="poisson", data=acc)
#summary(better)

better1 <- summary(better)
library(xtable)
better1.table <- xtable(better1)
library(knitr)
kable(better1.table, caption="Table U: Model selection output.", format="html", digits=2)
```

These analyses were not conducted because the experiment failed due to the grackles never habituating to the test apparatuses.

#### P1: go no-go

**Analysis:** 

**Model 2a: number of trials to reach criterion in the go no-go experiment** Generalized Linear Model (GLM; glm function, stats package) with a Poisson distribution and a log link. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

To determine our ability to detect actual effects, we ran a power analysis in G&ast;Power with the following settings: test family=F tests, statistical test=linear multiple regression: Fixed model (R^2 deviation from zero), type of power analysis=a priori, alpha error probability=0.05. We reduced the power to 0.70 and increased the effect size until the total sample size in the output matched our projected sample size (n=32). The protocol of the power analysis is here:

*Input:*

Effect size f                	=	0,27

 err prob                    	=	0,05

Power (1- err prob)          	=	0,7

Number of predictors          	=	2

*Output:*

Noncentrality parameter      	=	8,6400000

Critical F                    	=	3,3276545

Numerator df                  	=	2

Denominator df                	=	29

Total sample size             	=	32

Actual power                  	=	0,7047420

This means that, with our sample size of 32, we have a 70% chance of detecting a medium (approximated at f^2^=0.15 by @cohen1988statistical) to large effect (approximated at f^2^=0.35 by @cohen1988statistical). 

```{r go, eval=F, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsFirst","TrialsLast","AvgLatency")

#GLM
m1 <- glm(Gonogo150 ~ TrialsLast, family="poisson", data=d)
#sm1 <- summary(m1) 
#there is no relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the last reversal)

m2 <- glm(Gonogo85 ~ TrialsLast, family="poisson", data=d)
#sm2 <- summary(m2) 
#there is a relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the last reversal) 

#have a look at the plot to see why m2, but not m1 is positively related
#plot(Gonogo85~TrialsLast, data=d) 
#Taquito is a huge outlier here and if I look at the rest of the data, I don't see a positive relationship. Need more data to know whether this relationship holds


#UNREGISTERED analyses: number of trials to reverse in the first reversal (which will make this data comparable with more species)
u1 <- glm(Gonogo150 ~ TrialsFirst, family="poisson", data=d)
#su1 <- summary(u1) 
#there is no relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the first reversal)

u2 <- glm(Gonogo85 ~ TrialsFirst, family="poisson", data=d)
#su2 <- summary(u2) 
#there is no relationship between the number of trials to pass criterion in go no go and the number of trials to reverse a preference (in the first reversal) (though the estimate 0.008 and the standard error is lower than the estimate so it doesn't cross zero, it is is significant: p<2e-16)


#load packages for the output table
library(jtools) 
base::suppressMessages(jtools::export_summs(m1, m2, u1, u2, model.names=c("150 last reversal","85 last reversal","150 first reversal","85 first reversal"), digits = getOption("jtools-digits", default = 2), model.info = getOption("summ-model.info", TRUE), model.fit = getOption("summ-model.fit", TRUE), pvals = getOption("summ-pvals", FALSE))) 
#suppressMessages gets rid of the text saying that the broom package overwrites something in jtools. Need to specify the package before the function to avoid a message popping up and preventing the PDF from rendering
knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)}) 
#this prevents an issue with xcolor package when rendering to PDF


#Note: this code also works for showing output tables, but don't know how to get it to show more than one model at a time
#library(xtable)
#sm1.table <- xtable(sm1)
#library(knitr)
#kable(sm1.table, caption="Table T: Model selection output.", format="html", digits=2)
```


**Model 2b: latency to respond in the go no-go experiment** A Generalized Linear Mixed Model (GLMM; MCMCglmm function, MCMCglmm package; [@hadfieldMCMCglmmpackage]) will be used with a Poisson distribution and log link using 13,000 iterations with a thinning interval of 10, a burnin of 3,000, and minimal priors (V=1, nu=0) [@hadfield2014coursenotes]. We will ensure the GLMM shows acceptable convergence (lag time autocorrelation values <0.01 after lag 0; [@hadfieldMCMCglmmpackage]), and adjust parameters if necessary. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

NOTE (Sep 2020): we changed the distribution to Gaussian (with an identity link) because MCMCglmm would not run on a Poisson (it kept saying there were negative integers even after we removed them). A Gaussian distribution also works for this kind of data because the response variable is a latency in seconds.

To roughly estimate our ability to detect actual effects (because these power analyses are designed for frequentist statistics, not Bayesian statistics), we ran a power analysis in G&ast;Power with the following settings: test family=F tests, statistical test=linear multiple regression: Fixed model (R^2 deviation from zero), type of power analysis=a priori, alpha error probability=0.05. We reduced the power to 0.70 and increased the effect size until the total sample size in the output matched our projected sample size (n=32). The number of predictor variables was restricted to only the fixed effects because this test was not designed for mixed models. The protocol of the power analysis is here:

*Input:*

Effect size f                	=	0,32

 err prob                    	=	0,05

Power (1- err prob)          	=	0,7

Number of predictors          	=	3

*Output:*

Noncentrality parameter      	=	10,2400000

Critical F                    	=	2,9466853

Numerator df                  	=	3

Denominator df                	=	28

Total sample size             	=	32

Actual power                  	=	0,7061592

This means that, with our sample size of 32, we have a 71% chance of detecting a large effect (approximated at f^2^=0.35 by @cohen1988statistical). 

```{r golatency, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_data_gonogoExperimenter.csv"), header=T, sep=",", stringsAsFactors=F)
d <- data.frame(d)

#Remove trials that grackles didn't participate in, & Queso who didn't complete this experiment
d1 <- d[!d$CorrectChoice==-1  & !d$ID=="Queso",] 

#Note that latency data was brought in from PsychoPy data sheets, and that the number of trials reported by the experimenter and by PsychoPy sometimes differed for reasons that are not clear. Therefore, the first latency to peck the screen is not completely accurately matched between the two data sheets.

#Set numeric and factors so MCMCglmm will run
d1$LatencyFirstPeckToScreen <- as.numeric(d1$LatencyFirstPeckToScreen)
d1$Trial <- as.numeric(d1$Trial)
d1$CorrectChoice <- as.factor(d1$CorrectChoice)
d1$ID <- as.factor(d1$ID)

#GLMM
library(MCMCglmm)
prior2 = list(G=list(G1=list(V=1,nu=0)))

go <- MCMCglmm(LatencyFirstPeckToScreen ~ CorrectChoice * Trial, random=~ID, family="gaussian", data=d1, verbose=F, prior=prior2, nitt=3000000, thin=8000, burnin=2800000)
#gaussian = identity link for mcmcglmm https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf
summary(go)
autocorr(go$Sol) 
#Did fixed effects converge? No, changed nitt and burning from 13000 and 3000 respectively but nothing is getting it to converge
autocorr(go$VCV) 
#Did random effects converge? No, changed nitt and burning from 13000 and 3000 respectively but nothing is getting it to converge
#The model did not converge so cannot include it in the results section
```

#### P1: detour

**Analysis:** Generalized Linear Model (GLM; glm function, stats package) with a binomial distribution and a logit link. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

See the protocol for the power analyses for Model 2b above for the rough estimation our ability to detect actual effects with this model.

```{r detour, eval=F, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsFirst","TrialsLast","AvgLatency")

#GLM
d$ID <- factor(d$ID)
m4 <- glm(Detour ~ TrialsLast, family="binomial", data=d)
sm4 <- summary(m4) 
#there is no relationship between the proportion of trials correct on the detour task and the number of trials to reverse in the last reversal

#UNREGISTERED ANALYSIS: first reversal (rather than last reversal)
m5 <- glm(Detour ~ TrialsFirst, family="binomial", data=d)
sm5 <- summary(m5) 

#load packages for the output table
library(jtools) 
base::suppressMessages(jtools::export_summs(m4, m5, model.names=c("last reversal","first reversal"), digits = getOption("jtools-digits", default = 2), model.info = getOption("summ-model.info", TRUE), model.fit = getOption("summ-model.fit", TRUE), pvals = getOption("summ-pvals", FALSE))) 
#suppressMessages gets rid of the text saying that the broom package overwrites something in jtools. Need to specify the package before the function to avoid a message popping up and preventing the PDF from rendering
knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)}) 
#this prevents an issue with xcolor package when rendering to PDF
```

#### P1 alternative 2: are behavioral inhibition results reliable?

The reliability of the behavioral inhibition tests will be calculated using Cronbach's Alpha (as in @friedman2004relations; R package: psych [@psych], function: alpha), which is indicated by std.alpha in the output.

```{r reliability, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
dat <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datareliabilityanalysis.csv"), header=T, sep=",", stringsAsFactors=F)
dat <- data.frame(dat)
#Note: n=8 grackles participated in both of these tests (1 is female). Had to make IDs numeric for the code below to run

#From http://personality-project.org/r/r.guide.html#alpha "correlate the 5 items, rounded off to 2 decimals, use pairwise cases"
round(cor(dat,use="pair"),2)             
#correlations: go no-go 150 and detour=0.50, go no-go 85 and detour=0.40, go no-go 150 and detoura=0.70, go no-go 85 and detoura=0.29, go no-go 150 and 85=0.23, detour and detoura=0.73

#define a function to find the alpha coefficient
alpha.scale=function (x,y)   #create a reusable function to find coefficient alpha
	#input to the function are a scale and a data.frame of the items in the scale
        {
                Vi=sum(diag(var(y,na.rm=TRUE)))     #sum of item variance
                Vt=var(x,na.rm=TRUE)                #total test variance
                n=dim(y)[2]     #how many items are in the scale?  (calculated dynamically)
                ((Vt-Vi)/Vt)*(n/(n-1))}             #alpha

#find the alpha for the scale E1 made up of the 5 items in E1.df 
E.alpha=alpha.scale(dat,dat)  
E.alpha

library(psych)
datdf <- with(dat,data.frame(gng150, detour)) #another way to create the data.frame
alpha(datdf) 

#reliab <- psych::alpha(dat) 
#Check.keys automatically reverses the coding for variables that are negatively correlated with the total scale. How to interpret: http://data.library.virginia.edu/using-and-interpreting-cronbachs-alpha/ "If all of the scale items are entirely independent from one another (i.e., are not correlated or share no covariance), then alpha = 0; and, if all of the items have high covariances, then alpha will approach 1 as the number of items in the scale approaches infinity. In other words, the higher the alpha coefficient, the more the items have shared covariance and probably measure the same underlying concept."
#summary(reliab)
#Insert into text: `r reliab$std.alpha`
```



#### P2: correlation across behavioral inhibition tasks

**See analysis description for P1 alternative 2.** 

```{r reliability2, eval=FALSE, warning=FALSE, results='asis', echo=TRUE, include=TRUE}
dat <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datareliabilityanalysis.csv"), header=T, sep=",", stringsAsFactors=F)
dat <- data.frame(dat)
#Note: n=8 grackles participated in both of these tests (1 is female). Had to make IDs numeric for the code below to run


#From http://personality-project.org/r/r.guide.html#alpha 
attach(dat) #make this the active path
dat1=gng150+detour
dat2=data.frame(gng150+detour)
summary(dat2)

#"correlate the 5 items, rounded off to 2 decimals, use pairwise cases"
round(cor(dat2,use="pair"),2)             
#correlations: go no-go 150 and detour=0.50, go no-go 85 and detour=0.40, go no-go 150 and detoura=0.70, go no-go 85 and detoura=0.29, go no-go 150 and 85=0.23, detour and detoura=0.73

#define a function to find the alpha coefficient
alpha.scale=function (x,y)   #create a reusable function to find coefficient alpha
	#input to the function are a scale and a data.frame of the items in the scale
        {
                Vi=sum(diag(var(y,na.rm=TRUE)))     #sum of item variance
                Vt=var(x,na.rm=TRUE)                #total test variance
                n=dim(y)[2]     #how many items are in the scale?  (calculated dynamically)
                ((Vt-Vi)/Vt)*(n/(n-1))}             #alpha

#find the alpha for the scale E1 made up of the 5 items in E1.df 
E.alpha=alpha.scale(dat1,dat2)  
E.alpha
detach(dat)

library(psych)
datdf <- with(dat,data.frame(gng150, detour)) #another way to create the data.frame
alpha(datdf) 

#reliab2 <- psych::alpha(dat, n.var="2") 
#Check.keys automatically reverses the coding for variables that are negatively correlated with the total scale. How to interpret: http://data.library.virginia.edu/using-and-interpreting-cronbachs-alpha/ "If all of the scale items are entirely independent from one another (i.e., are not correlated or share no covariance), then alpha = 0; and, if all of the items have high covariances, then alpha will approach 1 as the number of items in the scale approaches infinity. In other words, the higher the alpha coefficient, the more the items have shared covariance and probably measure the same underlying concept."
#summary(reliab2)
```

When analyzing the go no-go and detour tasks, the reliability is alpha=`r reliab$std.alpha`. 

#### P3: does training improve detour performance?

**Analysis:** Generalized Linear Model (GLM; glm function, stats package) with a binomial distribution and a logit link. We will determine whether an independent variable had an effect or not using the Estimate in the full model.

To determine our ability to detect actual effects, we ran a power analysis in G&ast;Power with the following settings: test family=F tests, statistical test=linear multiple regression: Fixed model (R^2 deviation from zero), type of power analysis=a priori, alpha error probability=0.05. We reduced the power to 0.70 and increased the effect size until the total sample size in the output matched our projected sample size (n=32). The protocol of the power analysis is here:

*Input:*

Effect size f                	=	0,21

 err prob                    	=	0,05

Power (1- err prob)          	=	0,7

Number of predictors          	=	1

*Output:*

Noncentrality parameter      	=	6,7200000

Critical F                    	=	4,1708768

Numerator df                  	=	1

Denominator df                	=	30

Total sample size             	=	32

Actual power                  	=	0,7083763

This means that, with our sample size of 32, we have a 71% chance of detecting a medium effect (approximated at f^2^=0.15 by @cohen1988statistical).

```{r detour2, eval=F, warning=F, results='asis', echo=T, include=T}
d <- read.csv(url("https://raw.githubusercontent.com/corinalogan/grackles/master/Files/Preregistrations/g_inhibition_datasummary.csv"), header=F, sep=",", stringsAsFactors=F)
d <- data.frame(d)
colnames(d) <- c("Bird","ID","Gonogo150","Gonogo85","Detour","DetourA","Detourprepost","TrialsFirst","TrialsLast","AvgLatency")

#GLM - detour standard correct choice scoring
de <- glm(Detour ~ Detourprepost, family="binomial", data=d)
sde <- summary(de)
#no difference between detour percent correct and whether they received detour before or after reversal tubes

#GLM - detour grackle-specific correct choice scoring - UNREGISTERED ANALYSIS
de2 <- glm(DetourA ~ Detourprepost, family="binomial", data=d)
sde2 <- summary(de2)
#no difference between detour percent correct and whether they received detour before or after reversal tubes

#load packages for the output table
library(jtools) 
base::suppressMessages(jtools::export_summs(de, de2, model.names=c("Detour standard","Detour grackle-specific"), digits = getOption("jtools-digits", default = 2), model.info = getOption("summ-model.info", TRUE), model.fit = getOption("summ-model.fit", TRUE), pvals = getOption("summ-pvals", FALSE))) 
#suppressMessages gets rid of the text saying that the broom package overwrites something in jtools. Need to specify the package before the function to avoid a message popping up and preventing the PDF from rendering
knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)}) 
#this prevents an issue with xcolor package when rendering to PDF
```

#### Alternative Analyses

We anticipate that we will want to run additional/different analyses after reading @statrethinkingbook. We will revise this preregistration to include these new analyses before conducting the analyses above. See the [State of the Data](#a-state-of-the-data) for a description of the analysis changes we made.

### F. PLANNED SAMPLE

Great-tailed grackles are caught in the wild in Tempe, Arizona USA for individual identification (colored leg bands in unique combinations). Some individuals (~32) are brought temporarily into aviaries for testing, and then they will be released back to the wild. Grackles are individually housed in an aviary (each 244cm long by 122cm wide by 213cm tall) at Arizona State University for a maximum of three months where they have ad lib access to water at all times and are fed Mazuri Small Bird maintenance diet ad lib during non-testing hours (minimum 20h per day), and various other food items (e.g., peanuts, grapes, bread) during testing (up to 3h per day per bird). Individuals are given three to four days to habituate to the aviaries and then their test battery begins on the fourth or fifth day (birds are usually tested six days per week, therefore if their fourth day in the aviaries occurs on a day off, then they are tested on the fifth day instead).

**Sample size rationale**

We will test as many birds as we can in the approximately three years at this field site given that the birds only participate in tests in aviaries during the non-breeding season (approximately September through March). The minimum sample size will be 16, however we expect to be able to test up to 32 grackles.

**Data collection stopping rule**

We will stop testing birds once we have completed two full aviary seasons (likely in March 2020). NOTE: the two full aviary seasons concluded in May 2020.

### G. ETHICS

This research is carried out in accordance with permits from the:

1) US Fish and Wildlife Service (scientific collecting permit number MB76700A-0,1,2)
2) US Geological Survey Bird Banding Laboratory (federal bird banding permit number 23872)
3) Arizona Game and Fish Department (scientific collecting license number SP594338 [2017], SP606267 [2018], and SP639866 [2019])
4) Institutional Animal Care and Use Committee at Arizona State University (protocol number 17-1594R)
5) University of Cambridge ethical review process (non-regulated use of animals in scientific procedures: zoo4/17)

### H. AUTHOR CONTRIBUTIONS

**Logan:** Hypothesis development, experimental design (go no-go task), data collection, data analysis and interpretation, write up, revising/editing, materials/funding.

**McCune:** Data collection, data interpretation, revising/editing.

**MacPherson:** Data collection, data interpretation, revising/editing.

**Johnson-Ulrich:** Touchscreen programming for go no-go task, data interpretation, revising/editing.

**Bergeron:** Data collection, data interpretation, revising/editing.

**Rowney:** Data collection, data interpretation, revising/editing.

**Seitz:** Experimental design (go no-go task), touchscreen programming (go no-go task), data interpretation, revising/editing.

**Blaisdell:** Experimental design (go no-go task), data interpretation, revising/editing.

**Folsom:** Data collection, data interpretation, revising/editing.

**Deffner:** Data analysis (Flexibilitx 4 model), revising/editing.

**Wascher:** Hypothesis development, experimental design (delayed gratification and detour tasks), data analysis and interpretation, write up, revising/editing.

### I. FUNDING

This research is funded by the Department of Human Behavior, Ecology and Culture at the Max Planck Institute for Evolutionary Anthropology, and by a Leverhulme Early Career Research Fellowship to Logan in 2017-2018.

### J. CONFLICT OF INTEREST DISCLOSURE

We, the authors, declare that we have no financial conflicts of interest with the content of this article. Corina Logan is a Recommender and on the Managing Board at PCI Ecology.

### K. ACKNOWLEDGEMENTS

We thank Dieter Lukas for help polishing the predictions; Ben Trumble for providing us with a wet lab at Arizona State University and Angela Bond for lab support; Melissa Wilson Sayres for sponsoring our affiliations at Arizona State University and lending lab equipment; Kevin Langergraber for serving as local PI on the ASU IACUC; Kristine Johnson for technical advice on great-tailed grackles; Arizona State University School of Life Sciences Department Animal Care and Technologies for providing space for our aviaries and for their excellent support of our daily activities; Julia Cissewski for tirelessly solving problems involving financial transactions and contracts; Richard McElreath for project support; Erin Vogel, our Recommender at PCI Ecology, and Simon Gingins and two anonymous reviewers for their wonderful feedback; Debbie Kelly for advice on how to modify the go no-go experiment; and our research assistants: Aelin Mayer, Nancy Rodriguez, Brianna Thomas, Aldora Messinger, Elysia Mamola, Michael Guillen, Rita Barakat, Adriana Boderash, Olateju Ojekunle, August Sevchik, Justin Huynh, Jennifer Berens, and Amanda Overholt.

### L. REFERENCES
